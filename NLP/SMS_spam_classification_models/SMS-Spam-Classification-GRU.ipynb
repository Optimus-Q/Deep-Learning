{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\perei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\perei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libaries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "\n",
    "sms = pd.read_csv(\"SMSSpamCollection.csv\", sep = '\\t', names = ['label', 'message'])\n",
    "sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_text = sms['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                 Will ü b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\perei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\perei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import TextCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TextCleaner.TextCleaner(text = sms_text, text_form = 'List', stemming = True, lemmat = False)\n",
    "text_clean = tc.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n",
       " 'ok lar joke wif u oni',\n",
       " 'free entri wkli comp win fa cup final tkt st may tet fa receiv entri questionstd tt ratetc appli over']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clean[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Go until jurong point, crazy.. Available only ...\n",
       "1                        Ok lar... Joking wif u oni...\n",
       "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once all the text is cleaned, we now have to create the vocabulary of the sms messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_vocab_text = ' '.join(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_vocab_words = sorted(pre_vocab_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(pre_vocab_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('<UNK>')\n",
    "vocab.add('<PAD>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentenc',\n",
       " 'stdttrate',\n",
       " 'delu',\n",
       " 'fede',\n",
       " 'nuclear',\n",
       " 'costa',\n",
       " 'boyfriend',\n",
       " 'sudden',\n",
       " 'spark',\n",
       " 'uv',\n",
       " 'weeddefici',\n",
       " 'foreign',\n",
       " 'wrk!',\n",
       " 'roll',\n",
       " 'ill!',\n",
       " 'fine!',\n",
       " 'make',\n",
       " 'around!',\n",
       " 'what‘',\n",
       " 'youv',\n",
       " 'spontan',\n",
       " 'readyal',\n",
       " 'black',\n",
       " 'uup',\n",
       " 'main',\n",
       " 'rentl',\n",
       " 'cd',\n",
       " 'chat',\n",
       " 'kavalan',\n",
       " 'cover',\n",
       " 'over',\n",
       " 'chase',\n",
       " 'night!',\n",
       " 'medicin',\n",
       " 'thia',\n",
       " 'barm',\n",
       " 'gaug',\n",
       " 'tuition',\n",
       " 'merri',\n",
       " 'tech',\n",
       " 'variou',\n",
       " 'beforew',\n",
       " 'mg',\n",
       " 'thatd',\n",
       " 'tp',\n",
       " 'closedinclud',\n",
       " 'oper',\n",
       " 'dontgettet',\n",
       " 'faber',\n",
       " 'delet',\n",
       " 'hun!',\n",
       " 'orang',\n",
       " 'blake',\n",
       " 'clearer',\n",
       " 'corpor',\n",
       " 'comp',\n",
       " 'british',\n",
       " 'etc',\n",
       " 'itcould',\n",
       " 'd!!b',\n",
       " 'lit',\n",
       " 'hellodrivbyquit',\n",
       " 'heater',\n",
       " 'danalla',\n",
       " 'hurt',\n",
       " 'wwwbridalpetticoatdreamscouk',\n",
       " 'reappli',\n",
       " 'upset',\n",
       " 'questionstd',\n",
       " 'custcar',\n",
       " 'blond',\n",
       " 'bcozi',\n",
       " 'doin',\n",
       " 'tmorrowpl',\n",
       " 'disast',\n",
       " 'fmyou',\n",
       " 'stone',\n",
       " 'what',\n",
       " 'foreg',\n",
       " 'soire',\n",
       " 'stori',\n",
       " 'adewal',\n",
       " 'chop',\n",
       " 'onlin',\n",
       " 'cha',\n",
       " 'muhommad',\n",
       " 'reltnship!!',\n",
       " 'stopc',\n",
       " 'hide',\n",
       " 'hardest',\n",
       " 'waysmscom',\n",
       " 'thasa',\n",
       " 'salmon',\n",
       " 'ahth',\n",
       " 'raja',\n",
       " 'co',\n",
       " 'sf',\n",
       " 'monkey',\n",
       " 'workout',\n",
       " 'year!',\n",
       " 'hitler',\n",
       " 'multi',\n",
       " 'iff',\n",
       " 'alway',\n",
       " 'okday!',\n",
       " 'parti',\n",
       " 'hundr',\n",
       " 'mall',\n",
       " 'oppos',\n",
       " 'chat!',\n",
       " 'hella',\n",
       " 'mj',\n",
       " '!!!',\n",
       " 'fire',\n",
       " 'maat',\n",
       " 'obedi',\n",
       " 'thoughtsi',\n",
       " 'wise',\n",
       " 'loosu',\n",
       " 'onum',\n",
       " 'truck',\n",
       " 'pptnormal',\n",
       " 'arrest',\n",
       " 'erutupalam',\n",
       " 'smidgin',\n",
       " 'usb',\n",
       " 'wtf',\n",
       " 'poortiyagi',\n",
       " 'movi',\n",
       " 'gon',\n",
       " 'terribl',\n",
       " 'wasn‘t',\n",
       " 'smsd',\n",
       " 'ipad',\n",
       " 'apr',\n",
       " 'hopeu',\n",
       " 'singl',\n",
       " 'csh',\n",
       " 'africa',\n",
       " 'heaven',\n",
       " 'petrol!',\n",
       " 'shracomorsglsuplt',\n",
       " 'night',\n",
       " 'okthenwhat',\n",
       " 'cell',\n",
       " 'rcv',\n",
       " 'cougarpen',\n",
       " 'evng',\n",
       " 'wwwsmsacunat',\n",
       " 'guitar',\n",
       " 'pro',\n",
       " 'bored!',\n",
       " 'bookmark',\n",
       " 'role',\n",
       " 'yetti',\n",
       " 'christian',\n",
       " 'crbt',\n",
       " 'toilet',\n",
       " 'rr',\n",
       " 'chatting!',\n",
       " 'lb',\n",
       " 'disturb',\n",
       " 'particular',\n",
       " 'hollalat',\n",
       " 'citizen',\n",
       " 'playi',\n",
       " 'shit!!',\n",
       " 'mandan',\n",
       " 'christ',\n",
       " 'ringtone!',\n",
       " 'appreci',\n",
       " 'enc',\n",
       " 'fromwrk',\n",
       " 'netcol',\n",
       " 'sankatmochan',\n",
       " 'laugh!',\n",
       " 'lololo',\n",
       " 'wwwrtfsphostingcom',\n",
       " 'phoni',\n",
       " 'bore',\n",
       " 'falconerf',\n",
       " 'pharmaci',\n",
       " 'slurp!',\n",
       " 'entertain',\n",
       " 'sarcast',\n",
       " 'pavanaputra',\n",
       " 'strtd',\n",
       " 'sayhey!',\n",
       " 'scari',\n",
       " 'hellohow',\n",
       " 'wrong',\n",
       " 'hypertens',\n",
       " 'nowcan',\n",
       " 'teenag',\n",
       " 'uncount',\n",
       " 'wun',\n",
       " 'cooper',\n",
       " 'pl',\n",
       " 'prcvd',\n",
       " 'wave',\n",
       " 'readi',\n",
       " 'footi',\n",
       " 'veget',\n",
       " 'perspect',\n",
       " 'still',\n",
       " 'ourback',\n",
       " 'anything!',\n",
       " 'hgsuitelandsrowwjhl',\n",
       " 'sheffield',\n",
       " 'tahan',\n",
       " 'lyf',\n",
       " 'fond',\n",
       " 'karnan',\n",
       " 'plz',\n",
       " 'nite!',\n",
       " 'godtaken',\n",
       " 'reflect',\n",
       " 'comprehens',\n",
       " 'stuffleav',\n",
       " 'ceil',\n",
       " 'skilgmetscswinawk!ageperwksub',\n",
       " 'photo',\n",
       " 'hut',\n",
       " 'intro',\n",
       " 'kanagu',\n",
       " 'sausagelov',\n",
       " 'qi',\n",
       " 'carlosl',\n",
       " 'three',\n",
       " 'advanc',\n",
       " 'water',\n",
       " 'sprwm',\n",
       " 'england!',\n",
       " 'turn',\n",
       " 'sensit',\n",
       " 'todaysundaysunday',\n",
       " 'goodtime!oli',\n",
       " 'officewhat',\n",
       " 'itlet',\n",
       " 'feet',\n",
       " 'transact',\n",
       " 'p',\n",
       " 'thinghow',\n",
       " 'moro',\n",
       " 'about!',\n",
       " 'quarter',\n",
       " 'shortag',\n",
       " 'actual',\n",
       " 'lainorf',\n",
       " 'unrecogn',\n",
       " 'cheap!',\n",
       " 'nice',\n",
       " 'hubbi',\n",
       " 'knowh',\n",
       " 'ard',\n",
       " 'cashto',\n",
       " 'independ',\n",
       " 'mre',\n",
       " 'bthere',\n",
       " 'dena',\n",
       " 'imin',\n",
       " 'hunny!wot',\n",
       " 'gower',\n",
       " 'bcz',\n",
       " 'row',\n",
       " 'infovipclubu',\n",
       " 'siri',\n",
       " 'away!!',\n",
       " 'youphon',\n",
       " 'global',\n",
       " 'lili',\n",
       " 'mere',\n",
       " 'se',\n",
       " 'youdo',\n",
       " 'auto',\n",
       " 'weekly!',\n",
       " 'nightnight',\n",
       " 'rg',\n",
       " 'chick',\n",
       " 'outta',\n",
       " 'honestli',\n",
       " 'what!',\n",
       " 'avoid',\n",
       " 'oredi',\n",
       " 'nvm',\n",
       " 'clash',\n",
       " 'hardli',\n",
       " 'progress',\n",
       " 'pari',\n",
       " 'wordnot',\n",
       " 'popcorn',\n",
       " 'hu',\n",
       " 'nelson',\n",
       " 'case',\n",
       " 'cough',\n",
       " 'sign',\n",
       " 'inour',\n",
       " 'pod',\n",
       " 'wwwtetpodnet',\n",
       " 'shoreth',\n",
       " 'dagood',\n",
       " 'itwhichturnedinto',\n",
       " 'pimpleseven',\n",
       " 'mysteri',\n",
       " 'ttjourney',\n",
       " 'minor',\n",
       " 'settl',\n",
       " 'freeli',\n",
       " 'frwd',\n",
       " 'reali',\n",
       " 'ralph',\n",
       " 'macha',\n",
       " 'onluy',\n",
       " 'hoo',\n",
       " 'keyword',\n",
       " 'caveboy',\n",
       " 'delhi',\n",
       " 'ltgt',\n",
       " 'savamob',\n",
       " '…',\n",
       " 'naal',\n",
       " 'recdthirtyeight',\n",
       " 'genuin',\n",
       " 'teacoffe',\n",
       " 'girlfrnd',\n",
       " 'eat',\n",
       " 'hospit',\n",
       " 'iphon',\n",
       " 'coupla',\n",
       " 'tiwari',\n",
       " 'sorta',\n",
       " 'address',\n",
       " 'surprise!',\n",
       " 'fishrman',\n",
       " 'access!',\n",
       " 'dime',\n",
       " 'repair',\n",
       " 'nitetel',\n",
       " 'goalsteam',\n",
       " 'shall',\n",
       " 'hello',\n",
       " 'icki',\n",
       " 'hat',\n",
       " 'gong',\n",
       " 'thatmum',\n",
       " 'joanna',\n",
       " 'dormitori',\n",
       " 'con',\n",
       " 'born!',\n",
       " 'transport',\n",
       " 'zac',\n",
       " 'freeringtone!',\n",
       " 'ea',\n",
       " 'java',\n",
       " 'gbpweek!',\n",
       " 'u!',\n",
       " 'dinero',\n",
       " 'prizeto',\n",
       " 'ti',\n",
       " 'gain',\n",
       " 'lookatme!',\n",
       " 'accentur',\n",
       " 'wrong!!',\n",
       " 'hook',\n",
       " 'whr',\n",
       " 'art!',\n",
       " 'differ',\n",
       " 'pressur',\n",
       " 'okay',\n",
       " 'gland',\n",
       " 'eta',\n",
       " 'super',\n",
       " 'corrct',\n",
       " 'leav',\n",
       " 'tsandc',\n",
       " 'john',\n",
       " 'chillain',\n",
       " 'wwworangecoukow',\n",
       " 'administr',\n",
       " 'iscom',\n",
       " 'specif',\n",
       " 'ambiti',\n",
       " 'theth',\n",
       " 'vri',\n",
       " 'lush!',\n",
       " 'roast',\n",
       " 'stream',\n",
       " 'fwiw',\n",
       " 'drugs!',\n",
       " 'marsm',\n",
       " 'matter',\n",
       " 'lanka',\n",
       " 'offcampu',\n",
       " 'delici',\n",
       " 'around',\n",
       " 'friendsar',\n",
       " 'steed',\n",
       " 'zed',\n",
       " 'amigo',\n",
       " 'nit',\n",
       " 'clock',\n",
       " 'pobowtgp',\n",
       " 'homewot',\n",
       " 'i\\x92llspeak',\n",
       " 'mathew',\n",
       " 'largest',\n",
       " 'woman',\n",
       " 'skype',\n",
       " 'starer',\n",
       " 'comb',\n",
       " 'burn',\n",
       " 'rechargerakhesh',\n",
       " 'appear',\n",
       " 'oic',\n",
       " 'forevr',\n",
       " 'gd',\n",
       " 'youdearwith',\n",
       " 'dead',\n",
       " 'wq',\n",
       " 'becau',\n",
       " 'nd',\n",
       " 'cro',\n",
       " 'mentor',\n",
       " 'n',\n",
       " 'sleep',\n",
       " 'fade',\n",
       " 'dorm',\n",
       " 'barri',\n",
       " 'befor',\n",
       " 'scarcasim',\n",
       " 'ml',\n",
       " 'wasn\\x92t',\n",
       " 'ned',\n",
       " 'maraikara',\n",
       " 'batch',\n",
       " 'voic',\n",
       " 'mtnl',\n",
       " 'liaoso',\n",
       " 'zealand',\n",
       " 'gf',\n",
       " 'badli',\n",
       " 'elama',\n",
       " 'terminatedw',\n",
       " 'lkpobohpfl',\n",
       " 'tessypl',\n",
       " 'tote',\n",
       " 'heat',\n",
       " 'pray!',\n",
       " 'halla',\n",
       " 'competit',\n",
       " 'itplspl',\n",
       " 'hunny!hop',\n",
       " 'idk',\n",
       " 'ranju',\n",
       " 'appoint',\n",
       " 'first',\n",
       " 'wwwcashbincouk',\n",
       " 'lennon',\n",
       " 'simpli',\n",
       " 'ifwhenhow',\n",
       " 'came',\n",
       " 'bash',\n",
       " 'soso',\n",
       " 'neva',\n",
       " 'weeks!',\n",
       " 'smart',\n",
       " 'bak!',\n",
       " 'issu',\n",
       " 'tke',\n",
       " 'rum',\n",
       " 'studi',\n",
       " 'minstand',\n",
       " 'director',\n",
       " 'nice!',\n",
       " 'fuckin',\n",
       " 'motherfuck',\n",
       " 'gin',\n",
       " 'champ',\n",
       " 'enufcredeit',\n",
       " 'ewif',\n",
       " 'aight',\n",
       " 'gimm',\n",
       " 'yday',\n",
       " 'frosti',\n",
       " 'quick',\n",
       " 'forth',\n",
       " 'poorli',\n",
       " 'picsfre',\n",
       " 'you‘ll',\n",
       " 'tui',\n",
       " 'regular',\n",
       " 'chatter!',\n",
       " 'credit!',\n",
       " 'steak',\n",
       " 'dobbi',\n",
       " 'mell',\n",
       " 'ptet',\n",
       " 'elect',\n",
       " 'heroi',\n",
       " 'paperwork',\n",
       " 'anyhow',\n",
       " 'gene',\n",
       " 'na',\n",
       " 'nite!!',\n",
       " 'piah',\n",
       " 'closer',\n",
       " 'loyalti',\n",
       " 'lst',\n",
       " 'semest',\n",
       " 'mp',\n",
       " 'patent',\n",
       " 'tooo',\n",
       " 'nap',\n",
       " 'interviw',\n",
       " 'tag',\n",
       " 'darlin!im',\n",
       " 'prasanth',\n",
       " 'imf',\n",
       " 'seed',\n",
       " 'housemaid',\n",
       " 'brotha',\n",
       " 'rp',\n",
       " 'evr',\n",
       " 'brin',\n",
       " 'bugi',\n",
       " 'apolog',\n",
       " 'qet',\n",
       " 'alert!',\n",
       " 'svc',\n",
       " 'nooooooo',\n",
       " 'wipe',\n",
       " 'shadow',\n",
       " 'dramastorm',\n",
       " 'perform',\n",
       " 'rct',\n",
       " 'cock!',\n",
       " 'prabha',\n",
       " 'front',\n",
       " 'lyricalladief',\n",
       " 'cdgt',\n",
       " 'parchi',\n",
       " 'zaher',\n",
       " 'swss',\n",
       " 'try!',\n",
       " 'charli',\n",
       " 'iriv',\n",
       " 'trip!',\n",
       " 'threw',\n",
       " 'georg',\n",
       " 'girld',\n",
       " 'oblivi',\n",
       " 'prakasamanu',\n",
       " 'maretar',\n",
       " 'guid',\n",
       " 'uso',\n",
       " 'utter',\n",
       " 'tait',\n",
       " 'nu',\n",
       " 'nothing!!',\n",
       " 'tonight!',\n",
       " 'meat',\n",
       " 'shag',\n",
       " 'datingi',\n",
       " 'drama',\n",
       " 'nat',\n",
       " 'sleepingand',\n",
       " 'difficulti',\n",
       " 'mood',\n",
       " 'lt',\n",
       " 'sayask',\n",
       " 'video',\n",
       " 'anythingtomorrow',\n",
       " 'lawu',\n",
       " 'worc',\n",
       " 'arrang',\n",
       " 'assess',\n",
       " 'autocorrect',\n",
       " 'beerr',\n",
       " 'pushbutton',\n",
       " 'comuk',\n",
       " 'ger',\n",
       " 'social',\n",
       " 'private!',\n",
       " 'suffer',\n",
       " 'favor',\n",
       " 'ew',\n",
       " 'bluray',\n",
       " 'grow',\n",
       " 'digi',\n",
       " 'tvhe',\n",
       " 'hannaford',\n",
       " 'gucci',\n",
       " 'kane',\n",
       " 'intrud',\n",
       " 'typelyk',\n",
       " 'cashin',\n",
       " 'pint',\n",
       " 'dealing!',\n",
       " 'monster!',\n",
       " 'haircut',\n",
       " 'anywher',\n",
       " 'situat',\n",
       " 'goodies!',\n",
       " 'beerag',\n",
       " 'rington',\n",
       " 'valu',\n",
       " 'perfect',\n",
       " 'ttno',\n",
       " 'gotten',\n",
       " 'doublemin',\n",
       " 'duffer',\n",
       " 'ko',\n",
       " 'weekday',\n",
       " 'wwwgambtv',\n",
       " 'identif',\n",
       " 'cribb',\n",
       " 'pressi',\n",
       " 'riddanc',\n",
       " 'blame',\n",
       " 'fusion',\n",
       " 'complac',\n",
       " 'justthought',\n",
       " 'lookin',\n",
       " 'camri',\n",
       " 'messageno',\n",
       " 'wellyou',\n",
       " 'payoh',\n",
       " 'luuri',\n",
       " 'colleagu',\n",
       " 'friend',\n",
       " 'often',\n",
       " 'christmas!',\n",
       " 'sack',\n",
       " 'parkin',\n",
       " 'dr',\n",
       " 'iron',\n",
       " 'pretend',\n",
       " 'shopw',\n",
       " 'like!',\n",
       " 'dat',\n",
       " 'aha',\n",
       " 'breezi',\n",
       " 'republ',\n",
       " 'action',\n",
       " 'deck',\n",
       " 'naughti',\n",
       " 'dental',\n",
       " 'feelingood',\n",
       " 'carpark',\n",
       " 'bom',\n",
       " 'dessert',\n",
       " 'argh',\n",
       " 'indian',\n",
       " 'cp',\n",
       " 'keri',\n",
       " 'officestil',\n",
       " 'bomb',\n",
       " 'sent',\n",
       " 'kthen',\n",
       " 'ten',\n",
       " 'mw',\n",
       " 'halfth',\n",
       " 'seeker',\n",
       " 'deltomorrow',\n",
       " 'meim',\n",
       " 'boyi',\n",
       " 'past',\n",
       " 'spele',\n",
       " 'compens',\n",
       " 'retriev',\n",
       " 'sif',\n",
       " 'ppmsg',\n",
       " 'thankyou',\n",
       " 'boob',\n",
       " 'fri!',\n",
       " 'healthi',\n",
       " 'bergkamp',\n",
       " 'upcharg',\n",
       " 'getzedcouk',\n",
       " 'vari',\n",
       " 'sutra',\n",
       " 'meet',\n",
       " 'where',\n",
       " 'sh!ja',\n",
       " 'lotto',\n",
       " 'wwwasjesuscom',\n",
       " 'sed',\n",
       " 'bedroom',\n",
       " 'melik',\n",
       " 'borin',\n",
       " 'untam',\n",
       " 'roomat',\n",
       " 'swtheart',\n",
       " 'sicomo',\n",
       " 'wrench',\n",
       " 'hiphop',\n",
       " 'thot',\n",
       " 'answr',\n",
       " 'online!',\n",
       " 'kort',\n",
       " 'vouchers!',\n",
       " 'uwant',\n",
       " 'darlin',\n",
       " 'kodthini!',\n",
       " 'terrorist',\n",
       " 'batt',\n",
       " 'msgticketkioskvalid',\n",
       " 'r',\n",
       " 'scalli',\n",
       " 'snowbal',\n",
       " 'chapter',\n",
       " 'mobno',\n",
       " 'victor',\n",
       " 'padhegm',\n",
       " 'ardé',\n",
       " 'raglan',\n",
       " 'day!find',\n",
       " 'mmmmmm',\n",
       " 'wahleykkumshar',\n",
       " 'sn',\n",
       " 'minimum',\n",
       " 'satü',\n",
       " 'arnt',\n",
       " 'nokiap',\n",
       " 'shine',\n",
       " 'gent!',\n",
       " 'httpcareer',\n",
       " 'httpgotbabescouk',\n",
       " 'fite',\n",
       " 'al',\n",
       " 'symbol',\n",
       " 'darkest',\n",
       " 'descript',\n",
       " 'sore',\n",
       " 'ijust',\n",
       " 'import',\n",
       " 'oga',\n",
       " 'want',\n",
       " 'anetwork',\n",
       " 'desert',\n",
       " 'arriv',\n",
       " 'beg',\n",
       " 'winner',\n",
       " 'yuo',\n",
       " 'album',\n",
       " 'saved!',\n",
       " 'profit',\n",
       " 'camera!',\n",
       " 'basq!ihav',\n",
       " 'sip',\n",
       " 'daysh',\n",
       " 'bloodi',\n",
       " 'wwwwincouk',\n",
       " 'wo',\n",
       " 'financ',\n",
       " 'dvg',\n",
       " 'gym',\n",
       " 'deyhop',\n",
       " 'disturbancemight',\n",
       " 'blastin',\n",
       " 'cu',\n",
       " 'incred',\n",
       " 'no',\n",
       " 'sandiago',\n",
       " 'clean',\n",
       " 'unconsci',\n",
       " 'videochat',\n",
       " 'yoyyooo',\n",
       " 'msgsd',\n",
       " 'ringtoneget',\n",
       " 'therel',\n",
       " 'absolut',\n",
       " 'freesend',\n",
       " 'wee',\n",
       " 'cooki',\n",
       " 'needa',\n",
       " 'moneeppolum',\n",
       " 'rummer',\n",
       " 'tonght',\n",
       " 'imag',\n",
       " 'wi',\n",
       " 'neededsalari',\n",
       " 'henri',\n",
       " 'pub',\n",
       " 'hands!',\n",
       " 'nyt',\n",
       " 'ted',\n",
       " 'ecus',\n",
       " 'spring',\n",
       " 'jsco',\n",
       " 'ambrithmaduraimet',\n",
       " 'chore',\n",
       " 'india',\n",
       " 'wahala',\n",
       " 'els',\n",
       " 'havnt',\n",
       " 'verifi',\n",
       " 'postpon',\n",
       " 'caroline!',\n",
       " 'pan',\n",
       " 'recognis',\n",
       " 'quiteamuz',\n",
       " 'westlif',\n",
       " 'am',\n",
       " 'youuuuu',\n",
       " 'bong',\n",
       " 'lyk',\n",
       " 'shouldnt',\n",
       " 'drivin',\n",
       " 'teju',\n",
       " 'kit',\n",
       " 'yeovil',\n",
       " 'goodmorningmi',\n",
       " 'onward',\n",
       " 'bat',\n",
       " 'noncomitt',\n",
       " 'rsi',\n",
       " 'urmomi',\n",
       " 'piss',\n",
       " 'prolli',\n",
       " 'human',\n",
       " 'stomp',\n",
       " 'ind',\n",
       " 'nalla',\n",
       " 'egbon',\n",
       " 'tiger',\n",
       " 'yellow',\n",
       " 'wallpaperal',\n",
       " 'legal',\n",
       " 'tyler',\n",
       " 'mist',\n",
       " 'record',\n",
       " 'countinlot',\n",
       " 'moralon',\n",
       " 'subscrib',\n",
       " 'blood',\n",
       " 'chikku',\n",
       " 'willpow',\n",
       " 'becom',\n",
       " 'take',\n",
       " 'rush',\n",
       " 'nbme',\n",
       " 'atyour',\n",
       " 'road',\n",
       " 'machin',\n",
       " 'ifink',\n",
       " 'dayecept',\n",
       " 'journey!',\n",
       " 'nearer',\n",
       " 'meowd',\n",
       " 'detroit',\n",
       " 'qing',\n",
       " 'planeti',\n",
       " 'minapn',\n",
       " 'drum',\n",
       " 'tip',\n",
       " 'oficegot',\n",
       " 'parco',\n",
       " 'ibuprofen',\n",
       " 'hon',\n",
       " 'could',\n",
       " 'wld',\n",
       " 'danc',\n",
       " 'agenc',\n",
       " 'western',\n",
       " 'pinku',\n",
       " 'dirti',\n",
       " 'home!',\n",
       " 'convers',\n",
       " 'lshb',\n",
       " 'jurong',\n",
       " 'velusami',\n",
       " 'love!!',\n",
       " 'clo',\n",
       " 'oblising',\n",
       " 'unsub',\n",
       " 'agent',\n",
       " 'abi!',\n",
       " 'pale',\n",
       " 'costma',\n",
       " 'batteri',\n",
       " 'easter',\n",
       " 'hwd',\n",
       " 'nìte',\n",
       " 'webpag',\n",
       " 'dirt',\n",
       " 'vai',\n",
       " 'kitti',\n",
       " 'subscriptngbpwk',\n",
       " 'ima',\n",
       " 'dude!',\n",
       " 'ts',\n",
       " 'cud',\n",
       " 'plenti',\n",
       " 'std',\n",
       " 'oktak',\n",
       " 'problm',\n",
       " 'avent',\n",
       " 'freenokia',\n",
       " 'sister',\n",
       " 'borderlin',\n",
       " 'bowa',\n",
       " 'shijutta',\n",
       " 'w',\n",
       " 'carso',\n",
       " 'toleratbc',\n",
       " 'babygoodby',\n",
       " 'reg',\n",
       " 'aiyah',\n",
       " 'art',\n",
       " 'yavnt',\n",
       " 'loveabl',\n",
       " 'technic',\n",
       " 'sup',\n",
       " 'backdoor',\n",
       " 'virgin',\n",
       " 'drpd',\n",
       " 'dear',\n",
       " 'finishd',\n",
       " 'getanth',\n",
       " 'evrey',\n",
       " 'hamster',\n",
       " 'conect',\n",
       " 'ikea',\n",
       " 'donno',\n",
       " 'hero',\n",
       " 'kgive',\n",
       " 'cock',\n",
       " 'haiyoh',\n",
       " 'gone',\n",
       " 'nosi',\n",
       " 'saw',\n",
       " 'med',\n",
       " 'breaker',\n",
       " 'ecept',\n",
       " 'ey!',\n",
       " 'squid!',\n",
       " 'kyou',\n",
       " 'optin',\n",
       " 'kay',\n",
       " 'wiv',\n",
       " 'sppok',\n",
       " 'soz',\n",
       " 'nojst',\n",
       " 'yar',\n",
       " 'munster',\n",
       " 'sumthin',\n",
       " 'web',\n",
       " 'telphon',\n",
       " 'tcsstop',\n",
       " 'cruel',\n",
       " 'depend',\n",
       " 'audrey',\n",
       " 'lauri',\n",
       " 'tiz',\n",
       " 'cat',\n",
       " 'studentfinanci',\n",
       " 'magic',\n",
       " 'b\\x92day',\n",
       " 'receivea',\n",
       " 'bcum',\n",
       " 'vinobanagar',\n",
       " 'kb',\n",
       " 'tomorrow',\n",
       " 'layin',\n",
       " 'baby!hop',\n",
       " 'specialis',\n",
       " 'thin',\n",
       " 'mypar',\n",
       " 'overdid',\n",
       " 'pictt',\n",
       " 'wrg',\n",
       " 'scenario',\n",
       " 'presenc',\n",
       " 'heygreat',\n",
       " 'gari',\n",
       " 'marley',\n",
       " 'tabl',\n",
       " 'fun!',\n",
       " 'associ',\n",
       " 'cuppa',\n",
       " 'wkg',\n",
       " 'mango',\n",
       " 'rakhesh',\n",
       " 'brb',\n",
       " 'pierr',\n",
       " 'amrca',\n",
       " 'thenwil',\n",
       " 'usml',\n",
       " 'lipo',\n",
       " 'kiosk',\n",
       " 'gbp',\n",
       " 'impos',\n",
       " 'ntt',\n",
       " 'boytoy',\n",
       " 'butt',\n",
       " 'fireplac',\n",
       " 'bonus!',\n",
       " 'lu',\n",
       " 'orc',\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "remv = sorted(list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "remv.remove('!')\n",
    "remv.remove('!!')\n",
    "remv.remove('!!!')\n",
    "remv.remove('!!!!')\n",
    "remv.remove('!thi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>',\n",
       " '<UNK>',\n",
       " 'aa',\n",
       " 'aah',\n",
       " 'aah!',\n",
       " 'aaniy',\n",
       " 'aaooooright',\n",
       " 'aathilov',\n",
       " 'aathiwher',\n",
       " 'ab',\n",
       " 'abbey!',\n",
       " 'abdomen',\n",
       " 'abeg',\n",
       " 'abelu',\n",
       " 'aberdeen',\n",
       " 'abi',\n",
       " 'abi!',\n",
       " 'abil',\n",
       " 'abiola',\n",
       " 'abj',\n",
       " 'abl',\n",
       " 'abnorm',\n",
       " 'about!',\n",
       " 'abouta',\n",
       " 'abroad',\n",
       " 'absenc',\n",
       " 'absolut',\n",
       " 'abstract',\n",
       " 'abt',\n",
       " 'abta',\n",
       " 'aburo',\n",
       " 'abus',\n",
       " 'ac',\n",
       " 'academ',\n",
       " 'acc',\n",
       " 'accent',\n",
       " 'accentur',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'access!',\n",
       " 'accid',\n",
       " 'accident',\n",
       " 'accommod',\n",
       " 'accommodationvouch',\n",
       " 'accomod',\n",
       " 'accordin',\n",
       " 'accordingli',\n",
       " 'accordinglyor',\n",
       " 'account',\n",
       " 'accumul',\n",
       " 'ach',\n",
       " 'achanammarakheshqatar',\n",
       " 'achiev',\n",
       " 'acid!',\n",
       " 'acknowledg',\n",
       " 'aclpm',\n",
       " 'acnt',\n",
       " 'acoentri',\n",
       " 'across',\n",
       " 'acsmsreward',\n",
       " 'act',\n",
       " 'actin',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'acwicmbcktzr!',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'addamsfa',\n",
       " 'addi',\n",
       " 'addict',\n",
       " 'address',\n",
       " 'addressul',\n",
       " 'adewal',\n",
       " 'adi',\n",
       " 'adjust',\n",
       " 'admin',\n",
       " 'administr',\n",
       " 'admir',\n",
       " 'admiss',\n",
       " 'admit',\n",
       " 'admiti',\n",
       " 'ador',\n",
       " 'adp',\n",
       " 'adress',\n",
       " 'adrian',\n",
       " 'adrink',\n",
       " 'adsens',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'adventur',\n",
       " 'advic',\n",
       " 'advis',\n",
       " 'advisor',\n",
       " 'ae',\n",
       " 'aeronaut',\n",
       " 'aeroplan',\n",
       " 'afew',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affection',\n",
       " 'affectionsamp',\n",
       " 'affidavit',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'aft',\n",
       " 'afternon',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'aftr',\n",
       " 'ag',\n",
       " 'again!',\n",
       " 'againcal',\n",
       " 'againlov',\n",
       " 'agalla',\n",
       " 'age',\n",
       " 'agenc',\n",
       " 'agent',\n",
       " 'ageppermesssubscript',\n",
       " 'agesr',\n",
       " 'agidhan',\n",
       " 'ago',\n",
       " 'agocusoon',\n",
       " 'agre',\n",
       " 'agreen',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahge',\n",
       " 'ahhh',\n",
       " 'ahhhhjust',\n",
       " 'ahmad',\n",
       " 'ahnow',\n",
       " 'ahold',\n",
       " 'ahsen',\n",
       " 'ahth',\n",
       " 'ahwhat',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aig',\n",
       " 'aight',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'airtel',\n",
       " 'aiya',\n",
       " 'aiyah',\n",
       " 'aiyar',\n",
       " 'aiyo',\n",
       " 'aj',\n",
       " 'ajith',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akonlon',\n",
       " 'al',\n",
       " 'al!!!!!!!!!',\n",
       " 'alaikkumprid',\n",
       " 'alaipayuth',\n",
       " 'albi',\n",
       " 'album',\n",
       " 'albumquit',\n",
       " 'alcohol',\n",
       " 'aldrin',\n",
       " 'ale',\n",
       " 'alert',\n",
       " 'alert!',\n",
       " 'alertfrom',\n",
       " 'alett',\n",
       " 'alfi',\n",
       " 'algarv',\n",
       " 'algebra',\n",
       " 'algorithm',\n",
       " 'ali',\n",
       " 'alian',\n",
       " 'alibi',\n",
       " 'aliv',\n",
       " 'alivebett',\n",
       " 'all',\n",
       " 'allah',\n",
       " 'allahmeet',\n",
       " 'allahrakhesh',\n",
       " 'allalo',\n",
       " 'allday!',\n",
       " 'allo!',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'along!',\n",
       " 'alot',\n",
       " 'alreadi',\n",
       " 'alreadysabarish',\n",
       " 'alright',\n",
       " 'alrightokay',\n",
       " 'alrit',\n",
       " 'alritehav',\n",
       " 'also',\n",
       " 'alsoor',\n",
       " 'alter',\n",
       " 'alternativehop',\n",
       " 'although',\n",
       " 'alwa!!',\n",
       " 'alway',\n",
       " 'alwi',\n",
       " 'am',\n",
       " 'am!!',\n",
       " 'amanda',\n",
       " 'amaz',\n",
       " 'ambiti',\n",
       " 'ambrithmaduraimet',\n",
       " 'american',\n",
       " 'ami',\n",
       " 'amigo',\n",
       " 'amk',\n",
       " 'ammaelif',\n",
       " 'ammo',\n",
       " 'amnow',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amor',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amplikat',\n",
       " 'ampm',\n",
       " 'amrca',\n",
       " 'amrita',\n",
       " 'amt',\n",
       " 'amus',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anal',\n",
       " 'analysi',\n",
       " 'anand',\n",
       " 'anderson',\n",
       " 'andor',\n",
       " 'andr',\n",
       " 'andrewsboy',\n",
       " 'andro',\n",
       " 'anetwork',\n",
       " 'angel',\n",
       " 'angri',\n",
       " 'anim',\n",
       " 'animal!',\n",
       " 'anjie!',\n",
       " 'anjola',\n",
       " 'anna',\n",
       " 'anni',\n",
       " 'annie!',\n",
       " 'anniversari',\n",
       " 'annonc',\n",
       " 'announc',\n",
       " 'annoy',\n",
       " 'annoyin!',\n",
       " 'anonym',\n",
       " 'anot',\n",
       " 'anoth',\n",
       " 'ansr',\n",
       " 'answer',\n",
       " 'answerin',\n",
       " 'answr',\n",
       " 'antelop',\n",
       " 'anthoni',\n",
       " 'anti',\n",
       " 'antibiot',\n",
       " 'anybodi',\n",
       " 'anyhow',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyplac',\n",
       " 'anyth',\n",
       " 'anythi',\n",
       " 'anythin',\n",
       " 'anything!',\n",
       " 'anythingtomorrow',\n",
       " 'anytim',\n",
       " 'anyway',\n",
       " 'anywher',\n",
       " 'aom',\n",
       " 'apart',\n",
       " 'ape',\n",
       " 'apeshit',\n",
       " 'aphe\\x92',\n",
       " 'apnt',\n",
       " 'apo',\n",
       " 'apolog',\n",
       " 'apologet',\n",
       " 'apologis',\n",
       " 'app',\n",
       " 'appar',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appendi',\n",
       " 'appi',\n",
       " 'applebe',\n",
       " 'appledayno',\n",
       " 'applespairsal',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appoint',\n",
       " 'appreci',\n",
       " 'appro',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approv',\n",
       " 'appt',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'aproach',\n",
       " 'apt',\n",
       " 'aptitud',\n",
       " 'aquariu',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabian',\n",
       " 'arcad',\n",
       " 'archiv',\n",
       " 'ard',\n",
       " 'ardé',\n",
       " 'area',\n",
       " 'area!',\n",
       " 'arent',\n",
       " 'arestaur',\n",
       " 'aretak',\n",
       " 'argentina',\n",
       " 'argh',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'ari',\n",
       " 'aris',\n",
       " 'arithmet',\n",
       " 'arm',\n",
       " 'armand',\n",
       " 'armenia',\n",
       " 'arng',\n",
       " 'arngd',\n",
       " 'arnt',\n",
       " 'around',\n",
       " 'around!',\n",
       " 'aroundn',\n",
       " 'arpraveesh',\n",
       " 'arr',\n",
       " 'arrang',\n",
       " 'arrest',\n",
       " 'arriv',\n",
       " 'arrow',\n",
       " 'arsen',\n",
       " 'art',\n",
       " 'art!',\n",
       " 'arti',\n",
       " 'artist',\n",
       " 'arul',\n",
       " 'arun',\n",
       " 'asa',\n",
       " 'asap',\n",
       " 'asap!',\n",
       " 'asapok',\n",
       " 'asda',\n",
       " 'ash',\n",
       " 'ashley',\n",
       " 'ashwini',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'ask',\n",
       " 'askd',\n",
       " 'askin',\n",
       " 'aslamalaikkuminsha',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'ass',\n",
       " 'ass!',\n",
       " 'ass!!',\n",
       " 'assess',\n",
       " 'asshol',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'assum',\n",
       " 'asther',\n",
       " 'asthma',\n",
       " 'astn',\n",
       " 'astoundingli',\n",
       " 'astrolog',\n",
       " 'astronom',\n",
       " 'asu',\n",
       " 'asusual!',\n",
       " 'at!',\n",
       " 'ate',\n",
       " 'athlet',\n",
       " 'athom',\n",
       " 'atlanta',\n",
       " 'atlast',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'atroci',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'atten',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attitud',\n",
       " 'attract',\n",
       " 'attractioni',\n",
       " 'attribut',\n",
       " 'atyour',\n",
       " 'auction',\n",
       " 'auctionpunj',\n",
       " 'audiit',\n",
       " 'audit',\n",
       " 'audrey',\n",
       " 'audri',\n",
       " 'august',\n",
       " 'august!',\n",
       " 'aunt',\n",
       " 'aunti',\n",
       " 'aunty!',\n",
       " 'aust',\n",
       " 'australia',\n",
       " 'authoris',\n",
       " 'auto',\n",
       " 'autocorrect',\n",
       " 'av',\n",
       " 'ava',\n",
       " 'avail',\n",
       " 'availa',\n",
       " 'available!',\n",
       " 'availablei',\n",
       " 'availablethey',\n",
       " 'avalarr',\n",
       " 'avatar',\n",
       " 'avbl',\n",
       " 'ave',\n",
       " 'aveng',\n",
       " 'avent',\n",
       " 'avenu',\n",
       " 'avier',\n",
       " 'avin',\n",
       " 'avo',\n",
       " 'avoid',\n",
       " 'await',\n",
       " 'awak',\n",
       " 'award',\n",
       " 'award!',\n",
       " 'away',\n",
       " 'away!!',\n",
       " 'awesom',\n",
       " 'awkward',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'ay',\n",
       " 'ayn',\n",
       " 'ayo',\n",
       " 'b',\n",
       " 'ba',\n",
       " 'baaaaaaaabe!',\n",
       " 'baaaaabe!',\n",
       " 'babe',\n",
       " 'babe!',\n",
       " 'babeprobpop',\n",
       " 'babesozi',\n",
       " 'babi',\n",
       " 'babies!',\n",
       " 'baby!',\n",
       " 'baby!hop',\n",
       " 'babygoodby',\n",
       " 'babyjontet!',\n",
       " 'babysit',\n",
       " 'bac',\n",
       " 'back',\n",
       " 'back!',\n",
       " 'backa',\n",
       " 'backdoor',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bad!',\n",
       " 'badass',\n",
       " 'badli',\n",
       " 'badrith',\n",
       " 'bag',\n",
       " 'bagi',\n",
       " 'bahama',\n",
       " 'bahamas!',\n",
       " 'baig',\n",
       " 'bailiff',\n",
       " 'bajarangabali',\n",
       " 'bak',\n",
       " 'bak!',\n",
       " 'bakra',\n",
       " 'bakrid!',\n",
       " 'balanc',\n",
       " 'ball',\n",
       " 'baller',\n",
       " 'balloon!',\n",
       " 'bam',\n",
       " 'bambl',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bandag',\n",
       " 'bang',\n",
       " 'bangb',\n",
       " 'bangbab',\n",
       " 'bani',\n",
       " 'bank',\n",
       " 'banneduk',\n",
       " 'bannfwflyppm',\n",
       " 'banter',\n",
       " 'bao',\n",
       " 'bar',\n",
       " 'barbi',\n",
       " 'barcelona',\n",
       " 'bare',\n",
       " 'bari',\n",
       " 'barkley',\n",
       " 'barm',\n",
       " 'barolla',\n",
       " 'barrel',\n",
       " 'barri',\n",
       " 'base',\n",
       " 'bash',\n",
       " 'basic',\n",
       " 'basket',\n",
       " 'basketbal',\n",
       " 'basq!ihav',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'batch!',\n",
       " 'batchlor',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batsman',\n",
       " 'batt',\n",
       " 'batteri',\n",
       " 'battl',\n",
       " 'bawl',\n",
       " 'bay',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bbdelu',\n",
       " 'bbdpooja',\n",
       " 'bbdtht',\n",
       " 'bblue',\n",
       " 'bbq',\n",
       " 'bc',\n",
       " 'bcaz',\n",
       " 'bck',\n",
       " 'bcm',\n",
       " 'bcmsfwcn',\n",
       " 'bcmwcn',\n",
       " 'bcoz',\n",
       " 'bcozi',\n",
       " 'bcum',\n",
       " 'bcz',\n",
       " 'bday',\n",
       " 'beach',\n",
       " 'bead',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beauti',\n",
       " 'beautifulmay',\n",
       " 'bec',\n",
       " 'becau',\n",
       " 'becausethey',\n",
       " 'becom',\n",
       " 'becoz',\n",
       " 'becz',\n",
       " 'bed',\n",
       " 'bed!',\n",
       " 'bedbut',\n",
       " 'bedreal',\n",
       " 'bedrm',\n",
       " 'bedroom',\n",
       " 'bedroom!lov',\n",
       " 'beeen',\n",
       " 'beehoon',\n",
       " 'beendrop',\n",
       " 'beer',\n",
       " 'beerag',\n",
       " 'beerr',\n",
       " 'befor',\n",
       " 'beforehand',\n",
       " 'beforew',\n",
       " 'beg',\n",
       " 'beggar',\n",
       " 'begin',\n",
       " 'begun',\n",
       " 'behalf',\n",
       " 'behav',\n",
       " 'behind',\n",
       " 'bein',\n",
       " 'believ',\n",
       " 'beliv',\n",
       " 'bell',\n",
       " 'bellearli',\n",
       " 'belli',\n",
       " 'belliger',\n",
       " 'belong',\n",
       " 'belov',\n",
       " 'belovd',\n",
       " 'belt',\n",
       " 'ben',\n",
       " 'bend',\n",
       " 'beneath',\n",
       " 'beneficiari',\n",
       " 'benefit',\n",
       " 'benni',\n",
       " 'bergkamp',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'bestcongrat',\n",
       " 'bestrpli',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'beth',\n",
       " 'betta',\n",
       " 'better',\n",
       " 'bettersn',\n",
       " 'beverag',\n",
       " 'bevieswaz',\n",
       " 'bewar',\n",
       " 'beware!',\n",
       " 'beyond',\n",
       " 'bf',\n",
       " 'bff',\n",
       " 'bfore',\n",
       " 'bhaskar',\n",
       " 'bhayandar',\n",
       " 'bian',\n",
       " 'biatch!',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'big!',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bill',\n",
       " 'billi',\n",
       " 'billion',\n",
       " 'bilo',\n",
       " 'bimbo',\n",
       " 'bin',\n",
       " 'biola',\n",
       " 'bipw',\n",
       " 'bird',\n",
       " 'bird!',\n",
       " 'birla',\n",
       " 'biro',\n",
       " 'birth',\n",
       " 'birthdat',\n",
       " 'birthday',\n",
       " 'bishan',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'biz',\n",
       " 'bk',\n",
       " 'black',\n",
       " 'blackand',\n",
       " 'blackberri',\n",
       " 'blackim',\n",
       " 'blacko',\n",
       " 'blah',\n",
       " 'blake',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blastin',\n",
       " 'bleak',\n",
       " 'bleh',\n",
       " 'bless',\n",
       " 'bless!',\n",
       " 'blessget',\n",
       " 'blessings!',\n",
       " 'blimey',\n",
       " 'blind',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'bloke',\n",
       " 'blond',\n",
       " 'bloo',\n",
       " 'blood',\n",
       " 'bloodblood',\n",
       " 'bloodi',\n",
       " 'bloodsend',\n",
       " 'bloomberg',\n",
       " 'bloombergcom',\n",
       " 'blow',\n",
       " 'blown',\n",
       " 'blu',\n",
       " 'blue',\n",
       " 'bluetooth',\n",
       " 'bluetooth!',\n",
       " 'bluetoothhdset',\n",
       " 'blueu',\n",
       " 'bluff',\n",
       " 'blur',\n",
       " 'bluray',\n",
       " 'bmw',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'boatin',\n",
       " 'bob',\n",
       " 'bocpm',\n",
       " 'bodi',\n",
       " 'body!!',\n",
       " 'boggi',\n",
       " 'bognor',\n",
       " 'bold',\n",
       " 'bollo',\n",
       " 'boltblu',\n",
       " 'bom',\n",
       " 'bomb',\n",
       " 'bone',\n",
       " 'bong',\n",
       " 'bonqp',\n",
       " 'bonu',\n",
       " 'bonus!',\n",
       " 'boo',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'bookedth',\n",
       " 'bookmark',\n",
       " 'bookshelf',\n",
       " 'boooo',\n",
       " 'boost',\n",
       " 'booti',\n",
       " 'bootydeli',\n",
       " 'boqu',\n",
       " 'borderlin',\n",
       " 'bore',\n",
       " 'bored!',\n",
       " 'borin',\n",
       " 'boring!',\n",
       " 'born',\n",
       " 'born!',\n",
       " 'bornpleas',\n",
       " 'borrow',\n",
       " 'boskch',\n",
       " 'boskwpppm',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'both!',\n",
       " 'bother',\n",
       " 'bottl',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bought\\x94braindance\\x94a',\n",
       " 'boundari',\n",
       " 'bout',\n",
       " 'bout!',\n",
       " 'bowa',\n",
       " 'bowl',\n",
       " 'bowrc',\n",
       " 'boy',\n",
       " 'boyf',\n",
       " 'boyfriend',\n",
       " 'boyi',\n",
       " 'boytoy',\n",
       " 'boytoy!',\n",
       " 'bpo',\n",
       " 'bra',\n",
       " 'brah',\n",
       " 'brain',\n",
       " 'braini',\n",
       " 'brainless',\n",
       " 'brand',\n",
       " 'brandi',\n",
       " 'brat',\n",
       " 'brave',\n",
       " 'bray',\n",
       " 'brb',\n",
       " 'brdget',\n",
       " 'bread',\n",
       " 'breadstick',\n",
       " 'break',\n",
       " 'breaker',\n",
       " 'breakfast',\n",
       " 'breakin',\n",
       " 'breath',\n",
       " 'breather',\n",
       " 'breez',\n",
       " 'breezi',\n",
       " 'brekkie!',\n",
       " 'bribe',\n",
       " 'bridg',\n",
       " 'bridgwat',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brighten',\n",
       " 'brilliant',\n",
       " 'brilliantli',\n",
       " 'brilliantthingi',\n",
       " 'brin',\n",
       " 'bring',\n",
       " 'brisk',\n",
       " 'brison',\n",
       " 'bristol',\n",
       " 'british',\n",
       " 'britney',\n",
       " 'bro',\n",
       " 'broad',\n",
       " 'broadband',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brolli',\n",
       " 'broth',\n",
       " 'brotha',\n",
       " 'brother',\n",
       " 'brother‘',\n",
       " 'brought',\n",
       " 'browni',\n",
       " 'brows',\n",
       " 'browser',\n",
       " 'browsin',\n",
       " 'bruce',\n",
       " 'brum!',\n",
       " 'bruv',\n",
       " 'bruv!',\n",
       " 'bslvyl',\n",
       " 'bsn',\n",
       " 'bsnl',\n",
       " 'bstfrnd',\n",
       " 'bt',\n",
       " 'bthere',\n",
       " 'bthmm',\n",
       " 'btnation',\n",
       " 'btnationalr',\n",
       " 'btooth',\n",
       " 'btw',\n",
       " 'btwn',\n",
       " 'bu',\n",
       " 'buck',\n",
       " 'bud',\n",
       " 'buddi',\n",
       " 'buddy!!',\n",
       " 'budget',\n",
       " 'buen',\n",
       " 'buff',\n",
       " 'buffet',\n",
       " 'buffi',\n",
       " 'bugi',\n",
       " 'build',\n",
       " 'built',\n",
       " 'bulb',\n",
       " 'bull',\n",
       " 'bullshit',\n",
       " 'bun',\n",
       " 'bunch',\n",
       " 'bundl',\n",
       " 'bunker',\n",
       " 'buns!',\n",
       " 'burden',\n",
       " 'burger',\n",
       " 'burgundi',\n",
       " 'burial',\n",
       " 'burn',\n",
       " 'burnt',\n",
       " 'burrito',\n",
       " 'bus!',\n",
       " 'buse',\n",
       " 'busetop',\n",
       " 'busi',\n",
       " 'busti',\n",
       " 'busyi',\n",
       " 'but',\n",
       " 'butt',\n",
       " 'butther',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buyer',\n",
       " 'buz',\n",
       " 'buzi',\n",
       " 'buzz',\n",
       " 'buzz!',\n",
       " 'buzzzz!',\n",
       " 'bw',\n",
       " 'byatch',\n",
       " 'bye',\n",
       " 'by\\x94leafcutt',\n",
       " 'b\\x92day',\n",
       " 'b‘ham',\n",
       " 'c',\n",
       " 'c!',\n",
       " 'cab',\n",
       " 'cabin',\n",
       " 'cabl',\n",
       " 'cafe',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'caken',\n",
       " 'cal',\n",
       " 'calcul',\n",
       " 'cali',\n",
       " 'calicut',\n",
       " 'california',\n",
       " 'call',\n",
       " 'callback',\n",
       " 'callcost',\n",
       " 'callcoz',\n",
       " 'calld',\n",
       " 'calldrov',\n",
       " 'caller',\n",
       " 'callertun',\n",
       " 'callfreefon',\n",
       " 'callin',\n",
       " 'calling!',\n",
       " 'callingforgot',\n",
       " 'callon',\n",
       " 'calloptout',\n",
       " 'calloptout!yhl',\n",
       " 'calloptoutfq',\n",
       " 'calloptouthf',\n",
       " 'calloptoutj',\n",
       " 'calloptoutjq',\n",
       " 'calloptoutlf',\n",
       " 'calloptoutnd',\n",
       " 'calloptoutqf',\n",
       " 'calls!',\n",
       " 'callsmessagesmiss',\n",
       " 'callsminmobsmor',\n",
       " 'callsminmobsmorelkpobohpfl',\n",
       " 'callsminmoremobsemspobopowa',\n",
       " 'callsppm',\n",
       " 'callurg',\n",
       " 'calm',\n",
       " 'cam',\n",
       " 'camcord',\n",
       " 'came',\n",
       " 'came!',\n",
       " 'camera',\n",
       " 'camera!',\n",
       " 'cameravideo',\n",
       " 'camp',\n",
       " 'campu',\n",
       " 'camri',\n",
       " 'canada',\n",
       " 'canal',\n",
       " 'canari',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candont',\n",
       " 'canlov',\n",
       " 'cannam',\n",
       " 'cannot',\n",
       " 'cannt',\n",
       " 'cant',\n",
       " 'cantdo',\n",
       " 'canteen',\n",
       " 'can\\x92t',\n",
       " 'can‘t',\n",
       " 'cap',\n",
       " 'capac',\n",
       " 'capit',\n",
       " 'cappuccino',\n",
       " 'captain',\n",
       " 'car',\n",
       " 'card',\n",
       " 'card!',\n",
       " 'cardiff',\n",
       " 'cardin',\n",
       " 'care',\n",
       " 'care!',\n",
       " 'careabout',\n",
       " 'career',\n",
       " 'careful!',\n",
       " 'careinsha',\n",
       " 'careless',\n",
       " 'carent',\n",
       " 'careswt',\n",
       " 'careumma',\n",
       " 'carewhoev',\n",
       " 'carli',\n",
       " 'carlin',\n",
       " 'carlo',\n",
       " 'carlosl',\n",
       " 'carolin',\n",
       " 'carolina',\n",
       " 'caroline!',\n",
       " 'carpark',\n",
       " 'carri',\n",
       " 'carryin',\n",
       " 'carso',\n",
       " 'carton',\n",
       " 'cartoon',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cash!',\n",
       " 'cashbal',\n",
       " 'cashbincouk',\n",
       " 'cashin',\n",
       " 'cashto',\n",
       " 'cast',\n",
       " 'castor',\n",
       " 'casualti',\n",
       " 'cat',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<UNK>': 1,\n",
       " 'aa': 2,\n",
       " 'aah': 3,\n",
       " 'aah!': 4,\n",
       " 'aaniy': 5,\n",
       " 'aaooooright': 6,\n",
       " 'aathilov': 7,\n",
       " 'aathiwher': 8,\n",
       " 'ab': 9,\n",
       " 'abbey!': 10,\n",
       " 'abdomen': 11,\n",
       " 'abeg': 12,\n",
       " 'abelu': 13,\n",
       " 'aberdeen': 14,\n",
       " 'abi': 15,\n",
       " 'abi!': 16,\n",
       " 'abil': 17,\n",
       " 'abiola': 18,\n",
       " 'abj': 19,\n",
       " 'abl': 20,\n",
       " 'abnorm': 21,\n",
       " 'about!': 22,\n",
       " 'abouta': 23,\n",
       " 'abroad': 24,\n",
       " 'absenc': 25,\n",
       " 'absolut': 26,\n",
       " 'abstract': 27,\n",
       " 'abt': 28,\n",
       " 'abta': 29,\n",
       " 'aburo': 30,\n",
       " 'abus': 31,\n",
       " 'ac': 32,\n",
       " 'academ': 33,\n",
       " 'acc': 34,\n",
       " 'accent': 35,\n",
       " 'accentur': 36,\n",
       " 'accept': 37,\n",
       " 'access': 38,\n",
       " 'access!': 39,\n",
       " 'accid': 40,\n",
       " 'accident': 41,\n",
       " 'accommod': 42,\n",
       " 'accommodationvouch': 43,\n",
       " 'accomod': 44,\n",
       " 'accordin': 45,\n",
       " 'accordingli': 46,\n",
       " 'accordinglyor': 47,\n",
       " 'account': 48,\n",
       " 'accumul': 49,\n",
       " 'ach': 50,\n",
       " 'achanammarakheshqatar': 51,\n",
       " 'achiev': 52,\n",
       " 'acid!': 53,\n",
       " 'acknowledg': 54,\n",
       " 'aclpm': 55,\n",
       " 'acnt': 56,\n",
       " 'acoentri': 57,\n",
       " 'across': 58,\n",
       " 'acsmsreward': 59,\n",
       " 'act': 60,\n",
       " 'actin': 61,\n",
       " 'action': 62,\n",
       " 'activ': 63,\n",
       " 'actor': 64,\n",
       " 'actual': 65,\n",
       " 'acwicmbcktzr!': 66,\n",
       " 'ad': 67,\n",
       " 'adam': 68,\n",
       " 'add': 69,\n",
       " 'addamsfa': 70,\n",
       " 'addi': 71,\n",
       " 'addict': 72,\n",
       " 'address': 73,\n",
       " 'addressul': 74,\n",
       " 'adewal': 75,\n",
       " 'adi': 76,\n",
       " 'adjust': 77,\n",
       " 'admin': 78,\n",
       " 'administr': 79,\n",
       " 'admir': 80,\n",
       " 'admiss': 81,\n",
       " 'admit': 82,\n",
       " 'admiti': 83,\n",
       " 'ador': 84,\n",
       " 'adp': 85,\n",
       " 'adress': 86,\n",
       " 'adrian': 87,\n",
       " 'adrink': 88,\n",
       " 'adsens': 89,\n",
       " 'adult': 90,\n",
       " 'advanc': 91,\n",
       " 'adventur': 92,\n",
       " 'advic': 93,\n",
       " 'advis': 94,\n",
       " 'advisor': 95,\n",
       " 'ae': 96,\n",
       " 'aeronaut': 97,\n",
       " 'aeroplan': 98,\n",
       " 'afew': 99,\n",
       " 'affair': 100,\n",
       " 'affect': 101,\n",
       " 'affection': 102,\n",
       " 'affectionsamp': 103,\n",
       " 'affidavit': 104,\n",
       " 'afford': 105,\n",
       " 'afghanistan': 106,\n",
       " 'afraid': 107,\n",
       " 'africa': 108,\n",
       " 'african': 109,\n",
       " 'aft': 110,\n",
       " 'afternon': 111,\n",
       " 'afternoon': 112,\n",
       " 'afterward': 113,\n",
       " 'aftr': 114,\n",
       " 'ag': 115,\n",
       " 'again!': 116,\n",
       " 'againcal': 117,\n",
       " 'againlov': 118,\n",
       " 'agalla': 119,\n",
       " 'age': 120,\n",
       " 'agenc': 121,\n",
       " 'agent': 122,\n",
       " 'ageppermesssubscript': 123,\n",
       " 'agesr': 124,\n",
       " 'agidhan': 125,\n",
       " 'ago': 126,\n",
       " 'agocusoon': 127,\n",
       " 'agre': 128,\n",
       " 'agreen': 129,\n",
       " 'ah': 130,\n",
       " 'aha': 131,\n",
       " 'ahead': 132,\n",
       " 'ahge': 133,\n",
       " 'ahhh': 134,\n",
       " 'ahhhhjust': 135,\n",
       " 'ahmad': 136,\n",
       " 'ahnow': 137,\n",
       " 'ahold': 138,\n",
       " 'ahsen': 139,\n",
       " 'ahth': 140,\n",
       " 'ahwhat': 141,\n",
       " 'ai': 142,\n",
       " 'aid': 143,\n",
       " 'aig': 144,\n",
       " 'aight': 145,\n",
       " 'aint': 146,\n",
       " 'air': 147,\n",
       " 'airport': 148,\n",
       " 'airtel': 149,\n",
       " 'aiya': 150,\n",
       " 'aiyah': 151,\n",
       " 'aiyar': 152,\n",
       " 'aiyo': 153,\n",
       " 'aj': 154,\n",
       " 'ajith': 155,\n",
       " 'ak': 156,\n",
       " 'aka': 157,\n",
       " 'akonlon': 158,\n",
       " 'al': 159,\n",
       " 'al!!!!!!!!!': 160,\n",
       " 'alaikkumprid': 161,\n",
       " 'alaipayuth': 162,\n",
       " 'albi': 163,\n",
       " 'album': 164,\n",
       " 'albumquit': 165,\n",
       " 'alcohol': 166,\n",
       " 'aldrin': 167,\n",
       " 'ale': 168,\n",
       " 'alert': 169,\n",
       " 'alert!': 170,\n",
       " 'alertfrom': 171,\n",
       " 'alett': 172,\n",
       " 'alfi': 173,\n",
       " 'algarv': 174,\n",
       " 'algebra': 175,\n",
       " 'algorithm': 176,\n",
       " 'ali': 177,\n",
       " 'alian': 178,\n",
       " 'alibi': 179,\n",
       " 'aliv': 180,\n",
       " 'alivebett': 181,\n",
       " 'all': 182,\n",
       " 'allah': 183,\n",
       " 'allahmeet': 184,\n",
       " 'allahrakhesh': 185,\n",
       " 'allalo': 186,\n",
       " 'allday!': 187,\n",
       " 'allo!': 188,\n",
       " 'allow': 189,\n",
       " 'almost': 190,\n",
       " 'alon': 191,\n",
       " 'along': 192,\n",
       " 'along!': 193,\n",
       " 'alot': 194,\n",
       " 'alreadi': 195,\n",
       " 'alreadysabarish': 196,\n",
       " 'alright': 197,\n",
       " 'alrightokay': 198,\n",
       " 'alrit': 199,\n",
       " 'alritehav': 200,\n",
       " 'also': 201,\n",
       " 'alsoor': 202,\n",
       " 'alter': 203,\n",
       " 'alternativehop': 204,\n",
       " 'although': 205,\n",
       " 'alwa!!': 206,\n",
       " 'alway': 207,\n",
       " 'alwi': 208,\n",
       " 'am': 209,\n",
       " 'am!!': 210,\n",
       " 'amanda': 211,\n",
       " 'amaz': 212,\n",
       " 'ambiti': 213,\n",
       " 'ambrithmaduraimet': 214,\n",
       " 'american': 215,\n",
       " 'ami': 216,\n",
       " 'amigo': 217,\n",
       " 'amk': 218,\n",
       " 'ammaelif': 219,\n",
       " 'ammo': 220,\n",
       " 'amnow': 221,\n",
       " 'among': 222,\n",
       " 'amongst': 223,\n",
       " 'amor': 224,\n",
       " 'amount': 225,\n",
       " 'amp': 226,\n",
       " 'amplikat': 227,\n",
       " 'ampm': 228,\n",
       " 'amrca': 229,\n",
       " 'amrita': 230,\n",
       " 'amt': 231,\n",
       " 'amus': 232,\n",
       " 'an': 233,\n",
       " 'ana': 234,\n",
       " 'anal': 235,\n",
       " 'analysi': 236,\n",
       " 'anand': 237,\n",
       " 'anderson': 238,\n",
       " 'andor': 239,\n",
       " 'andr': 240,\n",
       " 'andrewsboy': 241,\n",
       " 'andro': 242,\n",
       " 'anetwork': 243,\n",
       " 'angel': 244,\n",
       " 'angri': 245,\n",
       " 'anim': 246,\n",
       " 'animal!': 247,\n",
       " 'anjie!': 248,\n",
       " 'anjola': 249,\n",
       " 'anna': 250,\n",
       " 'anni': 251,\n",
       " 'annie!': 252,\n",
       " 'anniversari': 253,\n",
       " 'annonc': 254,\n",
       " 'announc': 255,\n",
       " 'annoy': 256,\n",
       " 'annoyin!': 257,\n",
       " 'anonym': 258,\n",
       " 'anot': 259,\n",
       " 'anoth': 260,\n",
       " 'ansr': 261,\n",
       " 'answer': 262,\n",
       " 'answerin': 263,\n",
       " 'answr': 264,\n",
       " 'antelop': 265,\n",
       " 'anthoni': 266,\n",
       " 'anti': 267,\n",
       " 'antibiot': 268,\n",
       " 'anybodi': 269,\n",
       " 'anyhow': 270,\n",
       " 'anymor': 271,\n",
       " 'anyon': 272,\n",
       " 'anyplac': 273,\n",
       " 'anyth': 274,\n",
       " 'anythi': 275,\n",
       " 'anythin': 276,\n",
       " 'anything!': 277,\n",
       " 'anythingtomorrow': 278,\n",
       " 'anytim': 279,\n",
       " 'anyway': 280,\n",
       " 'anywher': 281,\n",
       " 'aom': 282,\n",
       " 'apart': 283,\n",
       " 'ape': 284,\n",
       " 'apeshit': 285,\n",
       " 'aphe\\x92': 286,\n",
       " 'apnt': 287,\n",
       " 'apo': 288,\n",
       " 'apolog': 289,\n",
       " 'apologet': 290,\n",
       " 'apologis': 291,\n",
       " 'app': 292,\n",
       " 'appar': 293,\n",
       " 'appeal': 294,\n",
       " 'appear': 295,\n",
       " 'appendi': 296,\n",
       " 'appi': 297,\n",
       " 'applebe': 298,\n",
       " 'appledayno': 299,\n",
       " 'applespairsal': 300,\n",
       " 'appli': 301,\n",
       " 'applic': 302,\n",
       " 'appoint': 303,\n",
       " 'appreci': 304,\n",
       " 'appro': 305,\n",
       " 'approach': 306,\n",
       " 'appropri': 307,\n",
       " 'approv': 308,\n",
       " 'appt': 309,\n",
       " 'apr': 310,\n",
       " 'april': 311,\n",
       " 'aproach': 312,\n",
       " 'apt': 313,\n",
       " 'aptitud': 314,\n",
       " 'aquariu': 315,\n",
       " 'ar': 316,\n",
       " 'arab': 317,\n",
       " 'arabian': 318,\n",
       " 'arcad': 319,\n",
       " 'archiv': 320,\n",
       " 'ard': 321,\n",
       " 'ardé': 322,\n",
       " 'area': 323,\n",
       " 'area!': 324,\n",
       " 'arent': 325,\n",
       " 'arestaur': 326,\n",
       " 'aretak': 327,\n",
       " 'argentina': 328,\n",
       " 'argh': 329,\n",
       " 'argu': 330,\n",
       " 'argument': 331,\n",
       " 'ari': 332,\n",
       " 'aris': 333,\n",
       " 'arithmet': 334,\n",
       " 'arm': 335,\n",
       " 'armand': 336,\n",
       " 'armenia': 337,\n",
       " 'arng': 338,\n",
       " 'arngd': 339,\n",
       " 'arnt': 340,\n",
       " 'around': 341,\n",
       " 'around!': 342,\n",
       " 'aroundn': 343,\n",
       " 'arpraveesh': 344,\n",
       " 'arr': 345,\n",
       " 'arrang': 346,\n",
       " 'arrest': 347,\n",
       " 'arriv': 348,\n",
       " 'arrow': 349,\n",
       " 'arsen': 350,\n",
       " 'art': 351,\n",
       " 'art!': 352,\n",
       " 'arti': 353,\n",
       " 'artist': 354,\n",
       " 'arul': 355,\n",
       " 'arun': 356,\n",
       " 'asa': 357,\n",
       " 'asap': 358,\n",
       " 'asap!': 359,\n",
       " 'asapok': 360,\n",
       " 'asda': 361,\n",
       " 'ash': 362,\n",
       " 'ashley': 363,\n",
       " 'ashwini': 364,\n",
       " 'asia': 365,\n",
       " 'asian': 366,\n",
       " 'ask': 367,\n",
       " 'askd': 368,\n",
       " 'askin': 369,\n",
       " 'aslamalaikkuminsha': 370,\n",
       " 'asleep': 371,\n",
       " 'aspect': 372,\n",
       " 'ass': 373,\n",
       " 'ass!': 374,\n",
       " 'ass!!': 375,\n",
       " 'assess': 376,\n",
       " 'asshol': 377,\n",
       " 'assist': 378,\n",
       " 'associ': 379,\n",
       " 'assum': 380,\n",
       " 'asther': 381,\n",
       " 'asthma': 382,\n",
       " 'astn': 383,\n",
       " 'astoundingli': 384,\n",
       " 'astrolog': 385,\n",
       " 'astronom': 386,\n",
       " 'asu': 387,\n",
       " 'asusual!': 388,\n",
       " 'at!': 389,\n",
       " 'ate': 390,\n",
       " 'athlet': 391,\n",
       " 'athom': 392,\n",
       " 'atlanta': 393,\n",
       " 'atlast': 394,\n",
       " 'atleast': 395,\n",
       " 'atm': 396,\n",
       " 'atroci': 397,\n",
       " 'attach': 398,\n",
       " 'attack': 399,\n",
       " 'attempt': 400,\n",
       " 'atten': 401,\n",
       " 'attend': 402,\n",
       " 'attent': 403,\n",
       " 'attitud': 404,\n",
       " 'attract': 405,\n",
       " 'attractioni': 406,\n",
       " 'attribut': 407,\n",
       " 'atyour': 408,\n",
       " 'auction': 409,\n",
       " 'auctionpunj': 410,\n",
       " 'audiit': 411,\n",
       " 'audit': 412,\n",
       " 'audrey': 413,\n",
       " 'audri': 414,\n",
       " 'august': 415,\n",
       " 'august!': 416,\n",
       " 'aunt': 417,\n",
       " 'aunti': 418,\n",
       " 'aunty!': 419,\n",
       " 'aust': 420,\n",
       " 'australia': 421,\n",
       " 'authoris': 422,\n",
       " 'auto': 423,\n",
       " 'autocorrect': 424,\n",
       " 'av': 425,\n",
       " 'ava': 426,\n",
       " 'avail': 427,\n",
       " 'availa': 428,\n",
       " 'available!': 429,\n",
       " 'availablei': 430,\n",
       " 'availablethey': 431,\n",
       " 'avalarr': 432,\n",
       " 'avatar': 433,\n",
       " 'avbl': 434,\n",
       " 'ave': 435,\n",
       " 'aveng': 436,\n",
       " 'avent': 437,\n",
       " 'avenu': 438,\n",
       " 'avier': 439,\n",
       " 'avin': 440,\n",
       " 'avo': 441,\n",
       " 'avoid': 442,\n",
       " 'await': 443,\n",
       " 'awak': 444,\n",
       " 'award': 445,\n",
       " 'award!': 446,\n",
       " 'away': 447,\n",
       " 'away!!': 448,\n",
       " 'awesom': 449,\n",
       " 'awkward': 450,\n",
       " 'aww': 451,\n",
       " 'awww': 452,\n",
       " 'ay': 453,\n",
       " 'ayn': 454,\n",
       " 'ayo': 455,\n",
       " 'b': 456,\n",
       " 'ba': 457,\n",
       " 'baaaaaaaabe!': 458,\n",
       " 'baaaaabe!': 459,\n",
       " 'babe': 460,\n",
       " 'babe!': 461,\n",
       " 'babeprobpop': 462,\n",
       " 'babesozi': 463,\n",
       " 'babi': 464,\n",
       " 'babies!': 465,\n",
       " 'baby!': 466,\n",
       " 'baby!hop': 467,\n",
       " 'babygoodby': 468,\n",
       " 'babyjontet!': 469,\n",
       " 'babysit': 470,\n",
       " 'bac': 471,\n",
       " 'back': 472,\n",
       " 'back!': 473,\n",
       " 'backa': 474,\n",
       " 'backdoor': 475,\n",
       " 'backward': 476,\n",
       " 'bad': 477,\n",
       " 'bad!': 478,\n",
       " 'badass': 479,\n",
       " 'badli': 480,\n",
       " 'badrith': 481,\n",
       " 'bag': 482,\n",
       " 'bagi': 483,\n",
       " 'bahama': 484,\n",
       " 'bahamas!': 485,\n",
       " 'baig': 486,\n",
       " 'bailiff': 487,\n",
       " 'bajarangabali': 488,\n",
       " 'bak': 489,\n",
       " 'bak!': 490,\n",
       " 'bakra': 491,\n",
       " 'bakrid!': 492,\n",
       " 'balanc': 493,\n",
       " 'ball': 494,\n",
       " 'baller': 495,\n",
       " 'balloon!': 496,\n",
       " 'bam': 497,\n",
       " 'bambl': 498,\n",
       " 'ban': 499,\n",
       " 'band': 500,\n",
       " 'bandag': 501,\n",
       " 'bang': 502,\n",
       " 'bangb': 503,\n",
       " 'bangbab': 504,\n",
       " 'bani': 505,\n",
       " 'bank': 506,\n",
       " 'banneduk': 507,\n",
       " 'bannfwflyppm': 508,\n",
       " 'banter': 509,\n",
       " 'bao': 510,\n",
       " 'bar': 511,\n",
       " 'barbi': 512,\n",
       " 'barcelona': 513,\n",
       " 'bare': 514,\n",
       " 'bari': 515,\n",
       " 'barkley': 516,\n",
       " 'barm': 517,\n",
       " 'barolla': 518,\n",
       " 'barrel': 519,\n",
       " 'barri': 520,\n",
       " 'base': 521,\n",
       " 'bash': 522,\n",
       " 'basic': 523,\n",
       " 'basket': 524,\n",
       " 'basketbal': 525,\n",
       " 'basq!ihav': 526,\n",
       " 'bat': 527,\n",
       " 'batch': 528,\n",
       " 'batch!': 529,\n",
       " 'batchlor': 530,\n",
       " 'bath': 531,\n",
       " 'bathroom': 532,\n",
       " 'batsman': 533,\n",
       " 'batt': 534,\n",
       " 'batteri': 535,\n",
       " 'battl': 536,\n",
       " 'bawl': 537,\n",
       " 'bay': 538,\n",
       " 'bb': 539,\n",
       " 'bbc': 540,\n",
       " 'bbdelu': 541,\n",
       " 'bbdpooja': 542,\n",
       " 'bbdtht': 543,\n",
       " 'bblue': 544,\n",
       " 'bbq': 545,\n",
       " 'bc': 546,\n",
       " 'bcaz': 547,\n",
       " 'bck': 548,\n",
       " 'bcm': 549,\n",
       " 'bcmsfwcn': 550,\n",
       " 'bcmwcn': 551,\n",
       " 'bcoz': 552,\n",
       " 'bcozi': 553,\n",
       " 'bcum': 554,\n",
       " 'bcz': 555,\n",
       " 'bday': 556,\n",
       " 'beach': 557,\n",
       " 'bead': 558,\n",
       " 'bear': 559,\n",
       " 'beat': 560,\n",
       " 'beauti': 561,\n",
       " 'beautifulmay': 562,\n",
       " 'bec': 563,\n",
       " 'becau': 564,\n",
       " 'becausethey': 565,\n",
       " 'becom': 566,\n",
       " 'becoz': 567,\n",
       " 'becz': 568,\n",
       " 'bed': 569,\n",
       " 'bed!': 570,\n",
       " 'bedbut': 571,\n",
       " 'bedreal': 572,\n",
       " 'bedrm': 573,\n",
       " 'bedroom': 574,\n",
       " 'bedroom!lov': 575,\n",
       " 'beeen': 576,\n",
       " 'beehoon': 577,\n",
       " 'beendrop': 578,\n",
       " 'beer': 579,\n",
       " 'beerag': 580,\n",
       " 'beerr': 581,\n",
       " 'befor': 582,\n",
       " 'beforehand': 583,\n",
       " 'beforew': 584,\n",
       " 'beg': 585,\n",
       " 'beggar': 586,\n",
       " 'begin': 587,\n",
       " 'begun': 588,\n",
       " 'behalf': 589,\n",
       " 'behav': 590,\n",
       " 'behind': 591,\n",
       " 'bein': 592,\n",
       " 'believ': 593,\n",
       " 'beliv': 594,\n",
       " 'bell': 595,\n",
       " 'bellearli': 596,\n",
       " 'belli': 597,\n",
       " 'belliger': 598,\n",
       " 'belong': 599,\n",
       " 'belov': 600,\n",
       " 'belovd': 601,\n",
       " 'belt': 602,\n",
       " 'ben': 603,\n",
       " 'bend': 604,\n",
       " 'beneath': 605,\n",
       " 'beneficiari': 606,\n",
       " 'benefit': 607,\n",
       " 'benni': 608,\n",
       " 'bergkamp': 609,\n",
       " 'besid': 610,\n",
       " 'best': 611,\n",
       " 'bestcongrat': 612,\n",
       " 'bestrpli': 613,\n",
       " 'bet': 614,\n",
       " 'beta': 615,\n",
       " 'beth': 616,\n",
       " 'betta': 617,\n",
       " 'better': 618,\n",
       " 'bettersn': 619,\n",
       " 'beverag': 620,\n",
       " 'bevieswaz': 621,\n",
       " 'bewar': 622,\n",
       " 'beware!': 623,\n",
       " 'beyond': 624,\n",
       " 'bf': 625,\n",
       " 'bff': 626,\n",
       " 'bfore': 627,\n",
       " 'bhaskar': 628,\n",
       " 'bhayandar': 629,\n",
       " 'bian': 630,\n",
       " 'biatch!': 631,\n",
       " 'bid': 632,\n",
       " 'big': 633,\n",
       " 'big!': 634,\n",
       " 'bigger': 635,\n",
       " 'biggest': 636,\n",
       " 'bike': 637,\n",
       " 'bill': 638,\n",
       " 'billi': 639,\n",
       " 'billion': 640,\n",
       " 'bilo': 641,\n",
       " 'bimbo': 642,\n",
       " 'bin': 643,\n",
       " 'biola': 644,\n",
       " 'bipw': 645,\n",
       " 'bird': 646,\n",
       " 'bird!': 647,\n",
       " 'birla': 648,\n",
       " 'biro': 649,\n",
       " 'birth': 650,\n",
       " 'birthdat': 651,\n",
       " 'birthday': 652,\n",
       " 'bishan': 653,\n",
       " 'bit': 654,\n",
       " 'bitch': 655,\n",
       " 'bite': 656,\n",
       " 'biz': 657,\n",
       " 'bk': 658,\n",
       " 'black': 659,\n",
       " 'blackand': 660,\n",
       " 'blackberri': 661,\n",
       " 'blackim': 662,\n",
       " 'blacko': 663,\n",
       " 'blah': 664,\n",
       " 'blake': 665,\n",
       " 'blame': 666,\n",
       " 'blank': 667,\n",
       " 'blanket': 668,\n",
       " 'blastin': 669,\n",
       " 'bleak': 670,\n",
       " 'bleh': 671,\n",
       " 'bless': 672,\n",
       " 'bless!': 673,\n",
       " 'blessget': 674,\n",
       " 'blessings!': 675,\n",
       " 'blimey': 676,\n",
       " 'blind': 677,\n",
       " 'block': 678,\n",
       " 'blog': 679,\n",
       " 'bloke': 680,\n",
       " 'blond': 681,\n",
       " 'bloo': 682,\n",
       " 'blood': 683,\n",
       " 'bloodblood': 684,\n",
       " 'bloodi': 685,\n",
       " 'bloodsend': 686,\n",
       " 'bloomberg': 687,\n",
       " 'bloombergcom': 688,\n",
       " 'blow': 689,\n",
       " 'blown': 690,\n",
       " 'blu': 691,\n",
       " 'blue': 692,\n",
       " 'bluetooth': 693,\n",
       " 'bluetooth!': 694,\n",
       " 'bluetoothhdset': 695,\n",
       " 'blueu': 696,\n",
       " 'bluff': 697,\n",
       " 'blur': 698,\n",
       " 'bluray': 699,\n",
       " 'bmw': 700,\n",
       " 'bo': 701,\n",
       " 'board': 702,\n",
       " 'boat': 703,\n",
       " 'boatin': 704,\n",
       " 'bob': 705,\n",
       " 'bocpm': 706,\n",
       " 'bodi': 707,\n",
       " 'body!!': 708,\n",
       " 'boggi': 709,\n",
       " 'bognor': 710,\n",
       " 'bold': 711,\n",
       " 'bollo': 712,\n",
       " 'boltblu': 713,\n",
       " 'bom': 714,\n",
       " 'bomb': 715,\n",
       " 'bone': 716,\n",
       " 'bong': 717,\n",
       " 'bonqp': 718,\n",
       " 'bonu': 719,\n",
       " 'bonus!': 720,\n",
       " 'boo': 721,\n",
       " 'boob': 722,\n",
       " 'book': 723,\n",
       " 'bookedth': 724,\n",
       " 'bookmark': 725,\n",
       " 'bookshelf': 726,\n",
       " 'boooo': 727,\n",
       " 'boost': 728,\n",
       " 'booti': 729,\n",
       " 'bootydeli': 730,\n",
       " 'boqu': 731,\n",
       " 'borderlin': 732,\n",
       " 'bore': 733,\n",
       " 'bored!': 734,\n",
       " 'borin': 735,\n",
       " 'boring!': 736,\n",
       " 'born': 737,\n",
       " 'born!': 738,\n",
       " 'bornpleas': 739,\n",
       " 'borrow': 740,\n",
       " 'boskch': 741,\n",
       " 'boskwpppm': 742,\n",
       " 'boss': 743,\n",
       " 'boston': 744,\n",
       " 'bot': 745,\n",
       " 'both!': 746,\n",
       " 'bother': 747,\n",
       " 'bottl': 748,\n",
       " 'bottom': 749,\n",
       " 'bought': 750,\n",
       " 'bought\\x94braindance\\x94a': 751,\n",
       " 'boundari': 752,\n",
       " 'bout': 753,\n",
       " 'bout!': 754,\n",
       " 'bowa': 755,\n",
       " 'bowl': 756,\n",
       " 'bowrc': 757,\n",
       " 'boy': 758,\n",
       " 'boyf': 759,\n",
       " 'boyfriend': 760,\n",
       " 'boyi': 761,\n",
       " 'boytoy': 762,\n",
       " 'boytoy!': 763,\n",
       " 'bpo': 764,\n",
       " 'bra': 765,\n",
       " 'brah': 766,\n",
       " 'brain': 767,\n",
       " 'braini': 768,\n",
       " 'brainless': 769,\n",
       " 'brand': 770,\n",
       " 'brandi': 771,\n",
       " 'brat': 772,\n",
       " 'brave': 773,\n",
       " 'bray': 774,\n",
       " 'brb': 775,\n",
       " 'brdget': 776,\n",
       " 'bread': 777,\n",
       " 'breadstick': 778,\n",
       " 'break': 779,\n",
       " 'breaker': 780,\n",
       " 'breakfast': 781,\n",
       " 'breakin': 782,\n",
       " 'breath': 783,\n",
       " 'breather': 784,\n",
       " 'breez': 785,\n",
       " 'breezi': 786,\n",
       " 'brekkie!': 787,\n",
       " 'bribe': 788,\n",
       " 'bridg': 789,\n",
       " 'bridgwat': 790,\n",
       " 'brief': 791,\n",
       " 'bright': 792,\n",
       " 'brighten': 793,\n",
       " 'brilliant': 794,\n",
       " 'brilliantli': 795,\n",
       " 'brilliantthingi': 796,\n",
       " 'brin': 797,\n",
       " 'bring': 798,\n",
       " 'brisk': 799,\n",
       " 'brison': 800,\n",
       " 'bristol': 801,\n",
       " 'british': 802,\n",
       " 'britney': 803,\n",
       " 'bro': 804,\n",
       " 'broad': 805,\n",
       " 'broadband': 806,\n",
       " 'broke': 807,\n",
       " 'broken': 808,\n",
       " 'brolli': 809,\n",
       " 'broth': 810,\n",
       " 'brotha': 811,\n",
       " 'brother': 812,\n",
       " 'brother‘': 813,\n",
       " 'brought': 814,\n",
       " 'browni': 815,\n",
       " 'brows': 816,\n",
       " 'browser': 817,\n",
       " 'browsin': 818,\n",
       " 'bruce': 819,\n",
       " 'brum!': 820,\n",
       " 'bruv': 821,\n",
       " 'bruv!': 822,\n",
       " 'bslvyl': 823,\n",
       " 'bsn': 824,\n",
       " 'bsnl': 825,\n",
       " 'bstfrnd': 826,\n",
       " 'bt': 827,\n",
       " 'bthere': 828,\n",
       " 'bthmm': 829,\n",
       " 'btnation': 830,\n",
       " 'btnationalr': 831,\n",
       " 'btooth': 832,\n",
       " 'btw': 833,\n",
       " 'btwn': 834,\n",
       " 'bu': 835,\n",
       " 'buck': 836,\n",
       " 'bud': 837,\n",
       " 'buddi': 838,\n",
       " 'buddy!!': 839,\n",
       " 'budget': 840,\n",
       " 'buen': 841,\n",
       " 'buff': 842,\n",
       " 'buffet': 843,\n",
       " 'buffi': 844,\n",
       " 'bugi': 845,\n",
       " 'build': 846,\n",
       " 'built': 847,\n",
       " 'bulb': 848,\n",
       " 'bull': 849,\n",
       " 'bullshit': 850,\n",
       " 'bun': 851,\n",
       " 'bunch': 852,\n",
       " 'bundl': 853,\n",
       " 'bunker': 854,\n",
       " 'buns!': 855,\n",
       " 'burden': 856,\n",
       " 'burger': 857,\n",
       " 'burgundi': 858,\n",
       " 'burial': 859,\n",
       " 'burn': 860,\n",
       " 'burnt': 861,\n",
       " 'burrito': 862,\n",
       " 'bus!': 863,\n",
       " 'buse': 864,\n",
       " 'busetop': 865,\n",
       " 'busi': 866,\n",
       " 'busti': 867,\n",
       " 'busyi': 868,\n",
       " 'but': 869,\n",
       " 'butt': 870,\n",
       " 'butther': 871,\n",
       " 'button': 872,\n",
       " 'buy': 873,\n",
       " 'buyer': 874,\n",
       " 'buz': 875,\n",
       " 'buzi': 876,\n",
       " 'buzz': 877,\n",
       " 'buzz!': 878,\n",
       " 'buzzzz!': 879,\n",
       " 'bw': 880,\n",
       " 'byatch': 881,\n",
       " 'bye': 882,\n",
       " 'by\\x94leafcutt': 883,\n",
       " 'b\\x92day': 884,\n",
       " 'b‘ham': 885,\n",
       " 'c': 886,\n",
       " 'c!': 887,\n",
       " 'cab': 888,\n",
       " 'cabin': 889,\n",
       " 'cabl': 890,\n",
       " 'cafe': 891,\n",
       " 'cage': 892,\n",
       " 'cake': 893,\n",
       " 'caken': 894,\n",
       " 'cal': 895,\n",
       " 'calcul': 896,\n",
       " 'cali': 897,\n",
       " 'calicut': 898,\n",
       " 'california': 899,\n",
       " 'call': 900,\n",
       " 'callback': 901,\n",
       " 'callcost': 902,\n",
       " 'callcoz': 903,\n",
       " 'calld': 904,\n",
       " 'calldrov': 905,\n",
       " 'caller': 906,\n",
       " 'callertun': 907,\n",
       " 'callfreefon': 908,\n",
       " 'callin': 909,\n",
       " 'calling!': 910,\n",
       " 'callingforgot': 911,\n",
       " 'callon': 912,\n",
       " 'calloptout': 913,\n",
       " 'calloptout!yhl': 914,\n",
       " 'calloptoutfq': 915,\n",
       " 'calloptouthf': 916,\n",
       " 'calloptoutj': 917,\n",
       " 'calloptoutjq': 918,\n",
       " 'calloptoutlf': 919,\n",
       " 'calloptoutnd': 920,\n",
       " 'calloptoutqf': 921,\n",
       " 'calls!': 922,\n",
       " 'callsmessagesmiss': 923,\n",
       " 'callsminmobsmor': 924,\n",
       " 'callsminmobsmorelkpobohpfl': 925,\n",
       " 'callsminmoremobsemspobopowa': 926,\n",
       " 'callsppm': 927,\n",
       " 'callurg': 928,\n",
       " 'calm': 929,\n",
       " 'cam': 930,\n",
       " 'camcord': 931,\n",
       " 'came': 932,\n",
       " 'came!': 933,\n",
       " 'camera': 934,\n",
       " 'camera!': 935,\n",
       " 'cameravideo': 936,\n",
       " 'camp': 937,\n",
       " 'campu': 938,\n",
       " 'camri': 939,\n",
       " 'canada': 940,\n",
       " 'canal': 941,\n",
       " 'canari': 942,\n",
       " 'cancel': 943,\n",
       " 'cancer': 944,\n",
       " 'candont': 945,\n",
       " 'canlov': 946,\n",
       " 'cannam': 947,\n",
       " 'cannot': 948,\n",
       " 'cannt': 949,\n",
       " 'cant': 950,\n",
       " 'cantdo': 951,\n",
       " 'canteen': 952,\n",
       " 'can\\x92t': 953,\n",
       " 'can‘t': 954,\n",
       " 'cap': 955,\n",
       " 'capac': 956,\n",
       " 'capit': 957,\n",
       " 'cappuccino': 958,\n",
       " 'captain': 959,\n",
       " 'car': 960,\n",
       " 'card': 961,\n",
       " 'card!': 962,\n",
       " 'cardiff': 963,\n",
       " 'cardin': 964,\n",
       " 'care': 965,\n",
       " 'care!': 966,\n",
       " 'careabout': 967,\n",
       " 'career': 968,\n",
       " 'careful!': 969,\n",
       " 'careinsha': 970,\n",
       " 'careless': 971,\n",
       " 'carent': 972,\n",
       " 'careswt': 973,\n",
       " 'careumma': 974,\n",
       " 'carewhoev': 975,\n",
       " 'carli': 976,\n",
       " 'carlin': 977,\n",
       " 'carlo': 978,\n",
       " 'carlosl': 979,\n",
       " 'carolin': 980,\n",
       " 'carolina': 981,\n",
       " 'caroline!': 982,\n",
       " 'carpark': 983,\n",
       " 'carri': 984,\n",
       " 'carryin': 985,\n",
       " 'carso': 986,\n",
       " 'carton': 987,\n",
       " 'cartoon': 988,\n",
       " 'case': 989,\n",
       " 'cash': 990,\n",
       " 'cash!': 991,\n",
       " 'cashbal': 992,\n",
       " 'cashbincouk': 993,\n",
       " 'cashin': 994,\n",
       " 'cashto': 995,\n",
       " 'cast': 996,\n",
       " 'castor': 997,\n",
       " 'casualti': 998,\n",
       " 'cat': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix = {word:i for i, word in enumerate(remv)}\n",
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PAD>',\n",
       " 1: '<UNK>',\n",
       " 2: 'aa',\n",
       " 3: 'aah',\n",
       " 4: 'aah!',\n",
       " 5: 'aaniy',\n",
       " 6: 'aaooooright',\n",
       " 7: 'aathilov',\n",
       " 8: 'aathiwher',\n",
       " 9: 'ab',\n",
       " 10: 'abbey!',\n",
       " 11: 'abdomen',\n",
       " 12: 'abeg',\n",
       " 13: 'abelu',\n",
       " 14: 'aberdeen',\n",
       " 15: 'abi',\n",
       " 16: 'abi!',\n",
       " 17: 'abil',\n",
       " 18: 'abiola',\n",
       " 19: 'abj',\n",
       " 20: 'abl',\n",
       " 21: 'abnorm',\n",
       " 22: 'about!',\n",
       " 23: 'abouta',\n",
       " 24: 'abroad',\n",
       " 25: 'absenc',\n",
       " 26: 'absolut',\n",
       " 27: 'abstract',\n",
       " 28: 'abt',\n",
       " 29: 'abta',\n",
       " 30: 'aburo',\n",
       " 31: 'abus',\n",
       " 32: 'ac',\n",
       " 33: 'academ',\n",
       " 34: 'acc',\n",
       " 35: 'accent',\n",
       " 36: 'accentur',\n",
       " 37: 'accept',\n",
       " 38: 'access',\n",
       " 39: 'access!',\n",
       " 40: 'accid',\n",
       " 41: 'accident',\n",
       " 42: 'accommod',\n",
       " 43: 'accommodationvouch',\n",
       " 44: 'accomod',\n",
       " 45: 'accordin',\n",
       " 46: 'accordingli',\n",
       " 47: 'accordinglyor',\n",
       " 48: 'account',\n",
       " 49: 'accumul',\n",
       " 50: 'ach',\n",
       " 51: 'achanammarakheshqatar',\n",
       " 52: 'achiev',\n",
       " 53: 'acid!',\n",
       " 54: 'acknowledg',\n",
       " 55: 'aclpm',\n",
       " 56: 'acnt',\n",
       " 57: 'acoentri',\n",
       " 58: 'across',\n",
       " 59: 'acsmsreward',\n",
       " 60: 'act',\n",
       " 61: 'actin',\n",
       " 62: 'action',\n",
       " 63: 'activ',\n",
       " 64: 'actor',\n",
       " 65: 'actual',\n",
       " 66: 'acwicmbcktzr!',\n",
       " 67: 'ad',\n",
       " 68: 'adam',\n",
       " 69: 'add',\n",
       " 70: 'addamsfa',\n",
       " 71: 'addi',\n",
       " 72: 'addict',\n",
       " 73: 'address',\n",
       " 74: 'addressul',\n",
       " 75: 'adewal',\n",
       " 76: 'adi',\n",
       " 77: 'adjust',\n",
       " 78: 'admin',\n",
       " 79: 'administr',\n",
       " 80: 'admir',\n",
       " 81: 'admiss',\n",
       " 82: 'admit',\n",
       " 83: 'admiti',\n",
       " 84: 'ador',\n",
       " 85: 'adp',\n",
       " 86: 'adress',\n",
       " 87: 'adrian',\n",
       " 88: 'adrink',\n",
       " 89: 'adsens',\n",
       " 90: 'adult',\n",
       " 91: 'advanc',\n",
       " 92: 'adventur',\n",
       " 93: 'advic',\n",
       " 94: 'advis',\n",
       " 95: 'advisor',\n",
       " 96: 'ae',\n",
       " 97: 'aeronaut',\n",
       " 98: 'aeroplan',\n",
       " 99: 'afew',\n",
       " 100: 'affair',\n",
       " 101: 'affect',\n",
       " 102: 'affection',\n",
       " 103: 'affectionsamp',\n",
       " 104: 'affidavit',\n",
       " 105: 'afford',\n",
       " 106: 'afghanistan',\n",
       " 107: 'afraid',\n",
       " 108: 'africa',\n",
       " 109: 'african',\n",
       " 110: 'aft',\n",
       " 111: 'afternon',\n",
       " 112: 'afternoon',\n",
       " 113: 'afterward',\n",
       " 114: 'aftr',\n",
       " 115: 'ag',\n",
       " 116: 'again!',\n",
       " 117: 'againcal',\n",
       " 118: 'againlov',\n",
       " 119: 'agalla',\n",
       " 120: 'age',\n",
       " 121: 'agenc',\n",
       " 122: 'agent',\n",
       " 123: 'ageppermesssubscript',\n",
       " 124: 'agesr',\n",
       " 125: 'agidhan',\n",
       " 126: 'ago',\n",
       " 127: 'agocusoon',\n",
       " 128: 'agre',\n",
       " 129: 'agreen',\n",
       " 130: 'ah',\n",
       " 131: 'aha',\n",
       " 132: 'ahead',\n",
       " 133: 'ahge',\n",
       " 134: 'ahhh',\n",
       " 135: 'ahhhhjust',\n",
       " 136: 'ahmad',\n",
       " 137: 'ahnow',\n",
       " 138: 'ahold',\n",
       " 139: 'ahsen',\n",
       " 140: 'ahth',\n",
       " 141: 'ahwhat',\n",
       " 142: 'ai',\n",
       " 143: 'aid',\n",
       " 144: 'aig',\n",
       " 145: 'aight',\n",
       " 146: 'aint',\n",
       " 147: 'air',\n",
       " 148: 'airport',\n",
       " 149: 'airtel',\n",
       " 150: 'aiya',\n",
       " 151: 'aiyah',\n",
       " 152: 'aiyar',\n",
       " 153: 'aiyo',\n",
       " 154: 'aj',\n",
       " 155: 'ajith',\n",
       " 156: 'ak',\n",
       " 157: 'aka',\n",
       " 158: 'akonlon',\n",
       " 159: 'al',\n",
       " 160: 'al!!!!!!!!!',\n",
       " 161: 'alaikkumprid',\n",
       " 162: 'alaipayuth',\n",
       " 163: 'albi',\n",
       " 164: 'album',\n",
       " 165: 'albumquit',\n",
       " 166: 'alcohol',\n",
       " 167: 'aldrin',\n",
       " 168: 'ale',\n",
       " 169: 'alert',\n",
       " 170: 'alert!',\n",
       " 171: 'alertfrom',\n",
       " 172: 'alett',\n",
       " 173: 'alfi',\n",
       " 174: 'algarv',\n",
       " 175: 'algebra',\n",
       " 176: 'algorithm',\n",
       " 177: 'ali',\n",
       " 178: 'alian',\n",
       " 179: 'alibi',\n",
       " 180: 'aliv',\n",
       " 181: 'alivebett',\n",
       " 182: 'all',\n",
       " 183: 'allah',\n",
       " 184: 'allahmeet',\n",
       " 185: 'allahrakhesh',\n",
       " 186: 'allalo',\n",
       " 187: 'allday!',\n",
       " 188: 'allo!',\n",
       " 189: 'allow',\n",
       " 190: 'almost',\n",
       " 191: 'alon',\n",
       " 192: 'along',\n",
       " 193: 'along!',\n",
       " 194: 'alot',\n",
       " 195: 'alreadi',\n",
       " 196: 'alreadysabarish',\n",
       " 197: 'alright',\n",
       " 198: 'alrightokay',\n",
       " 199: 'alrit',\n",
       " 200: 'alritehav',\n",
       " 201: 'also',\n",
       " 202: 'alsoor',\n",
       " 203: 'alter',\n",
       " 204: 'alternativehop',\n",
       " 205: 'although',\n",
       " 206: 'alwa!!',\n",
       " 207: 'alway',\n",
       " 208: 'alwi',\n",
       " 209: 'am',\n",
       " 210: 'am!!',\n",
       " 211: 'amanda',\n",
       " 212: 'amaz',\n",
       " 213: 'ambiti',\n",
       " 214: 'ambrithmaduraimet',\n",
       " 215: 'american',\n",
       " 216: 'ami',\n",
       " 217: 'amigo',\n",
       " 218: 'amk',\n",
       " 219: 'ammaelif',\n",
       " 220: 'ammo',\n",
       " 221: 'amnow',\n",
       " 222: 'among',\n",
       " 223: 'amongst',\n",
       " 224: 'amor',\n",
       " 225: 'amount',\n",
       " 226: 'amp',\n",
       " 227: 'amplikat',\n",
       " 228: 'ampm',\n",
       " 229: 'amrca',\n",
       " 230: 'amrita',\n",
       " 231: 'amt',\n",
       " 232: 'amus',\n",
       " 233: 'an',\n",
       " 234: 'ana',\n",
       " 235: 'anal',\n",
       " 236: 'analysi',\n",
       " 237: 'anand',\n",
       " 238: 'anderson',\n",
       " 239: 'andor',\n",
       " 240: 'andr',\n",
       " 241: 'andrewsboy',\n",
       " 242: 'andro',\n",
       " 243: 'anetwork',\n",
       " 244: 'angel',\n",
       " 245: 'angri',\n",
       " 246: 'anim',\n",
       " 247: 'animal!',\n",
       " 248: 'anjie!',\n",
       " 249: 'anjola',\n",
       " 250: 'anna',\n",
       " 251: 'anni',\n",
       " 252: 'annie!',\n",
       " 253: 'anniversari',\n",
       " 254: 'annonc',\n",
       " 255: 'announc',\n",
       " 256: 'annoy',\n",
       " 257: 'annoyin!',\n",
       " 258: 'anonym',\n",
       " 259: 'anot',\n",
       " 260: 'anoth',\n",
       " 261: 'ansr',\n",
       " 262: 'answer',\n",
       " 263: 'answerin',\n",
       " 264: 'answr',\n",
       " 265: 'antelop',\n",
       " 266: 'anthoni',\n",
       " 267: 'anti',\n",
       " 268: 'antibiot',\n",
       " 269: 'anybodi',\n",
       " 270: 'anyhow',\n",
       " 271: 'anymor',\n",
       " 272: 'anyon',\n",
       " 273: 'anyplac',\n",
       " 274: 'anyth',\n",
       " 275: 'anythi',\n",
       " 276: 'anythin',\n",
       " 277: 'anything!',\n",
       " 278: 'anythingtomorrow',\n",
       " 279: 'anytim',\n",
       " 280: 'anyway',\n",
       " 281: 'anywher',\n",
       " 282: 'aom',\n",
       " 283: 'apart',\n",
       " 284: 'ape',\n",
       " 285: 'apeshit',\n",
       " 286: 'aphe\\x92',\n",
       " 287: 'apnt',\n",
       " 288: 'apo',\n",
       " 289: 'apolog',\n",
       " 290: 'apologet',\n",
       " 291: 'apologis',\n",
       " 292: 'app',\n",
       " 293: 'appar',\n",
       " 294: 'appeal',\n",
       " 295: 'appear',\n",
       " 296: 'appendi',\n",
       " 297: 'appi',\n",
       " 298: 'applebe',\n",
       " 299: 'appledayno',\n",
       " 300: 'applespairsal',\n",
       " 301: 'appli',\n",
       " 302: 'applic',\n",
       " 303: 'appoint',\n",
       " 304: 'appreci',\n",
       " 305: 'appro',\n",
       " 306: 'approach',\n",
       " 307: 'appropri',\n",
       " 308: 'approv',\n",
       " 309: 'appt',\n",
       " 310: 'apr',\n",
       " 311: 'april',\n",
       " 312: 'aproach',\n",
       " 313: 'apt',\n",
       " 314: 'aptitud',\n",
       " 315: 'aquariu',\n",
       " 316: 'ar',\n",
       " 317: 'arab',\n",
       " 318: 'arabian',\n",
       " 319: 'arcad',\n",
       " 320: 'archiv',\n",
       " 321: 'ard',\n",
       " 322: 'ardé',\n",
       " 323: 'area',\n",
       " 324: 'area!',\n",
       " 325: 'arent',\n",
       " 326: 'arestaur',\n",
       " 327: 'aretak',\n",
       " 328: 'argentina',\n",
       " 329: 'argh',\n",
       " 330: 'argu',\n",
       " 331: 'argument',\n",
       " 332: 'ari',\n",
       " 333: 'aris',\n",
       " 334: 'arithmet',\n",
       " 335: 'arm',\n",
       " 336: 'armand',\n",
       " 337: 'armenia',\n",
       " 338: 'arng',\n",
       " 339: 'arngd',\n",
       " 340: 'arnt',\n",
       " 341: 'around',\n",
       " 342: 'around!',\n",
       " 343: 'aroundn',\n",
       " 344: 'arpraveesh',\n",
       " 345: 'arr',\n",
       " 346: 'arrang',\n",
       " 347: 'arrest',\n",
       " 348: 'arriv',\n",
       " 349: 'arrow',\n",
       " 350: 'arsen',\n",
       " 351: 'art',\n",
       " 352: 'art!',\n",
       " 353: 'arti',\n",
       " 354: 'artist',\n",
       " 355: 'arul',\n",
       " 356: 'arun',\n",
       " 357: 'asa',\n",
       " 358: 'asap',\n",
       " 359: 'asap!',\n",
       " 360: 'asapok',\n",
       " 361: 'asda',\n",
       " 362: 'ash',\n",
       " 363: 'ashley',\n",
       " 364: 'ashwini',\n",
       " 365: 'asia',\n",
       " 366: 'asian',\n",
       " 367: 'ask',\n",
       " 368: 'askd',\n",
       " 369: 'askin',\n",
       " 370: 'aslamalaikkuminsha',\n",
       " 371: 'asleep',\n",
       " 372: 'aspect',\n",
       " 373: 'ass',\n",
       " 374: 'ass!',\n",
       " 375: 'ass!!',\n",
       " 376: 'assess',\n",
       " 377: 'asshol',\n",
       " 378: 'assist',\n",
       " 379: 'associ',\n",
       " 380: 'assum',\n",
       " 381: 'asther',\n",
       " 382: 'asthma',\n",
       " 383: 'astn',\n",
       " 384: 'astoundingli',\n",
       " 385: 'astrolog',\n",
       " 386: 'astronom',\n",
       " 387: 'asu',\n",
       " 388: 'asusual!',\n",
       " 389: 'at!',\n",
       " 390: 'ate',\n",
       " 391: 'athlet',\n",
       " 392: 'athom',\n",
       " 393: 'atlanta',\n",
       " 394: 'atlast',\n",
       " 395: 'atleast',\n",
       " 396: 'atm',\n",
       " 397: 'atroci',\n",
       " 398: 'attach',\n",
       " 399: 'attack',\n",
       " 400: 'attempt',\n",
       " 401: 'atten',\n",
       " 402: 'attend',\n",
       " 403: 'attent',\n",
       " 404: 'attitud',\n",
       " 405: 'attract',\n",
       " 406: 'attractioni',\n",
       " 407: 'attribut',\n",
       " 408: 'atyour',\n",
       " 409: 'auction',\n",
       " 410: 'auctionpunj',\n",
       " 411: 'audiit',\n",
       " 412: 'audit',\n",
       " 413: 'audrey',\n",
       " 414: 'audri',\n",
       " 415: 'august',\n",
       " 416: 'august!',\n",
       " 417: 'aunt',\n",
       " 418: 'aunti',\n",
       " 419: 'aunty!',\n",
       " 420: 'aust',\n",
       " 421: 'australia',\n",
       " 422: 'authoris',\n",
       " 423: 'auto',\n",
       " 424: 'autocorrect',\n",
       " 425: 'av',\n",
       " 426: 'ava',\n",
       " 427: 'avail',\n",
       " 428: 'availa',\n",
       " 429: 'available!',\n",
       " 430: 'availablei',\n",
       " 431: 'availablethey',\n",
       " 432: 'avalarr',\n",
       " 433: 'avatar',\n",
       " 434: 'avbl',\n",
       " 435: 'ave',\n",
       " 436: 'aveng',\n",
       " 437: 'avent',\n",
       " 438: 'avenu',\n",
       " 439: 'avier',\n",
       " 440: 'avin',\n",
       " 441: 'avo',\n",
       " 442: 'avoid',\n",
       " 443: 'await',\n",
       " 444: 'awak',\n",
       " 445: 'award',\n",
       " 446: 'award!',\n",
       " 447: 'away',\n",
       " 448: 'away!!',\n",
       " 449: 'awesom',\n",
       " 450: 'awkward',\n",
       " 451: 'aww',\n",
       " 452: 'awww',\n",
       " 453: 'ay',\n",
       " 454: 'ayn',\n",
       " 455: 'ayo',\n",
       " 456: 'b',\n",
       " 457: 'ba',\n",
       " 458: 'baaaaaaaabe!',\n",
       " 459: 'baaaaabe!',\n",
       " 460: 'babe',\n",
       " 461: 'babe!',\n",
       " 462: 'babeprobpop',\n",
       " 463: 'babesozi',\n",
       " 464: 'babi',\n",
       " 465: 'babies!',\n",
       " 466: 'baby!',\n",
       " 467: 'baby!hop',\n",
       " 468: 'babygoodby',\n",
       " 469: 'babyjontet!',\n",
       " 470: 'babysit',\n",
       " 471: 'bac',\n",
       " 472: 'back',\n",
       " 473: 'back!',\n",
       " 474: 'backa',\n",
       " 475: 'backdoor',\n",
       " 476: 'backward',\n",
       " 477: 'bad',\n",
       " 478: 'bad!',\n",
       " 479: 'badass',\n",
       " 480: 'badli',\n",
       " 481: 'badrith',\n",
       " 482: 'bag',\n",
       " 483: 'bagi',\n",
       " 484: 'bahama',\n",
       " 485: 'bahamas!',\n",
       " 486: 'baig',\n",
       " 487: 'bailiff',\n",
       " 488: 'bajarangabali',\n",
       " 489: 'bak',\n",
       " 490: 'bak!',\n",
       " 491: 'bakra',\n",
       " 492: 'bakrid!',\n",
       " 493: 'balanc',\n",
       " 494: 'ball',\n",
       " 495: 'baller',\n",
       " 496: 'balloon!',\n",
       " 497: 'bam',\n",
       " 498: 'bambl',\n",
       " 499: 'ban',\n",
       " 500: 'band',\n",
       " 501: 'bandag',\n",
       " 502: 'bang',\n",
       " 503: 'bangb',\n",
       " 504: 'bangbab',\n",
       " 505: 'bani',\n",
       " 506: 'bank',\n",
       " 507: 'banneduk',\n",
       " 508: 'bannfwflyppm',\n",
       " 509: 'banter',\n",
       " 510: 'bao',\n",
       " 511: 'bar',\n",
       " 512: 'barbi',\n",
       " 513: 'barcelona',\n",
       " 514: 'bare',\n",
       " 515: 'bari',\n",
       " 516: 'barkley',\n",
       " 517: 'barm',\n",
       " 518: 'barolla',\n",
       " 519: 'barrel',\n",
       " 520: 'barri',\n",
       " 521: 'base',\n",
       " 522: 'bash',\n",
       " 523: 'basic',\n",
       " 524: 'basket',\n",
       " 525: 'basketbal',\n",
       " 526: 'basq!ihav',\n",
       " 527: 'bat',\n",
       " 528: 'batch',\n",
       " 529: 'batch!',\n",
       " 530: 'batchlor',\n",
       " 531: 'bath',\n",
       " 532: 'bathroom',\n",
       " 533: 'batsman',\n",
       " 534: 'batt',\n",
       " 535: 'batteri',\n",
       " 536: 'battl',\n",
       " 537: 'bawl',\n",
       " 538: 'bay',\n",
       " 539: 'bb',\n",
       " 540: 'bbc',\n",
       " 541: 'bbdelu',\n",
       " 542: 'bbdpooja',\n",
       " 543: 'bbdtht',\n",
       " 544: 'bblue',\n",
       " 545: 'bbq',\n",
       " 546: 'bc',\n",
       " 547: 'bcaz',\n",
       " 548: 'bck',\n",
       " 549: 'bcm',\n",
       " 550: 'bcmsfwcn',\n",
       " 551: 'bcmwcn',\n",
       " 552: 'bcoz',\n",
       " 553: 'bcozi',\n",
       " 554: 'bcum',\n",
       " 555: 'bcz',\n",
       " 556: 'bday',\n",
       " 557: 'beach',\n",
       " 558: 'bead',\n",
       " 559: 'bear',\n",
       " 560: 'beat',\n",
       " 561: 'beauti',\n",
       " 562: 'beautifulmay',\n",
       " 563: 'bec',\n",
       " 564: 'becau',\n",
       " 565: 'becausethey',\n",
       " 566: 'becom',\n",
       " 567: 'becoz',\n",
       " 568: 'becz',\n",
       " 569: 'bed',\n",
       " 570: 'bed!',\n",
       " 571: 'bedbut',\n",
       " 572: 'bedreal',\n",
       " 573: 'bedrm',\n",
       " 574: 'bedroom',\n",
       " 575: 'bedroom!lov',\n",
       " 576: 'beeen',\n",
       " 577: 'beehoon',\n",
       " 578: 'beendrop',\n",
       " 579: 'beer',\n",
       " 580: 'beerag',\n",
       " 581: 'beerr',\n",
       " 582: 'befor',\n",
       " 583: 'beforehand',\n",
       " 584: 'beforew',\n",
       " 585: 'beg',\n",
       " 586: 'beggar',\n",
       " 587: 'begin',\n",
       " 588: 'begun',\n",
       " 589: 'behalf',\n",
       " 590: 'behav',\n",
       " 591: 'behind',\n",
       " 592: 'bein',\n",
       " 593: 'believ',\n",
       " 594: 'beliv',\n",
       " 595: 'bell',\n",
       " 596: 'bellearli',\n",
       " 597: 'belli',\n",
       " 598: 'belliger',\n",
       " 599: 'belong',\n",
       " 600: 'belov',\n",
       " 601: 'belovd',\n",
       " 602: 'belt',\n",
       " 603: 'ben',\n",
       " 604: 'bend',\n",
       " 605: 'beneath',\n",
       " 606: 'beneficiari',\n",
       " 607: 'benefit',\n",
       " 608: 'benni',\n",
       " 609: 'bergkamp',\n",
       " 610: 'besid',\n",
       " 611: 'best',\n",
       " 612: 'bestcongrat',\n",
       " 613: 'bestrpli',\n",
       " 614: 'bet',\n",
       " 615: 'beta',\n",
       " 616: 'beth',\n",
       " 617: 'betta',\n",
       " 618: 'better',\n",
       " 619: 'bettersn',\n",
       " 620: 'beverag',\n",
       " 621: 'bevieswaz',\n",
       " 622: 'bewar',\n",
       " 623: 'beware!',\n",
       " 624: 'beyond',\n",
       " 625: 'bf',\n",
       " 626: 'bff',\n",
       " 627: 'bfore',\n",
       " 628: 'bhaskar',\n",
       " 629: 'bhayandar',\n",
       " 630: 'bian',\n",
       " 631: 'biatch!',\n",
       " 632: 'bid',\n",
       " 633: 'big',\n",
       " 634: 'big!',\n",
       " 635: 'bigger',\n",
       " 636: 'biggest',\n",
       " 637: 'bike',\n",
       " 638: 'bill',\n",
       " 639: 'billi',\n",
       " 640: 'billion',\n",
       " 641: 'bilo',\n",
       " 642: 'bimbo',\n",
       " 643: 'bin',\n",
       " 644: 'biola',\n",
       " 645: 'bipw',\n",
       " 646: 'bird',\n",
       " 647: 'bird!',\n",
       " 648: 'birla',\n",
       " 649: 'biro',\n",
       " 650: 'birth',\n",
       " 651: 'birthdat',\n",
       " 652: 'birthday',\n",
       " 653: 'bishan',\n",
       " 654: 'bit',\n",
       " 655: 'bitch',\n",
       " 656: 'bite',\n",
       " 657: 'biz',\n",
       " 658: 'bk',\n",
       " 659: 'black',\n",
       " 660: 'blackand',\n",
       " 661: 'blackberri',\n",
       " 662: 'blackim',\n",
       " 663: 'blacko',\n",
       " 664: 'blah',\n",
       " 665: 'blake',\n",
       " 666: 'blame',\n",
       " 667: 'blank',\n",
       " 668: 'blanket',\n",
       " 669: 'blastin',\n",
       " 670: 'bleak',\n",
       " 671: 'bleh',\n",
       " 672: 'bless',\n",
       " 673: 'bless!',\n",
       " 674: 'blessget',\n",
       " 675: 'blessings!',\n",
       " 676: 'blimey',\n",
       " 677: 'blind',\n",
       " 678: 'block',\n",
       " 679: 'blog',\n",
       " 680: 'bloke',\n",
       " 681: 'blond',\n",
       " 682: 'bloo',\n",
       " 683: 'blood',\n",
       " 684: 'bloodblood',\n",
       " 685: 'bloodi',\n",
       " 686: 'bloodsend',\n",
       " 687: 'bloomberg',\n",
       " 688: 'bloombergcom',\n",
       " 689: 'blow',\n",
       " 690: 'blown',\n",
       " 691: 'blu',\n",
       " 692: 'blue',\n",
       " 693: 'bluetooth',\n",
       " 694: 'bluetooth!',\n",
       " 695: 'bluetoothhdset',\n",
       " 696: 'blueu',\n",
       " 697: 'bluff',\n",
       " 698: 'blur',\n",
       " 699: 'bluray',\n",
       " 700: 'bmw',\n",
       " 701: 'bo',\n",
       " 702: 'board',\n",
       " 703: 'boat',\n",
       " 704: 'boatin',\n",
       " 705: 'bob',\n",
       " 706: 'bocpm',\n",
       " 707: 'bodi',\n",
       " 708: 'body!!',\n",
       " 709: 'boggi',\n",
       " 710: 'bognor',\n",
       " 711: 'bold',\n",
       " 712: 'bollo',\n",
       " 713: 'boltblu',\n",
       " 714: 'bom',\n",
       " 715: 'bomb',\n",
       " 716: 'bone',\n",
       " 717: 'bong',\n",
       " 718: 'bonqp',\n",
       " 719: 'bonu',\n",
       " 720: 'bonus!',\n",
       " 721: 'boo',\n",
       " 722: 'boob',\n",
       " 723: 'book',\n",
       " 724: 'bookedth',\n",
       " 725: 'bookmark',\n",
       " 726: 'bookshelf',\n",
       " 727: 'boooo',\n",
       " 728: 'boost',\n",
       " 729: 'booti',\n",
       " 730: 'bootydeli',\n",
       " 731: 'boqu',\n",
       " 732: 'borderlin',\n",
       " 733: 'bore',\n",
       " 734: 'bored!',\n",
       " 735: 'borin',\n",
       " 736: 'boring!',\n",
       " 737: 'born',\n",
       " 738: 'born!',\n",
       " 739: 'bornpleas',\n",
       " 740: 'borrow',\n",
       " 741: 'boskch',\n",
       " 742: 'boskwpppm',\n",
       " 743: 'boss',\n",
       " 744: 'boston',\n",
       " 745: 'bot',\n",
       " 746: 'both!',\n",
       " 747: 'bother',\n",
       " 748: 'bottl',\n",
       " 749: 'bottom',\n",
       " 750: 'bought',\n",
       " 751: 'bought\\x94braindance\\x94a',\n",
       " 752: 'boundari',\n",
       " 753: 'bout',\n",
       " 754: 'bout!',\n",
       " 755: 'bowa',\n",
       " 756: 'bowl',\n",
       " 757: 'bowrc',\n",
       " 758: 'boy',\n",
       " 759: 'boyf',\n",
       " 760: 'boyfriend',\n",
       " 761: 'boyi',\n",
       " 762: 'boytoy',\n",
       " 763: 'boytoy!',\n",
       " 764: 'bpo',\n",
       " 765: 'bra',\n",
       " 766: 'brah',\n",
       " 767: 'brain',\n",
       " 768: 'braini',\n",
       " 769: 'brainless',\n",
       " 770: 'brand',\n",
       " 771: 'brandi',\n",
       " 772: 'brat',\n",
       " 773: 'brave',\n",
       " 774: 'bray',\n",
       " 775: 'brb',\n",
       " 776: 'brdget',\n",
       " 777: 'bread',\n",
       " 778: 'breadstick',\n",
       " 779: 'break',\n",
       " 780: 'breaker',\n",
       " 781: 'breakfast',\n",
       " 782: 'breakin',\n",
       " 783: 'breath',\n",
       " 784: 'breather',\n",
       " 785: 'breez',\n",
       " 786: 'breezi',\n",
       " 787: 'brekkie!',\n",
       " 788: 'bribe',\n",
       " 789: 'bridg',\n",
       " 790: 'bridgwat',\n",
       " 791: 'brief',\n",
       " 792: 'bright',\n",
       " 793: 'brighten',\n",
       " 794: 'brilliant',\n",
       " 795: 'brilliantli',\n",
       " 796: 'brilliantthingi',\n",
       " 797: 'brin',\n",
       " 798: 'bring',\n",
       " 799: 'brisk',\n",
       " 800: 'brison',\n",
       " 801: 'bristol',\n",
       " 802: 'british',\n",
       " 803: 'britney',\n",
       " 804: 'bro',\n",
       " 805: 'broad',\n",
       " 806: 'broadband',\n",
       " 807: 'broke',\n",
       " 808: 'broken',\n",
       " 809: 'brolli',\n",
       " 810: 'broth',\n",
       " 811: 'brotha',\n",
       " 812: 'brother',\n",
       " 813: 'brother‘',\n",
       " 814: 'brought',\n",
       " 815: 'browni',\n",
       " 816: 'brows',\n",
       " 817: 'browser',\n",
       " 818: 'browsin',\n",
       " 819: 'bruce',\n",
       " 820: 'brum!',\n",
       " 821: 'bruv',\n",
       " 822: 'bruv!',\n",
       " 823: 'bslvyl',\n",
       " 824: 'bsn',\n",
       " 825: 'bsnl',\n",
       " 826: 'bstfrnd',\n",
       " 827: 'bt',\n",
       " 828: 'bthere',\n",
       " 829: 'bthmm',\n",
       " 830: 'btnation',\n",
       " 831: 'btnationalr',\n",
       " 832: 'btooth',\n",
       " 833: 'btw',\n",
       " 834: 'btwn',\n",
       " 835: 'bu',\n",
       " 836: 'buck',\n",
       " 837: 'bud',\n",
       " 838: 'buddi',\n",
       " 839: 'buddy!!',\n",
       " 840: 'budget',\n",
       " 841: 'buen',\n",
       " 842: 'buff',\n",
       " 843: 'buffet',\n",
       " 844: 'buffi',\n",
       " 845: 'bugi',\n",
       " 846: 'build',\n",
       " 847: 'built',\n",
       " 848: 'bulb',\n",
       " 849: 'bull',\n",
       " 850: 'bullshit',\n",
       " 851: 'bun',\n",
       " 852: 'bunch',\n",
       " 853: 'bundl',\n",
       " 854: 'bunker',\n",
       " 855: 'buns!',\n",
       " 856: 'burden',\n",
       " 857: 'burger',\n",
       " 858: 'burgundi',\n",
       " 859: 'burial',\n",
       " 860: 'burn',\n",
       " 861: 'burnt',\n",
       " 862: 'burrito',\n",
       " 863: 'bus!',\n",
       " 864: 'buse',\n",
       " 865: 'busetop',\n",
       " 866: 'busi',\n",
       " 867: 'busti',\n",
       " 868: 'busyi',\n",
       " 869: 'but',\n",
       " 870: 'butt',\n",
       " 871: 'butther',\n",
       " 872: 'button',\n",
       " 873: 'buy',\n",
       " 874: 'buyer',\n",
       " 875: 'buz',\n",
       " 876: 'buzi',\n",
       " 877: 'buzz',\n",
       " 878: 'buzz!',\n",
       " 879: 'buzzzz!',\n",
       " 880: 'bw',\n",
       " 881: 'byatch',\n",
       " 882: 'bye',\n",
       " 883: 'by\\x94leafcutt',\n",
       " 884: 'b\\x92day',\n",
       " 885: 'b‘ham',\n",
       " 886: 'c',\n",
       " 887: 'c!',\n",
       " 888: 'cab',\n",
       " 889: 'cabin',\n",
       " 890: 'cabl',\n",
       " 891: 'cafe',\n",
       " 892: 'cage',\n",
       " 893: 'cake',\n",
       " 894: 'caken',\n",
       " 895: 'cal',\n",
       " 896: 'calcul',\n",
       " 897: 'cali',\n",
       " 898: 'calicut',\n",
       " 899: 'california',\n",
       " 900: 'call',\n",
       " 901: 'callback',\n",
       " 902: 'callcost',\n",
       " 903: 'callcoz',\n",
       " 904: 'calld',\n",
       " 905: 'calldrov',\n",
       " 906: 'caller',\n",
       " 907: 'callertun',\n",
       " 908: 'callfreefon',\n",
       " 909: 'callin',\n",
       " 910: 'calling!',\n",
       " 911: 'callingforgot',\n",
       " 912: 'callon',\n",
       " 913: 'calloptout',\n",
       " 914: 'calloptout!yhl',\n",
       " 915: 'calloptoutfq',\n",
       " 916: 'calloptouthf',\n",
       " 917: 'calloptoutj',\n",
       " 918: 'calloptoutjq',\n",
       " 919: 'calloptoutlf',\n",
       " 920: 'calloptoutnd',\n",
       " 921: 'calloptoutqf',\n",
       " 922: 'calls!',\n",
       " 923: 'callsmessagesmiss',\n",
       " 924: 'callsminmobsmor',\n",
       " 925: 'callsminmobsmorelkpobohpfl',\n",
       " 926: 'callsminmoremobsemspobopowa',\n",
       " 927: 'callsppm',\n",
       " 928: 'callurg',\n",
       " 929: 'calm',\n",
       " 930: 'cam',\n",
       " 931: 'camcord',\n",
       " 932: 'came',\n",
       " 933: 'came!',\n",
       " 934: 'camera',\n",
       " 935: 'camera!',\n",
       " 936: 'cameravideo',\n",
       " 937: 'camp',\n",
       " 938: 'campu',\n",
       " 939: 'camri',\n",
       " 940: 'canada',\n",
       " 941: 'canal',\n",
       " 942: 'canari',\n",
       " 943: 'cancel',\n",
       " 944: 'cancer',\n",
       " 945: 'candont',\n",
       " 946: 'canlov',\n",
       " 947: 'cannam',\n",
       " 948: 'cannot',\n",
       " 949: 'cannt',\n",
       " 950: 'cant',\n",
       " 951: 'cantdo',\n",
       " 952: 'canteen',\n",
       " 953: 'can\\x92t',\n",
       " 954: 'can‘t',\n",
       " 955: 'cap',\n",
       " 956: 'capac',\n",
       " 957: 'capit',\n",
       " 958: 'cappuccino',\n",
       " 959: 'captain',\n",
       " 960: 'car',\n",
       " 961: 'card',\n",
       " 962: 'card!',\n",
       " 963: 'cardiff',\n",
       " 964: 'cardin',\n",
       " 965: 'care',\n",
       " 966: 'care!',\n",
       " 967: 'careabout',\n",
       " 968: 'career',\n",
       " 969: 'careful!',\n",
       " 970: 'careinsha',\n",
       " 971: 'careless',\n",
       " 972: 'carent',\n",
       " 973: 'careswt',\n",
       " 974: 'careumma',\n",
       " 975: 'carewhoev',\n",
       " 976: 'carli',\n",
       " 977: 'carlin',\n",
       " 978: 'carlo',\n",
       " 979: 'carlosl',\n",
       " 980: 'carolin',\n",
       " 981: 'carolina',\n",
       " 982: 'caroline!',\n",
       " 983: 'carpark',\n",
       " 984: 'carri',\n",
       " 985: 'carryin',\n",
       " 986: 'carso',\n",
       " 987: 'carton',\n",
       " 988: 'cartoon',\n",
       " 989: 'case',\n",
       " 990: 'cash',\n",
       " 991: 'cash!',\n",
       " 992: 'cashbal',\n",
       " 993: 'cashbincouk',\n",
       " 994: 'cashin',\n",
       " 995: 'cashto',\n",
       " 996: 'cast',\n",
       " 997: 'castor',\n",
       " 998: 'casualti',\n",
       " 999: 'cat',\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_word = {i:word for i, word in enumerate(remv)}\n",
    "ix_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert the words to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_to_ix = []\n",
    "for i in text_clean:\n",
    "    each_ix = []\n",
    "    for w in i.split():\n",
    "        if w not in word_to_ix:\n",
    "            each_ix.append(word_to_ix['<UNK>'])\n",
    "        else:\n",
    "            each_ix.append(word_to_ix[w])\n",
    "    sent_to_ix.append(each_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5418, 6709, 4223]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6771, 1821, 5540, 1842, 2913, 6771, 886, 195, 5540]\n",
      "['u', 'dun', 'say', 'earli', 'hor', 'u', 'c', 'alreadi', 'say']\n"
     ]
    }
   ],
   "source": [
    "print(sent_to_ix[3])\n",
    "print([ix_to_word[i] for i in sent_to_ix[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u dun say earli hor u c alreadi say'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clean[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x21aa9115fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#distribution of length of SMS\n",
    "# most of the sms length lies in 10, so we consider max length=10\n",
    "length = []\n",
    "for s in sent_to_ix:\n",
    "    length.append(len(s))\n",
    "import seaborn as sns\n",
    "sns.displot(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sentence = []\n",
    "max_length=10\n",
    "for s in sent_to_ix:\n",
    "    if (len(s)<max_length):\n",
    "        pad_req = max_length-len(s)\n",
    "        pad_zero = [0]*pad_req\n",
    "        padded_sentence.append(s+pad_zero)\n",
    "    elif (len(s)>=10):\n",
    "        padded_sentence.append(s[:max_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5418, 6709]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2509, 3345, 4913, 1370, 427, 845, 4210, 2605, 7297, 3487],\n",
       " [4507, 3522, 3307, 7196, 6771, 4541, 0, 0, 0, 0],\n",
       " [2312, 1968, 7252, 1241, 7211, 2075, 1422, 2186, 6562, 6052],\n",
       " [6771, 1821, 5540, 1842, 2913, 6771, 886, 195, 5540, 0],\n",
       " [4216, 1735, 6484, 2523, 6898, 3652, 341, 6504, 0, 0],\n",
       " [2321, 2813, 1477, 7107, 7285, 473, 3018, 3620, 2379, 6106],\n",
       " [2038, 812, 3620, 5979, 6690, 3620, 143, 4723, 0, 0],\n",
       " [4762, 5339, 3936, 3936, 4601, 4009, 4441, 6952, 5642, 907],\n",
       " [7221, 6926, 4285, 1432, 5605, 5264, 5055, 5377, 1146, 900],\n",
       " [4063, 4101, 6771, 5182, 1966, 6860, 3537, 1217, 4063, 934],\n",
       " [3045, 2539, 2884, 5935, 1735, 7051, 6322, 6170, 271, 6624],\n",
       " [5754, 1035, 7211, 991, 4966, 6725, 1402, 5616, 1332, 4743],\n",
       " [6878, 7107, 2312, 3941, 5055, 3239, 6725, 7285, 1146, 6348],\n",
       " [3221, 5581, 5388, 7285, 6425, 784, 5089, 7275, 6314, 2790],\n",
       " [1486, 6218, 7209, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4065, 6895, 1378, 1162, 7053, 3636, 4280, 6725, 3964, 1162],\n",
       " [4499, 3416, 7068, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1898, 6771, 5318, 5991, 4223, 7425, 6918, 4243, 3829, 6918],\n",
       " [2191, 6439, 7080, 6771, 2146, 6439, 7080, 2569, 456, 0],\n",
       " [1952, 6918, 3795, 1735, 4027, 2514, 4296, 6725, 6874, 4237],\n",
       " [5637, 5991, 4223, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3231, 2509, 6696, 4101, 2672, 2672, 3307, 0, 0, 0],\n",
       " [7539, 4733, 2208, 3522, 1447, 6110, 1232, 0, 0, 0],\n",
       " [110, 2198, 3772, 2509, 6133, 3700, 321, 5875, 3700, 6771],\n",
       " [2160, 197, 7080, 3925, 5938, 0, 0, 0, 0, 0],\n",
       " [2269, 1856, 5835, 3045, 5248, 2979, 6498, 6195, 3864, 2461],\n",
       " [3679, 207, 1309, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1000, 835, 2337, 1894, 3829, 6358, 1856, 4083, 3568, 1651],\n",
       " [3045, 472, 226, 4657, 960, 3041, 3589, 3454, 6461, 5427],\n",
       " [134, 7290, 6920, 5318, 6431, 2146, 3620, 3679, 0, 0],\n",
       " [7029, 6430, 6106, 1158, 6244, 5515, 6430, 1707, 7051, 3652],\n",
       " [7426, 2568, 6918, 290, 4210, 2100, 61, 3620, 6016, 1102],\n",
       " [3351, 6378, 274, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2137, 2090, 2932, 5171, 1424, 0, 0, 0, 0, 0],\n",
       " [6425, 6189, 5396, 6789, 4063, 1044, 4101, 4868, 1278, 5333],\n",
       " [7513, 4507, 2509, 2884, 3692, 6540, 4149, 7539, 6784, 2509],\n",
       " [4562, 3041, 3589, 3454, 5429, 1731, 0, 0, 0, 0],\n",
       " [5593, 3590, 456, 960, 0, 0, 0, 0, 0, 0],\n",
       " [274, 3700, 6771, 1536, 0, 0, 0, 0, 0, 0],\n",
       " [2784, 2933, 5531, 2509, 6412, 5593, 7476, 1536, 274, 6607],\n",
       " [4847, 2509, 132, 7078, 7051, 6244, 2605, 7110, 18, 0],\n",
       " [2277, 6378, 7051, 4262, 1369, 3724, 6272, 318, 6089, 4052],\n",
       " [5417, 860, 4149, 6696, 900, 5333, 5850, 2312, 4363, 4063],\n",
       " [5593, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2606, 2909, 3620, 3839, 7128, 1944, 3756, 3071, 0, 0],\n",
       " [923, 900, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1627, 2461, 2798, 456, 3055, 4315, 0, 0, 0, 0],\n",
       " [2091, 1961, 274, 2509, 0, 0, 0, 0, 0, 0],\n",
       " [7426, 2909, 6767, 950, 1340, 3898, 367, 341, 654, 0],\n",
       " [6771, 1735, 3454, 6160, 1627, 2038, 7051, 2509, 2919, 3394],\n",
       " [6484, 2208, 6540, 5539, 1152, 0, 0, 0, 0, 0],\n",
       " [2588, 6906, 5462, 3620, 3756, 2690, 1903, 5856, 6504, 2461],\n",
       " [3351, 2394, 5387, 1842, 6611, 4112, 2750, 1368, 4848, 6624],\n",
       " [7319, 4288, 5247, 1927, 44, 6506, 3620, 5780, 611, 1340],\n",
       " [5850, 32, 6035, 4291, 3281, 1606, 1602, 5279, 7218, 4860],\n",
       " [3454, 3836, 5691, 7452, 2190, 3760, 0, 0, 0, 0],\n",
       " [1284, 7429, 5981, 1140, 4714, 900, 4405, 886, 6242, 6918],\n",
       " [5947, 3041, 900, 3535, 3925, 0, 0, 0, 0, 0],\n",
       " [6378, 5235, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7445, 5603, 4475, 5635, 0, 0, 0, 0, 0, 0],\n",
       " [2539, 4822, 857, 7080, 2884, 950, 2038, 4133, 4664, 3414],\n",
       " [2672, 2672, 2672, 2541, 3307, 2485, 5799, 5597, 0, 0],\n",
       " [4704, 1065, 3167, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 5429, 6632, 2272, 4507, 1224, 0, 0, 0, 0],\n",
       " [4507, 3522, 1751, 1065, 7196, 1447, 2685, 1781, 195, 5481],\n",
       " [6926, 1432, 4868, 94, 2255, 5265, 5374, 4059, 445, 719],\n",
       " [6578, 5930, 1542, 1496, 5930, 6771, 1542, 5616, 6874, 6927],\n",
       " [6877, 6874, 445, 1256, 6698, 2030, 6685, 57, 1146, 6725],\n",
       " [2762, 4291, 1687, 512, 1224, 3391, 6171, 0, 0, 0],\n",
       " [4854, 2492, 4101, 1941, 0, 0, 0, 0, 0, 0],\n",
       " [7022, 3766, 3839, 5537, 4090, 2775, 0, 0, 0, 0],\n",
       " [2198, 1152, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 460, 3045, 2884, 7049, 5915, 0, 0, 0, 0],\n",
       " [3445, 7479, 4768, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 900, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7029, 3797, 900, 2312, 0, 0, 0, 0, 0, 0],\n",
       " [6430, 1313, 2452, 6690, 1643, 5353, 0, 0, 0, 0],\n",
       " [3620, 4760, 4166, 5695, 4655, 0, 0, 0, 0, 0],\n",
       " [4565, 3756, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6106, 3692, 3296, 4166, 6299, 1846, 0, 0, 0, 0],\n",
       " [5947, 3041, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [3351, 900, 130, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4507, 7080, 2884, 2821, 2821, 0, 0, 0, 0, 0],\n",
       " [4848, 3839, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7513, 4280, 6118, 0, 0, 0, 0, 0, 0, 0],\n",
       " [900, 3535, 1735, 4285, 6883, 5850, 0, 0, 0, 0],\n",
       " [5243, 6771, 2461, 7464, 4262, 6529, 4537, 3238, 3045, 1731],\n",
       " [7425, 6070, 5616, 5339, 3829, 4664, 932, 472, 3045, 472],\n",
       " [3045, 5248, 6106, 6624, 460, 0, 0, 0, 0, 0],\n",
       " [1910, 3370, 1759, 1224, 7136, 6874, 2312, 0, 0, 0],\n",
       " [7426, 1696, 1742, 6063, 1167, 6498, 7500, 1000, 5917, 0],\n",
       " [5947, 4664, 4507, 3925, 260, 4317, 5993, 3531, 112, 998],\n",
       " [5863, 4872, 5863, 4664, 5863, 6704, 4967, 3620, 5193, 5863],\n",
       " [4868, 900, 1432, 5640, 5337, 228, 2642, 990, 5056, 0],\n",
       " [2742, 4852, 873, 3535, 1065, 195, 3601, 2568, 5738, 1835],\n",
       " [2312, 5396, 7029, 1213, 5777, 6406, 4719, 3980, 6949, 2461],\n",
       " [7068, 6382, 4135, 28, 6771, 0, 0, 0, 0, 0],\n",
       " [5593, 2198, 3662, 3664, 4733, 0, 0, 0, 0, 0],\n",
       " [2821, 7247, 4507, 2873, 4405, 7425, 654, 5462, 2281, 2687],\n",
       " [5593, 1422, 1200, 246, 0, 0, 0, 0, 0, 0],\n",
       " [4868, 1735, 6406, 271, 4390, 1922, 5540, 0, 0, 0],\n",
       " [4509, 4223, 6874, 5036, 3687, 3572, 7136, 4822, 6771, 435],\n",
       " [3045, 6106, 3692, 960, 873, 2536, 1786, 6405, 7454, 0],\n",
       " [4762, 5339, 3936, 3936, 4601, 4009, 4441, 6952, 5642, 907],\n",
       " [7319, 7489, 5389, 1627, 3910, 2651, 2422, 744, 3946, 1037],\n",
       " [6797, 3603, 6937, 6797, 3724, 3708, 1519, 0, 0, 0],\n",
       " [6425, 3708, 7231, 652, 6425, 3829, 652, 6712, 3943, 0],\n",
       " [145, 3041, 2843, 2461, 990, 0, 0, 0, 0, 0],\n",
       " [7315, 3161, 73, 6405, 1291, 1261, 3183, 4004, 5639, 0],\n",
       " [3455, 2634, 4526, 4760, 4083, 3620, 618, 3602, 207, 4537],\n",
       " [1735, 7303, 2651, 2750, 866, 0, 0, 0, 0, 0],\n",
       " [4882, 4402, 5342, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2509, 1652, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 4507, 7196, 1187, 3620, 6696, 4291, 6481, 5551, 6771],\n",
       " [2450, 6696, 1296, 3529, 7110, 1770, 5738, 5055, 2642, 900],\n",
       " [7018, 6874, 4564, 5627, 2285, 280, 3045, 2191, 3350, 6725],\n",
       " [1962, 889, 4655, 5481, 2715, 556, 743, 1, 2153, 5981],\n",
       " [7219, 6771, 5981, 5605, 5263, 2879, 2228, 3070, 5979, 3652],\n",
       " [2557, 7425, 4192, 5979, 2339, 1895, 5222, 6650, 4264, 0],\n",
       " [2861, 6805, 3102, 2750, 4733, 5558, 1658, 4847, 873, 2261],\n",
       " [5053, 48, 6077, 5738, 6844, 719, 4913, 1146, 900, 3024],\n",
       " [6878, 4063, 445, 719, 906, 5055, 2186, 6696, 1296, 6772],\n",
       " [4291, 73, 300, 3833, 0, 0, 0, 0, 0, 0],\n",
       " [6578, 6997, 4434, 1941, 5605, 5263, 445, 3883, 4868, 900],\n",
       " [2509, 5509, 4165, 6578, 1731, 0, 0, 0, 0, 0],\n",
       " [7539, 5003, 7067, 6540, 7540, 2198, 873, 0, 0, 0],\n",
       " [2541, 6170, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3461, 2731, 5625, 4090, 7454, 5625, 6406, 747, 5616, 1735],\n",
       " [5427, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2813, 2485, 5182, 6771, 2909, 6771, 5182, 7128, 1557, 5182],\n",
       " [3439, 4166, 1332, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 2884, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1519, 900, 6567, 44, 0, 0, 0, 0, 0, 0],\n",
       " [2208, 262, 5169, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6225, 5176, 7252, 5155, 7211, 6642, 5931, 1830, 4862, 6771],\n",
       " [7051, 2461, 3501, 6624, 7051, 5243, 1710, 3668, 5625, 1657],\n",
       " [2679, 4159, 7461, 0, 0, 0, 0, 0, 0, 0],\n",
       " [900, 3925, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1065, 5427, 582, 63, 0, 0, 0, 0, 0, 0],\n",
       " [7483, 5231, 4149, 1053, 6258, 2312, 2722, 5640, 6406, 2509],\n",
       " [2568, 886, 3549, 6768, 2281, 7539, 3566, 5539, 4965, 3620],\n",
       " [3351, 6406, 7489, 7080, 0, 0, 0, 0, 0, 0],\n",
       " [5789, 7029, 3821, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6287, 6506, 4445, 2461, 6552, 3651, 6481, 3723, 4779, 1359],\n",
       " [3454, 4847, 4563, 472, 0, 0, 0, 0, 0, 0],\n",
       " [7425, 5593, 7407, 1750, 0, 0, 0, 0, 0, 0],\n",
       " [7160, 6056, 4223, 6314, 1152, 6891, 0, 0, 0, 0],\n",
       " [2321, 2742, 5333, 6406, 3045, 5209, 5649, 2154, 3652, 3667],\n",
       " [6798, 900, 1065, 3119, 3603, 587, 5156, 4847, 4995, 2720],\n",
       " [3407, 1559, 1296, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5782, 2568, 3296, 648, 5898, 0, 0, 0, 0, 0],\n",
       " [7217, 2240, 3045, 4288, 0, 0, 0, 0, 0, 0],\n",
       " [7513, 6490, 1139, 618, 1187, 4262, 2509, 4867, 3817, 0],\n",
       " [4507, 6874, 6770, 5333, 0, 0, 0, 0, 0, 0],\n",
       " [4762, 5339, 3936, 3936, 4601, 4009, 4441, 6952, 5642, 907],\n",
       " [2055, 1660, 2237, 7216, 2038, 5704, 5918, 4563, 4132, 1224],\n",
       " [6, 7290, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 3565, 2929, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2783, 3724, 2461, 3145, 6578, 2715, 2541, 758, 6484, 3915],\n",
       " [1432, 5640, 254, 4291, 7429, 1564, 7029, 4868, 900, 346],\n",
       " [7219, 6771, 5981, 5605, 5263, 990, 2879, 2228, 3070, 5979],\n",
       " [3387, 5477, 4262, 4027, 195, 1973, 2049, 5593, 5243, 3603],\n",
       " [4291, 960, 2929, 4696, 4291, 3296, 2699, 0, 0, 0],\n",
       " [3045, 3724, 3045, 1866, 1496, 5992, 3829, 2715, 0, 0],\n",
       " [4847, 6118, 730, 2074, 3156, 2342, 5333, 7425, 5593, 7391],\n",
       " [504, 6874, 4588, 7080, 6771, 5263, 5640, 4149, 1759, 6874],\n",
       " [4848, 6874, 4913, 1835, 1419, 4077, 195, 0, 0, 0],\n",
       " [6878, 6696, 1296, 3529, 7110, 1770, 5738, 5055, 2642, 900],\n",
       " [2821, 2351, 611, 7080, 442, 4035, 7236, 600, 4537, 0],\n",
       " [2605, 2009, 2107, 789, 4262, 3500, 5593, 6607, 0, 0],\n",
       " [7425, 1254, 2288, 201, 6910, 7065, 0, 0, 0, 0],\n",
       " [5789, 4262, 142, 506, 48, 506, 73, 0, 0, 0],\n",
       " [2858, 6490, 6244, 2568, 6540, 2908, 321, 7407, 2509, 2312],\n",
       " [6540, 1224, 3535, 0, 0, 0, 0, 0, 0, 0],\n",
       " [685, 2781, 950, 593, 2281, 6249, 4140, 3041, 2492, 6771],\n",
       " [7128, 3045, 2539, 2198, 531, 2546, 4317, 0, 0, 0],\n",
       " [3589, 3454, 7496, 2568, 4090, 978, 3829, 900, 0, 0],\n",
       " [6771, 6106, 2509, 3835, 0, 0, 0, 0, 0, 0],\n",
       " [6750, 2342, 6080, 7186, 5738, 7275, 472, 6537, 3756, 2146],\n",
       " [6406, 1707, 5333, 3589, 3454, 3671, 0, 0, 0, 0],\n",
       " [2822, 6017, 3847, 6918, 7099, 3620, 3454, 5525, 1979, 5333],\n",
       " [3614, 2909, 4482, 4090, 4262, 2012, 1941, 4101, 306, 2989],\n",
       " [3679, 6771, 6714, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4507, 2452, 6690, 1643, 5353, 0, 0, 0, 0, 0],\n",
       " [2662, 1167, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2509, 4390, 2608, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2783, 2703, 1, 2190, 3296, 3549, 7290, 6662, 2461, 472],\n",
       " [2680, 449, 4018, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4868, 900, 1432, 5640, 5337, 2325, 228, 2642, 990, 5056],\n",
       " [2568, 3790, 5187, 6540, 2461, 0, 0, 0, 0, 0],\n",
       " [3332, 5235, 2884, 2509, 531, 2208, 5754, 6895, 4280, 6378],\n",
       " [6830, 1961, 2190, 6420, 415, 7360, 0, 0, 0, 0],\n",
       " [3045, 5947, 3221, 3304, 3559, 4760, 1735, 3387, 6658, 3910],\n",
       " [2821, 2186, 1254, 1351, 0, 0, 0, 0, 0, 0],\n",
       " [6118, 2937, 6207, 6080, 5910, 20, 2492, 4582, 2045, 6117],\n",
       " [2909, 7496, 5644, 4291, 5558, 7429, 7233, 2583, 1496, 0],\n",
       " [2645, 4143, 1519, 2738, 4307, 1496, 0, 0, 0, 0],\n",
       " [6771, 2568, 4779, 6131, 0, 0, 0, 0, 0, 0],\n",
       " [2698, 1512, 2813, 6568, 3925, 4885, 4587, 4146, 0, 0],\n",
       " [2821, 3376, 2038, 2909, 5593, 6611, 654, 685, 469, 6725],\n",
       " [2294, 1940, 3756, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5625, 3756, 836, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2783, 1478, 3221, 2198, 1214, 6725, 6771, 2198, 6771, 3724],\n",
       " [48, 5289, 6194, 3122, 3752, 3396, 5009, 48, 493, 5444],\n",
       " [2550, 5826, 2396, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 900, 203, 4507, 0, 0, 0, 0, 0, 0],\n",
       " [7539, 5540, 3620, 1484, 1821, 873, 1997, 4604, 948, 4590],\n",
       " [1962, 889, 4655, 5481, 2715, 556, 743, 1, 2153, 5981],\n",
       " [145, 7464, 1484, 6134, 1712, 0, 0, 0, 0, 0],\n",
       " [4868, 2492, 6891, 1287, 6578, 3752, 5294, 638, 0, 0],\n",
       " [5717, 633, 3662, 2461, 5241, 0, 0, 0, 0, 0],\n",
       " [7160, 821, 2909, 2605, 779, 5376, 5612, 0, 0, 0],\n",
       " [2884, 207, 1053, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3438, 7128, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7513, 7539, 4353, 3574, 0, 0, 0, 0, 0, 0],\n",
       " [5960, 2606, 2884, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2186, 3883, 2752, 6662, 1770, 5003, 0, 0, 0, 0],\n",
       " [6552, 2742, 5834, 7128, 4721, 4317, 0, 0, 0, 0],\n",
       " [1849, 139, 2568, 5605, 3910, 2541, 0, 0, 0, 0],\n",
       " [6314, 1840, 3859, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7426, 6484, 6895, 2638, 396, 5299, 6244, 6461, 280, 2790],\n",
       " [4507, 5061, 6314, 6874, 6540, 0, 0, 0, 0, 0],\n",
       " [4602, 900, 6775, 5462, 7240, 3129, 2720, 1675, 6895, 4602],\n",
       " [5947, 3041, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 5540, 3574, 1351, 4390, 2711, 3522, 5540, 6918, 5423],\n",
       " [4291, 4063, 4192, 2510, 6725, 4363, 1213, 6580, 7397, 4580],\n",
       " [7315, 5248, 304, 900, 4262, 5910, 6322, 0, 0, 0],\n",
       " [6771, 3925, 6874, 1774, 4710, 5935, 6874, 968, 2247, 6070],\n",
       " [2813, 1242, 1913, 4896, 4173, 0, 0, 0, 0, 0],\n",
       " [3603, 6146, 6360, 552, 6360, 6359, 3588, 226, 1273, 1840],\n",
       " [1519, 2541, 4112, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2461, 2409, 7037, 1392, 1435, 5410, 5388, 5760, 3756, 6140],\n",
       " [1519, 2509, 5452, 4848, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 535, 1632, 7426, 3045, 0, 0, 0, 0, 0],\n",
       " [7447, 6752, 207, 427, 7290, 4848, 0, 0, 0, 0],\n",
       " [6406, 3925, 5910, 5649, 6578, 6771, 2190, 1486, 2038, 2233],\n",
       " [5046, 4499, 3756, 1224, 6870, 0, 0, 0, 0, 0],\n",
       " [3041, 3651, 1170, 3620, 835, 6118, 6140, 0, 0, 0],\n",
       " [7498, 7203, 5235, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4291, 6458, 331, 7211, 5799, 3704, 4779, 1735, 330, 6874],\n",
       " [6771, 5587, 80, 3692, 3829, 1296, 6778, 5443, 6484, 6874],\n",
       " [6604, 2186, 2762, 3521, 989, 950, 0, 0, 0, 0],\n",
       " [4871, 6375, 6918, 437, 1731, 6024, 0, 0, 0, 0],\n",
       " [4509, 5701, 3913, 5764, 5960, 618, 0, 0, 0, 0],\n",
       " [205, 6597, 6771, 1484, 3045, 486, 2078, 7068, 5248, 3620],\n",
       " [6771, 1735, 5318, 4526, 1237, 0, 0, 0, 0, 0],\n",
       " [3531, 5481, 7097, 1627, 1735, 5839, 0, 0, 0, 0],\n",
       " [367, 900, 4507, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3362, 7275, 527, 4249, 3116, 0, 0, 0, 0, 0],\n",
       " [1627, 7290, 4499, 4507, 2552, 3041, 2164, 5240, 6540, 7034],\n",
       " [1285, 6874, 445, 1010, 7007, 2478, 2642, 2312, 1968, 7252],\n",
       " [5215, 895, 1795, 1548, 1545, 3996, 2875, 0, 0, 0],\n",
       " [7136, 6874, 3723, 554, 245, 7194, 6771, 1695, 6314, 5637],\n",
       " [1719, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6855, 1496, 201, 5703, 1242, 6314, 7247, 7080, 6905, 6314],\n",
       " [3045, 472, 3578, 3454, 7489, 5240, 0, 0, 0, 0],\n",
       " [1735, 4258, 1977, 1731, 2461, 472, 6504, 3045, 2754, 0],\n",
       " [4049, 7507, 460, 4307, 3314, 6257, 0, 0, 0, 0],\n",
       " [3730, 4262, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6696, 1296, 5333, 4482, 6961, 2702, 279, 4285, 3996, 6839],\n",
       " [3231, 4700, 4280, 4006, 1224, 6578, 6484, 0, 0, 0],\n",
       " [7513, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [280, 3045, 2509, 5718, 1187, 5754, 1731, 7454, 1821, 1682],\n",
       " [3777, 5394, 6874, 342, 2671, 0, 0, 0, 0, 0],\n",
       " [2813, 5248, 2914, 7051, 1053, 5593, 4219, 6406, 2923, 6406],\n",
       " [1654, 1224, 6891, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7048, 4852, 6698, 5921, 0, 0, 0, 0, 0, 0],\n",
       " [6244, 7454, 6106, 6696, 2461, 2875, 0, 0, 0, 0],\n",
       " [6874, 5396, 5640, 1038, 2312, 1380, 2509, 1177, 1122, 1298],\n",
       " [2061, 1759, 2220, 3269, 0, 0, 0, 0, 0, 0],\n",
       " [5396, 1175, 2461, 6789, 5785, 1050, 4063, 7107, 1122, 6642],\n",
       " [1224, 4165, 5953, 4230, 5799, 0, 0, 0, 0, 0],\n",
       " [4317, 1941, 260, 1496, 4112, 1224, 5981, 7080, 3897, 5863],\n",
       " [2866, 719, 5981, 4966, 2455, 2866, 7007, 262, 1849, 5169],\n",
       " [6898, 2651, 3986, 7128, 6314, 960, 0, 0, 0, 0],\n",
       " [4463, 625, 1224, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6378, 5413, 3801, 2472, 6444, 0, 0, 0, 0, 0],\n",
       " [449, 3041, 5593, 654, 0, 0, 0, 0, 0, 0],\n",
       " [5625, 6768, 2261, 3620, 0, 0, 0, 0, 0, 0],\n",
       " [1731, 2699, 1015, 2376, 6281, 7454, 0, 0, 0, 0],\n",
       " [2568, 900, 6634, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7136, 6771, 4027, 5910, 4779, 1552, 5981, 6771, 4779, 5981],\n",
       " [4507, 367, 4090, 2110, 0, 0, 0, 0, 0, 0],\n",
       " [4515, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7426, 6484, 6906, 2662, 6106, 4714, 3529, 4317, 2461, 138],\n",
       " [3351, 3986, 1224, 6624, 1152, 3589, 1842, 0, 0, 0],\n",
       " [4507, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 464, 3045, 1399, 2485, 2342, 5182, 6771, 2492, 900],\n",
       " [3603, 3910, 3708, 3724, 3603, 3724, 4760, 3603, 7297, 900],\n",
       " [1527, 3821, 6628, 6141, 6860, 6629, 3692, 4521, 1877, 5203],\n",
       " [2813, 6597, 4223, 2421, 130, 0, 0, 0, 0, 0],\n",
       " [2679, 6771, 2294, 2146, 6176, 1447, 6918, 930, 7290, 0],\n",
       " [4562, 2568, 654, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4166, 876, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [41, 1559, 3964, 5343, 4868, 0, 0, 0, 0, 0],\n",
       " [6566, 1432, 3897, 1146, 2312, 934, 4808, 6862, 4733, 2509],\n",
       " [6837, 5799, 2509, 2660, 7315, 307, 0, 0, 0, 0],\n",
       " [2989, 6364, 3829, 1384, 1941, 3603, 1632, 4884, 3387, 4537],\n",
       " [950, 4822, 4808, 5388, 4847, 5616, 3964, 0, 0, 0],\n",
       " [4262, 1200, 5462, 6609, 593, 6540, 7107, 195, 0, 0],\n",
       " [449, 5318, 3529, 6540, 2568, 5908, 2828, 2208, 6540, 1633],\n",
       " [5705, 5248, 5714, 5553, 950, 3048, 5585, 1549, 4317, 6771],\n",
       " [4499, 7080, 2261, 2341, 7051, 2509, 3909, 6624, 0, 0],\n",
       " [7269, 64, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5850, 32, 677, 1486, 6772, 5416, 14, 6832, 3422, 1065],\n",
       " [7513, 5317, 6484, 723, 0, 0, 0, 0, 0, 0],\n",
       " [3294, 367, 6771, 7048, 3925, 0, 0, 0, 0, 0],\n",
       " [3679, 7425, 2346, 2704, 6511, 1003, 6771, 7275, 873, 6170],\n",
       " [6451, 1065, 4293, 5605, 1298, 2405, 6617, 2567, 460, 6024],\n",
       " [2413, 3399, 325, 726, 0, 0, 0, 0, 0, 0],\n",
       " [6578, 37, 1508, 37, 812, 5793, 3730, 1519, 611, 1165],\n",
       " [6484, 6874, 5854, 7211, 7107, 7112, 5176, 6406, 4860, 4413],\n",
       " [5540, 2781, 2492, 900, 2342, 2568, 4090, 2750, 1552, 873],\n",
       " [2821, 7080, 6771, 1496, 4380, 7083, 5243, 6874, 6831, 2909],\n",
       " [3806, 1496, 2605, 1496, 0, 0, 0, 0, 0, 0],\n",
       " [3432, 2715, 4929, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2858, 2651, 2509, 3381, 4210, 4969, 7466, 2680, 1823, 6309],\n",
       " [5248, 1813, 2342, 3045, 107, 0, 0, 0, 0, 0],\n",
       " [1534, 4548, 4063, 4163, 1966, 6860, 3537, 1217, 934, 4063],\n",
       " [1200, 893, 2651, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3959, 1130, 460, 3724, 7407, 3427, 0, 0, 0, 0],\n",
       " [2813, 1735, 2509, 7068, 3946, 3772, 2680, 0, 0, 0],\n",
       " [1414, 6771, 6378, 4972, 3045, 2535, 456, 654, 3486, 1187],\n",
       " [7315, 2605, 7128, 2655, 1340, 3925, 801, 5410, 5923, 2461],\n",
       " [5063, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [923, 900, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 1457, 6578, 1152, 0, 0, 0, 0, 0, 0],\n",
       " [3018, 5540, 6430, 2541, 5764, 7128, 3454, 6668, 5273, 5238],\n",
       " [1313, 6406, 7489, 4700, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 5238, 6406, 5625, 3913, 3307, 5238, 3615, 0, 0],\n",
       " [3434, 3405, 4134, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3898, 1340, 2461, 723, 6607, 5370, 3054, 5915, 0, 0],\n",
       " [900, 2460, 4754, 4762, 4019, 900, 2167, 3630, 6954, 38],\n",
       " [1035, 3986, 2034, 5935, 6977, 5051, 6086, 4808, 4434, 1935],\n",
       " [6923, 1496, 5982, 7211, 5176, 6314, 4710, 6698, 3611, 5616],\n",
       " [6306, 2884, 460, 6106, 0, 0, 0, 0, 0, 0],\n",
       " [1313, 1224, 2742, 7217, 1648, 0, 0, 0, 0, 0],\n",
       " [5830, 6246, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 3041, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 900, 5388, 900, 2699, 4808, 0, 0, 0, 0],\n",
       " [4507, 6430, 2605, 3708, 0, 0, 0, 0, 0, 0],\n",
       " [6314, 4956, 1224, 6455, 4192, 6406, 4405, 2715, 5238, 4537],\n",
       " [6771, 2826, 6137, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3139, 3620, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5793, 1158, 6765, 5432, 648, 5898, 7452, 0, 0, 0],\n",
       " [2649, 2509, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1615, 7460, 3332, 5539, 6874, 3821, 989, 2970, 2742, 5625],\n",
       " [4537, 5852, 5025, 5063, 0, 0, 0, 0, 0, 0],\n",
       " [2107, 5664, 1722, 5643, 6725, 6789, 6257, 6725, 1332, 4762],\n",
       " [1065, 5248, 4027, 5593, 3277, 2605, 4101, 0, 0, 0],\n",
       " [4216, 950, 2790, 3221, 4288, 3164, 0, 0, 0, 0],\n",
       " [7489, 960, 2927, 2690, 3045, 2509, 285, 0, 0, 0],\n",
       " [6578, 5947, 1497, 2042, 245, 2042, 4022, 2989, 4884, 4884],\n",
       " [7464, 2662, 2042, 2178, 4166, 4262, 166, 3261, 6696, 2178],\n",
       " [3756, 3178, 4018, 4018, 126, 7347, 0, 0, 0, 0],\n",
       " [6425, 911, 5540, 2715, 4534, 5791, 2191, 5318, 3974, 3135],\n",
       " [1285, 6874, 445, 1010, 7007, 2478, 2642, 2312, 1968, 7252],\n",
       " [6874, 992, 1427, 4966, 3824, 6874, 994, 5616, 990, 4889],\n",
       " [3045, 64, 7290, 7290, 2038, 5826, 3531, 5780, 3045, 6819],\n",
       " [2784, 2568, 6052, 241, 3687, 7081, 1206, 3387, 4956, 0],\n",
       " [2672, 2672, 1313, 1313, 1093, 1096, 0, 0, 0, 0],\n",
       " [4499, 4507, 5061, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1065, 413, 6079, 5388, 0, 0, 0, 0, 0, 0],\n",
       " [866, 6696, 2198, 4291, 7429, 3692, 2293, 2186, 3925, 0],\n",
       " [2541, 112, 6226, 1495, 1496, 5293, 2715, 180, 783, 147],\n",
       " [7128, 3454, 7516, 6314, 965, 7303, 0, 0, 0, 0],\n",
       " [6861, 3790, 4483, 3537, 4129, 5933, 4363, 2312, 694, 1751],\n",
       " [1671, 1199, 5439, 6118, 3964, 5333, 6118, 7385, 1432, 5640],\n",
       " [7067, 6828, 2461, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1313, 6406, 7489, 5240, 0, 0, 0, 0, 0, 0],\n",
       " [2783, 762, 2441, 4027, 195, 7266, 7231, 569, 1415, 3724],\n",
       " [6015, 569, 7128, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 2509, 531, 4149, 4280, 3756, 3996, 0, 0, 0],\n",
       " [950, 3387, 6322, 4760, 6244, 4733, 128, 5036, 4847, 6378],\n",
       " [6425, 5396, 4588, 5286, 1044, 2429, 4762, 7107, 6851, 279],\n",
       " [5540, 2711, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1340, 5599, 3931, 1631, 5272, 2078, 0, 0, 0, 0],\n",
       " [7128, 6461, 3708, 6481, 2711, 3629, 4291, 7429, 5762, 511],\n",
       " [3387, 4734, 5402, 798, 0, 0, 0, 0, 0, 0],\n",
       " [6342, 5215, 5789, 900, 5850, 3620, 564, 2750, 6949, 5085],\n",
       " [2651, 6430, 7303, 4192, 3454, 6461, 7080, 707, 5329, 3045],\n",
       " [7426, 6244, 2492, 1348, 4018, 6668, 7041, 0, 0, 0],\n",
       " [2813, 3565, 633, 1514, 6314, 965, 0, 0, 0, 0],\n",
       " [2813, 3531, 130, 3925, 0, 0, 0, 0, 0, 0],\n",
       " [1751, 3996, 6725, 4101, 2312, 693, 4584, 427, 5931, 4363],\n",
       " [6632, 4140, 4646, 3600, 0, 0, 0, 0, 0, 0],\n",
       " [1432, 4848, 900, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4048, 6540, 1735, 3620, 2379, 0, 0, 0, 0, 0],\n",
       " [4163, 2690, 5036, 4584, 3630, 5327, 3537, 934, 4808, 2312],\n",
       " [7513, 3772, 843, 6771, 1856, 195, 0, 0, 0, 0],\n",
       " [2968, 3531, 2301, 1651, 0, 0, 0, 0, 0, 0],\n",
       " [2813, 5521, 2509, 3150, 4834, 3410, 0, 0, 0, 0],\n",
       " [4112, 4507, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7425, 6484, 4485, 3519, 5427, 6484, 6430, 3529, 1496, 1627],\n",
       " [4822, 753, 3178, 6540, 2509, 0, 0, 0, 0, 0],\n",
       " [4768, 445, 896, 2045, 6765, 4104, 1427, 4537, 4101, 4772],\n",
       " [65, 5826, 6106, 3986, 6771, 900, 472, 6406, 2583, 5415],\n",
       " [207, 5148, 866, 5148, 4826, 373, 2081, 4537, 4563, 4760],\n",
       " [2541, 2038, 5789, 159, 5486, 7027, 2715, 4298, 2585, 2516],\n",
       " [2862, 7051, 1037, 2169, 5172, 1458, 7049, 2461, 6298, 79],\n",
       " [2312, 5396, 6406, 2208, 4919, 6406, 2461, 6709, 6618, 2790],\n",
       " [1519, 1064, 6322, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2685, 1374, 5703, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4368, 6430, 2711, 6537, 2461, 6504, 0, 0, 0, 0],\n",
       " [7440, 2605, 3663, 3790, 6693, 860, 3756, 6070, 2927, 0],\n",
       " [2680, 2461, 6895, 1786, 6898, 3839, 3454, 3708, 6116, 0],\n",
       " [7128, 5837, 1667, 1152, 4885, 2130, 1480, 2909, 1496, 4507],\n",
       " [2784, 2541, 7107, 2107, 1783, 5915, 3535, 0, 0, 0],\n",
       " [2754, 6662, 865, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3969, 6406, 4027, 5618, 4027, 4434, 4027, 5626, 4027, 4027],\n",
       " [1224, 5427, 4913, 3171, 4852, 7110, 0, 0, 0, 0],\n",
       " [1187, 7051, 6481, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4515, 3041, 2509, 7417, 3292, 5815, 321, 4604, 2509, 1139],\n",
       " [798, 2884, 7137, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1486, 5640, 900, 741, 0, 0, 0, 0, 0, 0],\n",
       " [7163, 1735, 6771, 7051, 5826, 0, 0, 0, 0, 0],\n",
       " [197, 4291, 2512, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2312, 1968, 7112, 1248, 6406, 7285, 7211, 6348, 7404, 0],\n",
       " [197, 3041, 2752, 4018, 6406, 3925, 0, 0, 0, 0],\n",
       " [5616, 3673, 6874, 3730, 4223, 3304, 2765, 6725, 3724, 4223],\n",
       " [7444, 3529, 7107, 3045, 6314, 3652, 900, 0, 0, 0],\n",
       " [5910, 1296, 1486, 5640, 1962, 4808, 2107, 7471, 2190, 900],\n",
       " [5800, 2921, 131, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6878, 4063, 4434, 445, 5055, 2642, 900, 3509, 3630, 1146],\n",
       " [5616, 6874, 2342, 5263, 5915, 6874, 7000, 5979, 1992, 1103],\n",
       " [4507, 5689, 4507, 2651, 0, 0, 0, 0, 0, 0],\n",
       " [8, 1519, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4664, 6886, 6481, 1922, 0, 0, 0, 0, 0, 0],\n",
       " [2014, 7539, 3999, 2492, 3614, 1187, 2568, 960, 6578, 0],\n",
       " [7262, 873, 700, 960, 6881, 7012, 6880, 2994, 5727, 3756],\n",
       " [2884, 7068, 6752, 3700, 0, 0, 0, 0, 0, 0],\n",
       " [6906, 6314, 2173, 2368, 4018, 5355, 7425, 5169, 0, 0],\n",
       " [1284, 4363, 6961, 934, 4808, 900, 900, 1332, 4974, 435],\n",
       " [723, 6529, 4929, 0, 0, 0, 0, 0, 0, 0],\n",
       " [427, 3045, 3620, 5388, 341, 2833, 226, 3756, 6420, 0],\n",
       " [3964, 5625, 369, 3756, 1726, 5732, 4733, 3756, 3756, 0],\n",
       " [367, 2395, 3160, 3221, 6597, 6131, 3620, 6388, 6540, 195],\n",
       " [3687, 298, 2368, 6314, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 2909, 6771, 2461, 6732, 2731, 2437, 3996, 3531, 6484],\n",
       " [3620, 3724, 346, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7446, 5248, 2607, 6597, 3362, 611, 1386, 5470, 7301, 6659],\n",
       " [6240, 7034, 2638, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4504, 5539, 6655, 1647, 886, 2294, 2626, 3594, 0, 0],\n",
       " [5947, 3041, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [2813, 2813, 7145, 4094, 5540, 4096, 2936, 2562, 2939, 1716],\n",
       " [5947, 535, 1632, 1224, 3045, 2461, 2588, 7173, 4848, 0],\n",
       " [7128, 1731, 676, 1883, 7426, 3418, 5318, 7311, 2856, 0],\n",
       " [7275, 2461, 1267, 1519, 3454, 3999, 2051, 0, 0, 0],\n",
       " [3679, 3806, 4852, 4291, 7429, 0, 0, 0, 0, 0],\n",
       " [3996, 3535, 3351, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2707, 3711, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6425, 2909, 2541, 1496, 6578, 0, 0, 0, 0, 0],\n",
       " [3443, 1598, 7051, 6680, 1961, 0, 0, 0, 0, 0],\n",
       " [4507, 6378, 6080, 7426, 6659, 4576, 6481, 3065, 4101, 0],\n",
       " [3664, 5142, 2890, 6389, 7126, 5033, 5296, 6106, 2790, 900],\n",
       " [5754, 5754, 6484, 3041, 2509, 3829, 4591, 6711, 0, 0],\n",
       " [3692, 216, 6875, 561, 3136, 7268, 3620, 6771, 3708, 3454],\n",
       " [2909, 6430, 5365, 1292, 3136, 3417, 6070, 367, 4985, 3636],\n",
       " [900, 1332, 2651, 3183, 477, 4027, 7407, 4262, 7407, 7051],\n",
       " [2509, 6520, 1636, 2149, 1538, 1319, 3092, 2758, 2051, 593],\n",
       " [6771, 2509, 4808, 2539, 1632, 6080, 0, 0, 0, 0],\n",
       " [2605, 4288, 618, 1496, 2492, 2038, 5252, 6425, 2516, 0],\n",
       " [6863, 4584, 1432, 3897, 1146, 2312, 934, 4808, 6862, 3742],\n",
       " [5947, 3041, 900, 3535, 4507, 882, 0, 0, 0, 0],\n",
       " [4507, 7080, 5192, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2605, 5045, 3724, 2492, 5263, 4583, 1713, 6178, 2131, 4952],\n",
       " [1735, 5148, 6170, 5410, 3387, 2461, 5840, 0, 0, 0],\n",
       " [2509, 5387, 637, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7513, 4262, 3041, 3332, 7029, 1835, 5193, 6118, 0, 0],\n",
       " [3850, 1242, 6378, 3516, 0, 0, 0, 0, 0, 0],\n",
       " [4516, 1519, 1492, 2186, 4395, 1213, 6391, 2879, 990, 446],\n",
       " [3687, 5780, 5570, 5044, 0, 0, 0, 0, 0, 0],\n",
       " [4390, 3913, 4090, 1962, 48, 506, 5323, 2221, 5219, 5910],\n",
       " [7051, 2461, 3501, 6624, 7051, 5243, 1710, 3668, 5625, 1657],\n",
       " [4307, 3630, 5481, 808, 2765, 4884, 1735, 1420, 6540, 3108],\n",
       " [4507, 3045, 2539, 2752, 6898, 3620, 2173, 4018, 0, 0],\n",
       " [3724, 7, 6771, 3708, 0, 0, 0, 0, 0, 0],\n",
       " [6393, 141, 3798, 5063, 0, 0, 0, 0, 0, 0],\n",
       " [3351, 4822, 260, 6420, 7489, 1731, 0, 0, 0, 0],\n",
       " [7171, 2662, 2461, 472, 2395, 5481, 6484, 6080, 3906, 0],\n",
       " [190, 5593, 6771, 5584, 0, 0, 0, 0, 0, 0],\n",
       " [7464, 978, 2342, 195, 367, 7290, 7110, 0, 0, 0],\n",
       " [7068, 6752, 3700, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6425, 466, 950, 7029, 6337, 5243, 6481, 0, 0, 0],\n",
       " [1037, 2136, 3263, 6524, 2098, 0, 0, 0, 0, 0],\n",
       " [7211, 5248, 5760, 3687, 6540, 0, 0, 0, 0, 0],\n",
       " [2312, 3964, 63, 2312, 6406, 3964, 5333, 3964, 7285, 2312],\n",
       " [1519, 5235, 5192, 2711, 0, 0, 0, 0, 0, 0],\n",
       " [1578, 5164, 7051, 6768, 5625, 758, 2085, 2501, 7051, 5205],\n",
       " [6484, 3221, 2167, 5616, 6405, 3964, 0, 0, 0, 0],\n",
       " [5947, 3839, 48, 1782, 7315, 7051, 1340, 6670, 472, 2690],\n",
       " [1284, 7429, 5981, 1140, 4714, 900, 4405, 886, 6242, 6918],\n",
       " [5952, 3925, 3041, 900, 3535, 0, 0, 0, 0, 0],\n",
       " [1152, 3756, 5371, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2312, 4417, 900, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2568, 3930, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4375, 6484, 2509, 4086, 5947, 5333, 3531, 0, 0, 0],\n",
       " [6597, 36, 1278, 6709, 0, 0, 0, 0, 0, 0],\n",
       " [3376, 3240, 5258, 1018, 3178, 5388, 0, 0, 0, 0],\n",
       " [1519, 5235, 5427, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2176, 7297, 1849, 6771, 1908, 7211, 3704, 827, 2177, 1167],\n",
       " [7539, 1224, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1065, 4432, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3681, 7139, 2209, 7072, 0, 0, 0, 0, 0, 0],\n",
       " [1285, 7107, 1248, 1770, 6771, 5055, 1146, 900, 456, 6354],\n",
       " [7029, 1835, 960, 1484, 733, 7067, 1187, 7029, 4628, 2568],\n",
       " [3898, 7151, 2999, 4700, 6975, 4848, 4251, 2929, 0, 0],\n",
       " [3454, 2933, 266, 798, 4090, 3221, 5558, 2144, 4733, 5326],\n",
       " [7160, 5766, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4566, 3242, 3481, 3723, 5770, 6007, 1043, 3896, 6179, 5775],\n",
       " [3537, 2635, 6106, 5573, 220, 7051, 2492, 4291, 156, 6696],\n",
       " [4981, 5956, 2765, 3045, 5946, 0, 0, 0, 0, 0],\n",
       " [3679, 4507, 2279, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4361, 1037, 6338, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2642, 3537, 4363, 4808, 2428, 3165, 4137, 4862, 5056, 6725],\n",
       " [5884, 1248, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [713, 6617, 4654, 5333, 4919, 4098, 1891, 4919, 1027, 1027],\n",
       " [1378, 6642, 2955, 5325, 4839, 6419, 0, 0, 0, 0],\n",
       " [7080, 6682, 3586, 5065, 5521, 4317, 7080, 6771, 7051, 367],\n",
       " [6906, 4779, 6809, 6430, 1105, 90, 3897, 590, 21, 3041],\n",
       " [6430, 1859, 3986, 3586, 1923, 0, 0, 0, 0, 0],\n",
       " [5670, 1224, 2461, 4823, 0, 0, 0, 0, 0, 0],\n",
       " [2539, 2509, 2461, 6303, 0, 0, 0, 0, 0, 0],\n",
       " [6430, 5453, 938, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6878, 4063, 445, 719, 906, 5055, 1, 4249, 400, 1296],\n",
       " [2821, 7275, 456, 321, 1130, 1955, 4210, 3959, 3790, 0],\n",
       " [6578, 4483, 1146, 6874, 7309, 1671, 7008, 6406, 7425, 4405],\n",
       " [7442, 5029, 3495, 3620, 5785, 0, 0, 0, 0, 0],\n",
       " [5270, 6617, 7239, 4280, 2944, 6395, 1271, 4868, 5593, 1039],\n",
       " [3261, 5540, 7489, 1752, 0, 0, 0, 0, 0, 0],\n",
       " [5053, 48, 6077, 5738, 6844, 5773, 4913, 900, 3024, 1199],\n",
       " [6585, 2881, 7290, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2649, 2509, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3041, 3531, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3221, 900, 2909, 3744, 3832, 3454, 4027, 2662, 4027, 505],\n",
       " [2541, 112, 3725, 2523, 1496, 2909, 3898, 2568, 3556, 3296],\n",
       " [5062, 2539, 5593, 3535, 6624, 3750, 0, 0, 0, 0],\n",
       " [3898, 2121, 2197, 5022, 872, 1707, 3454, 0, 0, 0],\n",
       " [6799, 3850, 3850, 2715, 5370, 1496, 1519, 6272, 2765, 2715],\n",
       " [6555, 1447, 6070, 4485, 900, 0, 0, 0, 0, 0],\n",
       " [7359, 4103, 3838, 6353, 7092, 120, 6118, 6725, 6118, 0],\n",
       " [2105, 5181, 1604, 17, 3645, 274, 6808, 7240, 3704, 6386],\n",
       " [2509, 1214, 4655, 1922, 3041, 1224, 5606, 4655, 0, 0],\n",
       " [4471, 4002, 522, 2221, 4852, 0, 0, 0, 0, 0],\n",
       " [2485, 6080, 569, 2485, 1707, 4262, 5275, 6540, 3018, 5221],\n",
       " [5981, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3454, 4262, 2461, 2924, 2568, 3156, 291, 897, 6272, 1224],\n",
       " [5947, 6632, 3687, 4532, 0, 0, 0, 0, 0, 0],\n",
       " [7029, 3756, 3996, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4507, 2492, 4018, 6484, 5593, 833, 7489, 179, 1435, 2685],\n",
       " [3048, 2186, 2461, 5786, 531, 5148, 4656, 3898, 2038, 1856],\n",
       " [2987, 3221, 7106, 3620, 6513, 1496, 0, 0, 0, 0],\n",
       " [6244, 2461, 54, 384, 6305, 2448, 2086, 1569, 683, 4459],\n",
       " [4507, 2045, 4317, 6314, 7056, 531, 1783, 1422, 3991, 7483],\n",
       " [3230, 3692, 2337, 4670, 989, 3219, 1060, 723, 4770, 6441],\n",
       " [7128, 6912, 1003, 4197, 6224, 3620, 2016, 6467, 0, 0],\n",
       " [3774, 4546, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3454, 2342, 195, 6597, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 5045, 6425, 4821, 5029, 0, 0, 0, 0, 0],\n",
       " [153, 6771, 207, 886, 1835, 4537, 1823, 28, 3931, 5333],\n",
       " [2821, 4149, 3932, 4485, 0, 0, 0, 0, 0, 0],\n",
       " [1835, 815, 6918, 4307, 0, 0, 0, 0, 0, 0],\n",
       " [2442, 3724, 4166, 514, 6063, 0, 0, 0, 0, 0],\n",
       " [2450, 6696, 1296, 3529, 7110, 1770, 5738, 5055, 2642, 900],\n",
       " [2368, 460, 4027, 195, 3454, 950, 3589, 5616, 4090, 6662],\n",
       " [3041, 900, 6771, 4147, 4332, 73, 3016, 215, 2318, 7275],\n",
       " [4559, 569, 5386, 2069, 6484, 0, 0, 0, 0, 0],\n",
       " [280, 2509, 2666, 7162, 3724, 5863, 2909, 4507, 2541, 1496],\n",
       " [3724, 3188, 1453, 3829, 5570, 4873, 2509, 5823, 373, 1623],\n",
       " [7311, 6771, 7049, 4029, 0, 0, 0, 0, 0, 0],\n",
       " [7418, 3700, 7029, 4180, 2198, 5556, 3772, 3700, 7186, 4112],\n",
       " [3454, 3488, 2524, 7139, 0, 0, 0, 0, 0, 0],\n",
       " [4563, 1744, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7029, 900, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4375, 7029, 5556, 1453, 0, 0, 0, 0, 0, 0],\n",
       " [990, 5056, 1146, 900, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 6552, 330, 7107, 7107, 7051, 3041, 0, 0, 0],\n",
       " [7539, 7029, 5556, 2198, 321, 0, 0, 0, 0, 0],\n",
       " [4063, 4434, 1146, 900, 6891, 472, 5394, 1146, 2923, 3630],\n",
       " [339, 3869, 6771, 5182, 7039, 6823, 5877, 656, 6771, 827],\n",
       " [2968, 1842, 7539, 1651, 4628, 3225, 0, 0, 0, 0],\n",
       " [4507, 280, 4262, 1037, 5481, 0, 0, 0, 0, 0],\n",
       " [6696, 1296, 5333, 4482, 3996, 6408, 4291, 6961, 4808, 900],\n",
       " [2068, 20, 3412, 7051, 3412, 4537, 1496, 0, 0, 0],\n",
       " [2933, 5564, 2909, 5738, 3293, 6390, 6314, 965, 3652, 1774],\n",
       " [6378, 6771, 2753, 7051, 6895, 2927, 5758, 6540, 0, 0],\n",
       " [1821, 6490, 3041, 5174, 7454, 2858, 2509, 3265, 7467, 4604],\n",
       " [4789, 4868, 5394, 3933, 2725, 2570, 1378, 0, 0, 0],\n",
       " [7407, 6046, 618, 7458, 6498, 0, 0, 0, 0, 0],\n",
       " [3045, 3925, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [6874, 1035, 7211, 7252, 5718, 6031, 6725, 5718, 6721, 7403],\n",
       " [5981, 5605, 5263, 4966, 446, 900, 3630, 1167, 1332, 4974],\n",
       " [5053, 48, 6077, 5738, 6844, 4913, 900, 3024, 1199, 1983],\n",
       " [6106, 2590, 5035, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3974, 6137, 1122, 2342, 3687, 7297, 6063, 2346, 4288, 1941],\n",
       " [2606, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2645, 4143, 1519, 4307, 1496, 0, 0, 0, 0, 0],\n",
       " [3059, 1432, 5640, 255, 900, 2325, 4405, 0, 0, 0],\n",
       " [1899, 6673, 4112, 4166, 7217, 4827, 5826, 7128, 0, 0],\n",
       " [3045, 2509, 873, 4180, 5018, 316, 0, 0, 0, 0],\n",
       " [3999, 669, 6724, 4469, 5201, 6118, 6279, 3088, 4470, 0],\n",
       " [6771, 5616, 2884, 2208, 4507, 3700, 3045, 5240, 7454, 0],\n",
       " [5979, 990, 7454, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2715, 1224, 4372, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3925, 3772, 3487, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6314, 965, 4210, 2461, 7128, 5935, 0, 0, 0, 0],\n",
       " [1179, 4118, 5901, 5981, 7529, 4310, 4698, 5430, 3495, 1],\n",
       " [3913, 5540, 950, 7029, 5593, 6771, 2461, 733, 790, 509],\n",
       " [4286, 3999, 4507, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2191, 3053, 2461, 1783, 5916, 7051, 1224, 2190, 0, 0],\n",
       " [1496, 3409, 4477, 2029, 6771, 3394, 1486, 3537, 4296, 5365],\n",
       " [6923, 2405, 5616, 1615, 4149, 6874, 2342, 262, 5182, 5910],\n",
       " [3850, 1578, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6578, 1021, 4307, 1000, 435, 2190, 6540, 4495, 4499, 7128],\n",
       " [900, 5481, 2836, 1122, 2391, 0, 0, 0, 0, 0],\n",
       " [2715, 6923, 1496, 3454, 1842, 2976, 2703, 561, 7231, 6506],\n",
       " [3620, 6918, 5714, 3574, 1187, 6378, 5750, 3620, 6378, 3583],\n",
       " [2102, 2715, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1224, 4210, 4822, 7539, 1224, 3054, 110, 6874, 3588, 0],\n",
       " [3589, 5888, 3589, 5888, 3417, 7091, 798, 4972, 6588, 2346],\n",
       " [1519, 2568, 3756, 1726, 2821, 2821, 0, 0, 0, 0],\n",
       " [2541, 7285, 7285, 3897, 3565, 6771, 1677, 3850, 6540, 0],\n",
       " [3829, 6244, 168, 3454, 652, 2173, 4018, 2110, 7489, 1268],\n",
       " [5947, 2568, 6481, 3897, 5125, 3535, 0, 0, 0, 0],\n",
       " [4216, 6134, 798, 837, 1783, 5915, 6430, 65, 3651, 6895],\n",
       " [2680, 2541, 2762, 3045, 4490, 4663, 3865, 6420, 0, 0],\n",
       " [3850, 3600, 6314, 2461, 1018, 6641, 4939, 0, 0, 0],\n",
       " [7513, 6490, 5182, 1835, 6360, 5481, 3829, 2078, 3692, 3689],\n",
       " [4291, 6410, 1053, 2914, 2662, 6874, 323, 4654, 2312, 5263],\n",
       " [6578, 6998, 4434, 1941, 5605, 5263, 445, 4434, 3883, 900],\n",
       " [4868, 1735, 5540, 3620, 2821, 2821, 2821, 0, 0, 0],\n",
       " [6425, 6772, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4499, 2293, 3964, 6506, 5616, 0, 0, 0, 0, 0],\n",
       " [2568, 5647, 4966, 5646, 2976, 4047, 7541, 2909, 4507, 0],\n",
       " [1519, 7007, 2876, 1146, 7107, 4482, 4741, 2509, 2956, 6721],\n",
       " [4210, 2387, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6275, 2909, 3417, 1497, 4537, 3662, 5252, 5863, 644, 0],\n",
       " [7539, 3672, 1484, 6540, 1452, 2157, 7539, 2884, 0, 0],\n",
       " [5739, 464, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [368, 6771, 5169, 2927, 262, 0, 0, 0, 0, 0],\n",
       " [7128, 3053, 1552, 4262, 5360, 6426, 3041, 3589, 3454, 3045],\n",
       " [5481, 3427, 3427, 950, 5960, 1888, 2562, 3839, 3183, 2751],\n",
       " [5062, 2539, 6281, 7104, 654, 0, 0, 0, 0, 0],\n",
       " [7407, 4307, 5240, 6526, 0, 0, 0, 0, 0, 0],\n",
       " [188, 773, 864, 6316, 6673, 6702, 3910, 7158, 885, 3313],\n",
       " [7068, 988, 3645, 4191, 226, 2035, 2509, 6387, 226, 1136],\n",
       " [3999, 367, 2711, 1735, 5540, 6807, 0, 0, 0, 0],\n",
       " [5053, 48, 6077, 5738, 6844, 4913, 900, 3024, 1199, 1983],\n",
       " [5061, 5616, 1926, 0, 0, 0, 0, 0, 0, 0],\n",
       " [990, 5056, 1146, 900, 6348, 5446, 6259, 6048, 4974, 0],\n",
       " [6430, 1314, 5918, 5846, 2451, 5929, 5431, 2720, 0, 0],\n",
       " [3045, 2539, 5540, 5947, 7315, 4380, 6070, 4674, 6540, 5947],\n",
       " [7029, 3454, 7146, 6663, 614, 2782, 1798, 0, 0, 0],\n",
       " [2191, 4027, 4166, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 2568, 4779, 6131, 0, 0, 0, 0, 0, 0],\n",
       " [6378, 1796, 1515, 2461, 3057, 0, 0, 0, 0, 0],\n",
       " [6217, 950, 1224, 1847, 5616, 3779, 5225, 1173, 950, 1224],\n",
       " [4848, 3839, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1707, 3829, 5621, 6314, 6837, 2312, 4262, 3454, 7202, 0],\n",
       " [5008, 4808, 5640, 900, 0, 0, 0, 0, 0, 0],\n",
       " [5580, 3547, 5415, 5415, 1972, 1972, 4683, 4683, 7285, 0],\n",
       " [4180, 5331, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 2509, 2884, 2208, 1453, 1224, 2157, 7539, 3535, 0],\n",
       " [3565, 1511, 6070, 5010, 4280, 0, 0, 0, 0, 0],\n",
       " [7425, 466, 6166, 4952, 3364, 6256, 0, 0, 0, 0],\n",
       " [1938, 1093, 4227, 491, 4149, 3363, 6361, 0, 0, 0],\n",
       " [979, 4018, 6106, 4262, 873, 0, 0, 0, 0, 0],\n",
       " [4733, 3752, 3504, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2541, 2039, 6736, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 5263, 4149, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2867, 2867, 633, 597, 3540, 5593, 7407, 6607, 0, 0],\n",
       " [5850, 32, 6217, 4956, 2789, 5598, 1313, 7051, 5540, 2821],\n",
       " [2461, 6874, 6052, 5396, 2312, 4405, 5333, 4149, 6617, 2583],\n",
       " [1684, 7275, 7303, 5540, 274, 271, 3620, 5481, 3529, 4317],\n",
       " [3221, 2568, 3756, 7080, 1340, 4822, 0, 0, 0, 0],\n",
       " [1735, 3462, 4655, 1783, 3991, 0, 0, 0, 0, 0],\n",
       " [3899, 5540, 2821, 2190, 2568, 961, 2605, 2009, 7153, 0],\n",
       " [4833, 5182, 6771, 444, 614, 6875, 6106, 5826, 3045, 2509],\n",
       " [1003, 3045, 2310, 3679, 0, 0, 0, 0, 0, 0],\n",
       " [4027, 900, 1003, 7435, 5568, 4027, 6771, 950, 7029, 6771],\n",
       " [4848, 6322, 1987, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7539, 3671, 7067, 5578, 0, 0, 0, 0, 0, 0],\n",
       " [2509, 1835, 3772, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 3045, 6200, 7429, 4526, 7290, 3520, 3724, 5579, 6406],\n",
       " [7051, 367, 7539, 7029, 2198, 3566, 1187, 3566, 2198, 2927],\n",
       " [2198, 7290, 7454, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2045, 3420, 1384, 464, 2045, 2605, 846, 3854, 3066, 6771],\n",
       " [1524, 1082, 989, 6771, 5182, 1224, 1194, 4847, 900, 627],\n",
       " [6425, 3724, 6648, 711, 0, 0, 0, 0, 0, 0],\n",
       " [2293, 4868, 900, 3054, 6877, 3964, 7029, 0, 0, 0],\n",
       " [2112, 4563, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 6704, 6771, 873, 1452, 633, 5852, 5521, 4210, 6217],\n",
       " [5793, 3545, 2909, 2605, 4101, 5540, 2813, 18, 0, 0],\n",
       " [5138, 6170, 6578, 3821, 4896, 701, 4434, 0, 0, 0],\n",
       " [130, 4935, 3692, 3620, 3041, 5061, 5616, 3521, 2461, 2167],\n",
       " [2541, 2541, 3296, 3620, 1967, 0, 0, 0, 0, 0],\n",
       " [145, 1167, 6106, 341, 168, 4848, 0, 0, 0, 0],\n",
       " [3925, 1323, 6052, 4628, 2412, 7542, 5593, 3999, 7294, 0],\n",
       " [4180, 367, 7539, 873, 2261, 2884, 0, 0, 0, 0],\n",
       " [3478, 201, 1735, 4149, 5333, 4149, 0, 0, 0, 0],\n",
       " [4166, 5182, 7539, 7207, 4733, 0, 0, 0, 0, 0],\n",
       " [5947, 3041, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [3059, 5030, 1556, 2492, 1961, 2242, 0, 0, 0, 0],\n",
       " [6430, 654, 7121, 2038, 6240, 2711, 2541, 3021, 6244, 5126],\n",
       " [6709, 1521, 5521, 4995, 2038, 2153, 5958, 5871, 6540, 0],\n",
       " [1735, 6484, 2461, 447, 6694, 3687, 2102, 6663, 5947, 0],\n",
       " [7049, 2666, 2729, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5174, 3531, 3522, 321, 280, 7356, 456, 1789, 0, 0],\n",
       " [5374, 3387, 2109, 4363, 4302, 2405, 1539, 1175, 4363, 2509],\n",
       " [4163, 2690, 5036, 4584, 3630, 5327, 3537, 934, 4808, 2312],\n",
       " [2778, 1276, 97, 5080, 7141, 904, 226, 7141, 368, 5794],\n",
       " [5598, 3620, 7121, 6540, 4317, 2395, 7051, 1224, 5868, 1496],\n",
       " [228, 1332, 4654, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5537, 6142, 4779, 1745, 48, 5616, 48, 1598, 4090, 5625],\n",
       " [201, 3454, 3772, 3952, 1447, 3454, 0, 0, 0, 0],\n",
       " [6170, 5610, 3041, 6378, 0, 0, 0, 0, 0, 0],\n",
       " [6878, 4249, 400, 1296, 6773, 900, 456, 6351, 902, 4974],\n",
       " [723, 3588, 4149, 900, 7290, 6100, 3045, 2509, 2461, 5980],\n",
       " [2642, 990, 5055, 1146, 7504, 5055, 900, 1432, 5640, 5337],\n",
       " [3796, 1735, 2146, 6868, 380, 4001, 4537, 2038, 7274, 4852],\n",
       " [4499, 5616, 73, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5655, 279, 611, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7272, 2376, 2230, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7407, 2038, 1312, 3273, 0, 0, 0, 0, 0, 0],\n",
       " [7297, 5462, 6107, 2146, 5500, 3208, 83, 3810, 1327, 3589],\n",
       " [2568, 3188, 3692, 5574, 1453, 7051, 1856, 4317, 3688, 0],\n",
       " [1187, 3522, 3045, 457, 1471, 4507, 4885, 3700, 6771, 4288],\n",
       " [197, 4532, 2574, 1037, 4588, 2691, 0, 0, 0, 0],\n",
       " [1839, 280, 2110, 3291, 6166, 6986, 0, 0, 0, 0],\n",
       " [1823, 6771, 367, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1926, 171, 3278, 6098, 3382, 3739, 5015, 1804, 3645, 1926],\n",
       " [1627, 6032, 1224, 1842, 7422, 0, 0, 0, 0, 0],\n",
       " [3679, 7275, 2146, 477, 6895, 4090, 6314, 6085, 1651, 0],\n",
       " [2038, 6771, 1735, 2461, 6704, 1310, 6375, 6759, 6375, 4271],\n",
       " [3565, 5156, 6626, 5581, 4570, 7139, 2120, 69, 6874, 4997],\n",
       " [4537, 6322, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6425, 3692, 5248, 304, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 1432, 3742, 4484, 4291, 4363, 4063, 6727, 6725, 7285],\n",
       " [7231, 4405, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2680, 3898, 6875, 5406, 6771, 3454, 7128, 1447, 2146, 3620],\n",
       " [7425, 2495, 3806, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7128, 3651, 6540, 6481, 2541, 6540, 132, 0, 0, 0],\n",
       " [2568, 5427, 5935, 7542, 2677, 5148, 1166, 472, 6537, 5736],\n",
       " [4507, 3897, 2312, 2666, 0, 0, 0, 0, 0, 0],\n",
       " [3946, 3620, 5729, 3495, 2427, 2071, 0, 0, 0, 0],\n",
       " [1823, 3332, 5540, 2509, 3601, 6540, 0, 0, 0, 0],\n",
       " [5089, 6314, 2541, 965, 5044, 5462, 4868, 5616, 4821, 2461],\n",
       " [6771, 6187, 611, 4063, 1298, 5640, 6789, 4762, 1496, 5616],\n",
       " [5252, 7154, 6018, 7429, 280, 2605, 7107, 611, 1840, 0],\n",
       " [4086, 4280, 7107, 2492, 2376, 2490, 0, 0, 0, 0],\n",
       " [5247, 7429, 7128, 6509, 4526, 3495, 5462, 341, 6340, 0],\n",
       " [3059, 1432, 5640, 255, 5007, 0, 0, 0, 0, 0],\n",
       " [1735, 2482, 3641, 1005, 0, 0, 0, 0, 0, 0],\n",
       " [2461, 3599, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5244, 5951, 1735, 5272, 4434, 1282, 5182, 6771, 4870, 0],\n",
       " [1627, 2882, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [950, 6484, 272, 5975, 5427, 6642, 2752, 0, 0, 0],\n",
       " [2092, 3829, 6481, 4955, 3829, 6481, 7295, 3829, 6481, 562],\n",
       " [6771, 3806, 303, 0, 0, 0, 0, 0, 0, 0],\n",
       " [900, 7474, 3176, 4808, 6956, 60, 3986, 2762, 6406, 0],\n",
       " [5423, 4697, 4317, 2228, 723, 4280, 7429, 900, 6721, 301],\n",
       " [2592, 4499, 1519, 6771, 6106, 3041, 2153, 5705, 4112, 6484],\n",
       " [6877, 6874, 2642, 445, 6106, 6806, 900, 1171, 1147, 4048],\n",
       " [4390, 3332, 6655, 6771, 7315, 367, 1187, 6771, 457, 2640],\n",
       " [7231, 2102, 3959, 3790, 2715, 4291, 7429, 91, 0, 0],\n",
       " [6874, 445, 1141, 779, 1340, 7211, 6213, 5718, 6031, 2045],\n",
       " [3045, 4424, 2526, 2568, 5916, 6837, 3927, 1651, 3700, 2680],\n",
       " [5947, 3041, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [950, 4822, 4808, 5388, 4847, 5616, 3964, 0, 0, 0],\n",
       " [3679, 3455, 6475, 1768, 5558, 195, 1167, 6611, 293, 950],\n",
       " [2461, 281, 1462, 3296, 2986, 2799, 0, 0, 0, 0],\n",
       " [3680, 6771, 1802, 2685, 4084, 7426, 6106, 6624, 7067, 4852],\n",
       " [3019, 2461, 7090, 7080, 5705, 6759, 5435, 0, 0, 0],\n",
       " [7203, 3756, 4018, 2568, 5969, 0, 0, 0, 0, 0],\n",
       " [5830, 6246, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6425, 4822, 6683, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1735, 2509, 6378, 2342, 7489, 6244, 7051, 3652, 5868, 4166],\n",
       " [2821, 3376, 3724, 5593, 6624, 3041, 4808, 6611, 2568, 5783],\n",
       " [2715, 4291, 7429, 1519, 812, 5248, 4027, 2568, 4434, 1536],\n",
       " [3910, 2461, 1744, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4566, 3242, 3481, 3723, 5770, 6007, 1043, 3896, 6179, 5775],\n",
       " [2858, 6506, 5481, 2927, 5824, 3531, 5134, 0, 0, 0],\n",
       " [580, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3059, 1432, 5640, 255, 5007, 900, 2325, 4405, 0, 0],\n",
       " [1735, 6484, 6750, 3620, 5213, 7239, 3996, 4563, 0, 0],\n",
       " [6240, 1342, 3829, 5684, 6106, 6663, 6504, 0, 0, 0],\n",
       " [6540, 2167, 5991, 5918, 2461, 1254, 1635, 7285, 2509, 2178],\n",
       " [2042, 6506, 3652, 2541, 3603, 4766, 4710, 6725, 472, 4223],\n",
       " [2312, 6642, 4927, 6617, 900, 4237, 5219, 2461, 6646, 6747],\n",
       " [2645, 4143, 1519, 2738, 4307, 1496, 0, 0, 0, 0],\n",
       " [2909, 1955, 2405, 7452, 5947, 3221, 6658, 4847, 3454, 2258],\n",
       " [1835, 611, 6874, 1786, 6568, 0, 0, 0, 0, 0],\n",
       " [7515, 6771, 1711, 5960, 3620, 3252, 886, 6439, 160, 0],\n",
       " [4531, 7051, 5570, 7116, 3707, 7118, 7279, 0, 0, 0],\n",
       " [2448, 3183, 4537, 6811, 4402, 6771, 1625, 4829, 5342, 0],\n",
       " [5248, 2461, 2704, 341, 0, 0, 0, 0, 0, 0],\n",
       " [4584, 1432, 3897, 1146, 2312, 934, 4808, 6862, 3742, 900],\n",
       " [4792, 758, 7174, 2345, 6448, 1224, 946, 4306, 0, 0],\n",
       " [4507, 4149, 6771, 456, 3565, 2929, 0, 0, 0, 0],\n",
       " [2482, 3756, 4018, 126, 0, 0, 0, 0, 0, 0],\n",
       " [3529, 1036, 1146, 6874, 7309, 1671, 7007, 6579, 6406, 5718],\n",
       " [309, 3758, 2127, 6771, 1735, 3645, 6597, 6771, 6759, 0],\n",
       " [2312, 6052, 7108, 4363, 6617, 6874, 4063, 2045, 7107, 6725],\n",
       " [2642, 445, 2038, 995, 1146, 6874, 445, 900, 2312, 6118],\n",
       " [3351, 3041, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1692, 3056, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6244, 3829, 6244, 3454, 146, 5869, 7454, 0, 0, 0],\n",
       " [727, 207, 7290, 5174, 0, 0, 0, 0, 0, 0],\n",
       " [6314, 2690, 1496, 3565, 563, 7128, 0, 0, 0, 0],\n",
       " [6780, 1735, 7049, 2461, 569, 7056, 0, 0, 0, 0],\n",
       " [6051, 3756, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6461, 5394, 1224, 2662, 1336, 2478, 2391, 7502, 2837, 2837],\n",
       " [1285, 6874, 445, 1908, 1010, 2478, 7007, 2312, 1968, 7112],\n",
       " [740, 6874, 482, 4507, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 4618, 5774, 5699, 1830, 4883, 632, 6986, 5850, 59],\n",
       " [7173, 762, 4027, 2711, 0, 0, 0, 0, 0, 0],\n",
       " [3708, 6895, 4537, 460, 4074, 1707, 2790, 7480, 798, 2781],\n",
       " [201, 798, 2401, 1698, 0, 0, 0, 0, 0, 0],\n",
       " [5355, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [721, 461, 6771, 1957, 7491, 6771, 5598, 456, 2469, 7128],\n",
       " [2541, 112, 6069, 2933, 762, 1369, 7454, 50, 2368, 5787],\n",
       " [5410, 950, 6725, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5873, 7490, 6406, 1378, 4847, 2573, 7370, 3672, 5162, 6851],\n",
       " [4654, 173, 4106, 1105, 4262, 5930, 6874, 4059, 6378, 6874],\n",
       " [2541, 2039, 6736, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2856, 654, 4829, 3679, 5762, 0, 0, 0, 0, 0],\n",
       " [2681, 767, 1519, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2813, 2568, 3821, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 3615, 6750, 2612, 3913, 260, 2342, 7051, 3756, 7309],\n",
       " [6425, 7452, 5789, 7274, 2909, 1955, 859, 4080, 0, 0],\n",
       " [6771, 5587, 80, 5372, 6484, 6771, 5182, 5981, 900, 4574],\n",
       " [2821, 3884, 5466, 6771, 2738, 4307, 2873, 3964, 5540, 2783],\n",
       " [1519, 7007, 2876, 1146, 7107, 4482, 4741, 4868, 2509, 2956],\n",
       " [6425, 4166, 5819, 7236, 3485, 6243, 1627, 2461, 4872, 1242],\n",
       " [6244, 5365, 4482, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2541, 4112, 1519, 2605, 226, 6194, 1496, 0, 0, 0],\n",
       " [7051, 279, 4285, 3996, 6406, 4291, 6961, 4808, 2214, 4966],\n",
       " [5789, 3531, 4733, 5326, 4721, 4101, 4733, 3756, 1044, 2153],\n",
       " [6696, 1296, 4482, 4291, 6961, 4808, 279, 4285, 3996, 2690],\n",
       " [3529, 1035, 1146, 6874, 7309, 1671, 7009, 7425, 4408, 4482],\n",
       " [3779, 6771, 5934, 4166, 6771, 1741, 6814, 5981, 6771, 5182],\n",
       " [4847, 5616, 1258, 3821, 3045, 4733, 4166, 0, 0, 0],\n",
       " [4994, 4124, 4714, 447, 3529, 4317, 4995, 2102, 0, 0],\n",
       " [6878, 900, 3510, 1256, 3006, 2879, 990, 443, 1213, 5475],\n",
       " [3444, 2509, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3914, 5705, 6208, 439, 1536, 2492, 6891, 3756, 5585, 7057],\n",
       " [6113, 6520, 4166, 6684, 6269, 950, 1856, 618, 3704, 7117],\n",
       " [4489, 3894, 4418, 900, 779, 0, 0, 0, 0, 0],\n",
       " [7426, 6461, 514, 1961, 5427, 6765, 6891, 3850, 2368, 5715],\n",
       " [6578, 4483, 1146, 6874, 7309, 1671, 7008, 6406, 7425, 4405],\n",
       " [6771, 5235, 4587, 195, 6771, 7047, 2509, 873, 6529, 2208],\n",
       " [5243, 466, 7051, 798, 3115, 6534, 0, 0, 0, 0],\n",
       " [1447, 5462, 63, 2376, 6950, 1447, 0, 0, 0, 0],\n",
       " [130, 4936, 467, 6876, 619, 3780, 5071, 4637, 7290, 2813],\n",
       " [6118, 6131, 3221, 6597, 3221, 5370, 2750, 5540, 4588, 0],\n",
       " [6322, 5651, 3829, 4291, 2342, 2099, 3724, 7297, 1672, 6406],\n",
       " [2509, 6314, 460, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2683, 234, 6604, 1224, 4112, 3752, 3041, 5523, 2509, 5449],\n",
       " [6022, 4509, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5540, 5908, 4223, 6329, 0, 0, 0, 0, 0, 0],\n",
       " [7290, 2509, 3996, 0, 0, 0, 0, 0, 0, 0],\n",
       " [812, 2449, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 2651, 7169, 2461, 2875, 1287, 3898, 2927, 6765, 3041],\n",
       " [6771, 2190, 6540, 835, 1357, 4262, 5953, 6170, 0, 0],\n",
       " [1813, 3221, 5593, 3713, 1330, 3531, 0, 0, 0, 0],\n",
       " [1285, 6874, 445, 1908, 7504, 6235, 1010, 6982, 5273, 4208],\n",
       " [1291, 7040, 854, 5705, 3059, 4288, 4860, 4745, 2651, 4848],\n",
       " [5053, 48, 6077, 5738, 6844, 4913, 900, 3024, 1199, 1983],\n",
       " [2783, 4262, 4950, 646, 1040, 6897, 6697, 5076, 1034, 5148],\n",
       " [6771, 7051, 3790, 2312, 6406, 3964, 4291, 6961, 4808, 2690],\n",
       " [7128, 4490, 4804, 2877, 6771, 7049, 900, 2884, 5240, 5538],\n",
       " [2509, 2555, 5066, 6106, 4262, 3651, 1979, 6814, 215, 1432],\n",
       " [3041, 6406, 1793, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6780, 3687, 1496, 3045, 1899, 7051, 1415, 6314, 4229, 0],\n",
       " [6322, 395, 1498, 4608, 4027, 611, 2342, 7298, 5669, 5692],\n",
       " [5718, 6538, 6771, 1793, 1908, 3351, 3351, 990, 6686, 7007],\n",
       " [997, 4262, 5593, 5915, 0, 0, 0, 0, 0, 0],\n",
       " [6225, 5176, 7252, 5155, 7211, 6642, 5931, 1830, 4862, 6771],\n",
       " [6771, 5587, 80, 3692, 3829, 1296, 6778, 5443, 6484, 6874],\n",
       " [6771, 5587, 80, 3692, 3829, 1296, 6778, 5443, 6484, 6874],\n",
       " [5322, 1759, 1298, 195, 4663, 2573, 2950, 4205, 6752, 1213],\n",
       " [5593, 3451, 2492, 779, 6540, 7314, 3556, 207, 7051, 4027],\n",
       " [3724, 2492, 3877, 6895, 3708, 464, 4505, 2131, 4952, 0],\n",
       " [1813, 2509, 6228, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7503, 6771, 3454, 1037, 4775, 1786, 3794, 6892, 2220, 1786],\n",
       " [2476, 6847, 2991, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3620, 6322, 4655, 20, 1735, 3454, 0, 0, 0, 0],\n",
       " [1821, 1435, 5726, 3574, 6771, 1821, 3620, 130, 2088, 5684],\n",
       " [6803, 2087, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7199, 3451, 6540, 4188, 1839, 0, 0, 0, 0, 0],\n",
       " [367, 5044, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2605, 5045, 6484, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4444, 1440, 1410, 1411, 1409, 1406, 1405, 3029, 0, 0],\n",
       " [4507, 4353, 6875, 866, 3045, 5248, 733, 4149, 6771, 4604],\n",
       " [1707, 2395, 1152, 1842, 6611, 6523, 5734, 6696, 5868, 3756],\n",
       " [6230, 6506, 2597, 6771, 1735, 2051, 6771, 7051, 3910, 6771],\n",
       " [2909, 2541, 7107, 1065, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 6895, 2909, 122, 1735, 1793, 5780, 3221, 723, 6481],\n",
       " [6526, 4317, 7426, 6244, 6481, 7128, 7290, 0, 0, 0],\n",
       " [2312, 5396, 7029, 1213, 5777, 6406, 4719, 3980, 6949, 2461],\n",
       " [5062, 4090, 7303, 6481, 1224, 1816, 5648, 4630, 3158, 7290],\n",
       " [4954, 6359, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7274, 4808, 535, 7139, 1512, 6378, 3724, 460, 0, 0],\n",
       " [3724, 5860, 835, 146, 6574, 0, 0, 0, 0, 0],\n",
       " [2461, 7303, 1583, 6344, 195, 380, 7308, 0, 0, 0],\n",
       " [2813, 7160, 1047, 5947, 3531, 5333, 0, 0, 0, 0],\n",
       " [3530, 6093, 3866, 1690, 5184, 3598, 6151, 7211, 4371, 2405],\n",
       " [3041, 2492, 4878, 5481, 2619, 2614, 7169, 5979, 0, 0],\n",
       " [7183, 2371, 4591, 6129, 0, 0, 0, 0, 0, 0],\n",
       " [3256, 3834, 5489, 2923, 2423, 1053, 1062, 900, 4237, 5219],\n",
       " [3724, 1, 1224, 6632, 3687, 3565, 7518, 2568, 7285, 7462],\n",
       " [5947, 2989, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [950, 2146, 4244, 3045, 4844, 1627, 1856, 6272, 7107, 1003],\n",
       " [4507, 3700, 1842, 6106, 5085, 3925, 0, 0, 0, 0],\n",
       " [900, 1447, 7029, 900, 0, 0, 0, 0, 0, 0],\n",
       " [1340, 367, 978, 1340, 2461, 269, 1922, 1116, 0, 0],\n",
       " [65, 5616, 5322, 6578, 7274, 7110, 0, 0, 0, 0],\n",
       " [4760, 5593, 4149, 6484, 3003, 72, 4150, 7339, 552, 1735],\n",
       " [2813, 2422, 4813, 5299, 1786, 130, 6568, 7049, 3925, 7423],\n",
       " [1735, 6322, 2042, 4507, 7285, 0, 0, 0, 0, 0],\n",
       " [6771, 7048, 5593, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7080, 5558, 4847, 5616, 363, 4434, 0, 0, 0, 0],\n",
       " [5670, 2191, 432, 2883, 0, 0, 0, 0, 0, 0],\n",
       " [7139, 402, 260, 6765, 5432, 6581, 6106, 1631, 5235, 2884],\n",
       " [65, 1559, 4526, 7098, 679, 3816, 0, 0, 0, 0],\n",
       " [3351, 7029, 1098, 5616, 114, 3756, 3996, 0, 0, 0],\n",
       " [3045, 1634, 390, 3850, 5835, 4846, 7452, 6780, 3045, 207],\n",
       " [3407, 2492, 3482, 34, 1598, 0, 0, 0, 0, 0],\n",
       " [4499, 1224, 130, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4091, 5182, 3766, 7219, 1, 1146, 5055, 6406, 4090, 3994],\n",
       " [3045, 5248, 5947, 7275, 456, 20, 2340, 6771, 2190, 204],\n",
       " [1285, 4589, 4057, 4649, 7018, 1955, 7231, 3850, 2715, 4084],\n",
       " [5501, 5733, 7454, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6540, 6484, 7483, 4262, 3454, 4251, 938, 0, 0, 0],\n",
       " [1519, 3895, 4868, 900, 3510, 1256, 3761, 6391, 2879, 990],\n",
       " [1821, 7089, 3270, 3700, 0, 0, 0, 0, 0, 0],\n",
       " [5780, 5760, 2158, 7005, 0, 0, 0, 0, 0, 0],\n",
       " [3435, 1214, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6878, 900, 3510, 1256, 6391, 2879, 990, 443, 1213, 5475],\n",
       " [618, 3806, 2339, 6169, 3620, 4832, 7452, 2146, 671, 3562],\n",
       " [5610, 7128, 6616, 1203, 5610, 1203, 5910, 6520, 4740, 7002],\n",
       " [6475, 3708, 4848, 2919, 3921, 4848, 5477, 0, 0, 0],\n",
       " [2461, 6658, 2254, 7029, 1242, 6725, 472, 4223, 120, 4574],\n",
       " [201, 3221, 5954, 690, 1348, 6540, 5265, 3018, 5221, 6406],\n",
       " [5625, 5562, 5943, 5586, 302, 5558, 6484, 6484, 301, 5342],\n",
       " [950, 7029, 5593, 7471, 4813, 6895, 0, 0, 0, 0],\n",
       " [6874, 992, 1427, 4966, 3824, 6874, 994, 5616, 2509, 4889],\n",
       " [2813, 723, 3381, 5521, 195, 3588, 2509, 130, 3387, 5521],\n",
       " [1118, 6874, 601, 4148, 1624, 0, 0, 0, 0, 0],\n",
       " [6540, 7051, 1224, 0, 0, 0, 0, 0, 0, 0],\n",
       " [449, 3578, 3454, 7169, 7489, 341, 0, 0, 0, 0],\n",
       " [5682, 456, 4507, 3700, 0, 0, 0, 0, 0, 0],\n",
       " [561, 6715, 2601, 5238, 965, 2765, 2146, 3615, 5910, 2146],\n",
       " [201, 5318, 2461, 1698, 756, 960, 0, 0, 0, 0],\n",
       " [2184, 6131, 2485, 7029, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 886, 6874, 4149, 7418, 3700, 4936, 6481, 4537, 4317],\n",
       " [3724, 3183, 1538, 2146, 1340, 1536, 3724, 3603, 7315, 4166],\n",
       " [7135, 293, 5368, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5953, 1199, 34, 506, 4242, 5333, 1278, 3221, 5625, 5388],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 6244, 6771, 950, 6314, 5758, 6540, 0, 0, 0],\n",
       " [6878, 6696, 1296, 6771, 6578, 1770, 5738, 5055, 2642, 900],\n",
       " [7068, 988, 3645, 4191, 226, 2035, 2509, 6387, 226, 1136],\n",
       " [7464, 1029, 2668, 1152, 7049, 6314, 5795, 5540, 1129, 1152],\n",
       " [4166, 876, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [618, 6106, 1000, 3589, 367, 5610, 3756, 0, 0, 0],\n",
       " [6244, 4317, 3952, 3454, 4372, 3952, 0, 0, 0, 0],\n",
       " [6771, 7051, 1224, 474, 561, 4260, 6595, 2765, 7494, 2492],\n",
       " [7207, 2509, 314, 1152, 0, 0, 0, 0, 0, 0],\n",
       " [7275, 456, 6696, 5953, 2929, 4507, 0, 0, 0, 0],\n",
       " [7418, 3700, 7047, 2509, 886, 2918, 5185, 6578, 3817, 1856],\n",
       " [2680, 449, 4532, 472, 0, 0, 0, 0, 0, 0],\n",
       " [7513, 6490, 1835, 5718, 1167, 3700, 0, 0, 0, 0],\n",
       " [48, 4434, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1898, 6771, 5616, 7342, 3522, 0, 0, 0, 0, 0],\n",
       " [2813, 67, 1367, 4337, 735, 7240, 7407, 709, 6771, 733],\n",
       " [4507, 5670, 6322, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1735, 2812, 3454, 5585, 6540, 7087, 3620, 3387, 4389, 1856],\n",
       " [2813, 4733, 5487, 1511, 3756, 0, 0, 0, 0, 0],\n",
       " [260, 4101, 4262, 1120, 7105, 166, 0, 0, 0, 0],\n",
       " [6070, 5581, 2461, 3296, 1503, 2605, 4963, 6319, 0, 0],\n",
       " [5271, 4262, 6663, 1904, 7037, 983, 0, 0, 0, 0],\n",
       " [1284, 4063, 2395, 6964, 5182, 900, 4405, 6962, 7194, 3884],\n",
       " [3692, 2369, 6540, 2368, 6484, 0, 0, 0, 0, 0],\n",
       " [7464, 2651, 1793, 0, 0, 0, 0, 0, 0, 0],\n",
       " [978, 5540, 2781, 4165, 3756, 4018, 0, 0, 0, 0],\n",
       " [3045, 4485, 900, 3756, 3996, 0, 0, 0, 0, 0],\n",
       " [2441, 4027, 195, 3454, 6484, 2368, 950, 7029, 6538, 4280],\n",
       " [7509, 140, 6776, 4537, 5540, 7539, 7047, 900, 6613, 3692],\n",
       " [6780, 2574, 1786, 472, 5576, 3487, 870, 5944, 0, 0],\n",
       " [6420, 3337, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 3045, 5305, 6540, 2043, 2461, 2045, 1497, 4706, 2541],\n",
       " [7539, 7539, 7047, 1224, 1224, 3700, 1647, 886, 6150, 5816],\n",
       " [3790, 6131, 4745, 3790, 4149, 3724, 3790, 4020, 3283, 2738],\n",
       " [950, 1735, 4435, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1037, 1835, 4537, 4280, 2008, 0, 0, 0, 0, 0],\n",
       " [7456, 3045, 1152, 5462, 7072, 3829, 4507, 4847, 0, 0],\n",
       " [3708, 2711, 2146, 5173, 616, 417, 1048, 7290, 3708, 2780],\n",
       " [7539, 7029, 835, 6118, 110, 6874, 3566, 3522, 1821, 886],\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(sms['label']=='ham', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split in batch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "xarray = np.array(padded_sentence)\n",
    "yarray = np.array(y)\n",
    "\n",
    "ix_train = int(xarray.shape[0]*0.7)\n",
    "ix_valid = int(xarray.shape[0]*0.85)\n",
    "\n",
    "X_train = torch.tensor(xarray[:ix_train], dtype = torch.long)\n",
    "Y_train = torch.tensor(yarray[:ix_train], dtype = torch.long)\n",
    "\n",
    "X_valid = torch.tensor(xarray[ix_train:ix_valid], dtype = torch.long)\n",
    "Y_valid = torch.tensor(yarray[ix_train:ix_valid], dtype = torch.long)\n",
    "\n",
    "X_test = torch.tensor(xarray[ix_valid:], dtype = torch.long)\n",
    "Y_test = torch.tensor(yarray[ix_valid:], dtype = torch.long)\n",
    "\n",
    "Batch=60\n",
    "train = TensorDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train, batch_size = Batch, shuffle = True, drop_last=True)\n",
    "\n",
    "valid = TensorDataset(X_valid, Y_valid)\n",
    "valid_loader = DataLoader(valid, batch_size = Batch, shuffle = False, drop_last=True)\n",
    "\n",
    "test = TensorDataset(X_test, Y_test)\n",
    "test_loader = DataLoader(test, batch_size = Batch, shuffle = False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model class\n",
    "\n",
    "class GRUSpam(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embedding, emed_dim, batch, seq_len, inp_sz, rnn_hid_sz, nlayer, fc_in1,fc_out2):\n",
    "        super(GRUSpam, self).__init__()\n",
    "        \n",
    "        self.num_embedding = num_embedding\n",
    "        self.emed_dim = emed_dim\n",
    "        self.batch = batch\n",
    "        self.seq_len = seq_len\n",
    "        self.inp_sz = inp_sz\n",
    "        self.rnn_hid_sz = rnn_hid_sz\n",
    "        self.nlayer = nlayer\n",
    "        self.fc_in1 = fc_in1\n",
    "        self.fc_out = fc_out2\n",
    "        self.embed = nn.Embedding(self.num_embedding, self.emed_dim)\n",
    "        self.rnn = nn.GRU(self.inp_sz,self.rnn_hid_sz,self.nlayer)\n",
    "        self.fc1 = nn.Linear(self.fc_in1, self.fc_out)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = x.view(self.seq_len, self.batch, self.inp_sz)\n",
    "        hidden = torch.randn(self.nlayer, self.batch, self.rnn_hid_sz)\n",
    "        x, hidden = self.rnn(x, hidden)\n",
    "        x = x.view(self.batch, self.fc_in1)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = self.softmax(x)\n",
    "        return (x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7549"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "num_embedding = len(vocab)\n",
    "embed_dim = 50\n",
    "batch = Batch\n",
    "seq_len = xarray.shape[1]\n",
    "inp_sz = embed_dim\n",
    "rnn_hid_sz = 100\n",
    "nlayer = 1\n",
    "fc_in1 = rnn_hid_sz*seq_len\n",
    "out_sz = 2\n",
    "fc_out2 = out_sz\n",
    "\n",
    "model = GRUSpam(num_embedding, embed_dim, batch, seq_len, inp_sz, rnn_hid_sz, nlayer, fc_in1,fc_out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUSpam(\n",
      "  (embed): Embedding(7549, 50)\n",
      "  (rnn): GRU(50, 100)\n",
      "  (fc1): Linear(in_features=1000, out_features=2, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestAccuracy(pred, yt):\n",
    "    \n",
    "    pred_ix = pred.argmax(dim = 1)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc = accuracy_score(yt.numpy(), pred_ix.numpy())\n",
    "    return (np.round(acc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ValidationAnalysis(xtest, ytest):\n",
    "    valid_actual = []\n",
    "    valid_predict = []\n",
    "    avg_valid_loss = []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for xv, yv in valid_loader:\n",
    "            yp = model(xv)\n",
    "            pred_ix = yp.argmax(dim = 1)\n",
    "            valid_loss = criterion(yp, yv)\n",
    "            avg_valid_loss.append(valid_loss)\n",
    "            valid_predict.append(pred_ix.numpy())\n",
    "            valid_actual.append(yv.numpy())\n",
    "                     \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc = accuracy_score(np.array(valid_actual).reshape(-1,1), np.array(valid_predict).reshape(-1,1)) \n",
    "    return (yp, np.array(valid_predict).reshape(-1,1), np.array(valid_actual).reshape(-1,1), np.round(acc, 3), np.round(np.mean(avg_valid_loss),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EachAccuracyClass(yt, pt):\n",
    "    cls, ncls = np.unique(yt, return_counts = True)\n",
    "    acc = pd.DataFrame()\n",
    "    acc['ytest'] = yt.squeeze()\n",
    "    acc['pred'] = pt.squeeze()\n",
    "    class_acc = {}\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    for c in cls:\n",
    "        sig = acc.loc[acc.loc[acc['ytest']==c].index]\n",
    "        class_acc[str(c)] = round(accuracy_score(sig['ytest'], sig['pred'])*100, 2)\n",
    "    return (class_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Epoch: 0 |Train Loss: 0.6809999942779541 | Train Accuracy: 0.65 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 |Train Loss: 0.48399999737739563 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4830000102519989 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.47099998593330383 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.49000000953674316 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.5040000081062317 | Train Accuracy: 0.817 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.44999998807907104 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.49399998784065247 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.44600000977516174 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4959999918937683 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4880000054836273 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4950000047683716 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4860000014305115 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4860000014305115 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4819999933242798 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.5139999985694885 | Train Accuracy: 0.8 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4819999933242798 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.5329999923706055 | Train Accuracy: 0.8 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4790000021457672 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4729999899864197 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4729999899864197 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.49900001287460327 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.48399999737739563 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5220000147819519 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4230000078678131 | Train Accuracy: 0.95 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5109999775886536 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.48899999260902405 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5239999890327454 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4620000123977661 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.531000018119812 | Train Accuracy: 0.8 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.46799999475479126 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4959999918937683 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5360000133514404 | Train Accuracy: 0.8 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5230000019073486 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.49900001287460327 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4740000069141388 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4650000035762787 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4959999918937683 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4699999988079071 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4569999873638153 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.43299999833106995 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4399999976158142 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4429999887943268 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4620000123977661 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.45500001311302185 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4399999976158142 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 0 |Valid Loss: 0.4620000123977661 | Valid Accuracy: 0.895 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 1 |Train Loss: 0.4390000104904175 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4309999942779541 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4950000047683716 | Train Accuracy: 0.85 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 |Train Loss: 0.44200000166893005 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.42500001192092896 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.46000000834465027 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4480000138282776 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.460999995470047 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4309999942779541 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.48100000619888306 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.460999995470047 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.46799999475479126 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.45100000500679016 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4729999899864197 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4309999942779541 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4050000011920929 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4480000138282776 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4169999957084656 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4449999928474426 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4350000023841858 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4189999997615814 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.45100000500679016 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4189999997615814 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.421999990940094 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.42500001192092896 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.3889999985694885 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4390000104904175 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.421999990940094 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4519999921321869 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.421999990940094 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.40400001406669617 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.460999995470047 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.41499999165534973 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.453000009059906 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.421999990940094 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.45100000500679016 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 1 |Valid Loss: 0.4189999997615814 | Valid Accuracy: 0.954 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 2 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.41999998688697815 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.41600000858306885 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.38999998569488525 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.95 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.41600000858306885 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4230000078678131 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4320000112056732 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.41499999165534973 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.43799999356269836 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.45100000500679016 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.421999990940094 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4230000078678131 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.492000013589859 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.42800000309944153 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4300000071525574 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 2 |Valid Loss: 0.41999998688697815 | Valid Accuracy: 0.954 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 3 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4350000023841858 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.45100000500679016 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.40400001406669617 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.41600000858306885 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.41999998688697815 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.41999998688697815 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.42800000309944153 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.43799999356269836 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 3 |Valid Loss: 0.41600000858306885 | Valid Accuracy: 0.958 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 4 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.41600000858306885 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.41499999165534973 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4050000011920929 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4309999942779541 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.42500001192092896 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3889999985694885 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4180000126361847 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 4 |Valid Loss: 0.41200000047683716 | Valid Accuracy: 0.963 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 5 |Train Loss: 0.4050000011920929 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.983 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.40299999713897705 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4180000126361847 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.41999998688697815 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4309999942779541 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.44600000977516174 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 5 |Valid Loss: 0.41100001335144043 | Valid Accuracy: 0.964 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4169999957084656 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.40299999713897705 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.41999998688697815 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.40299999713897705 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.421999990940094 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 6 |Valid Loss: 0.41200000047683716 | Valid Accuracy: 0.964 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.43299999833106995 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4050000011920929 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.38999998569488525 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.41499999165534973 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 7 |Valid Loss: 0.4090000092983246 | Valid Accuracy: 0.965 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4350000023841858 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4050000011920929 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.42800000309944153 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 8 |Valid Loss: 0.40700000524520874 | Valid Accuracy: 0.971 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 9 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4050000011920929 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.40400001406669617 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 9 |Valid Loss: 0.40799999237060547 | Valid Accuracy: 0.969 | Valid-Class: [0 1] \n",
      "==================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.41600000858306885 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 10 |Valid Loss: 0.40799999237060547 | Valid Accuracy: 0.967 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3930000066757202 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.38999998569488525 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 11 |Valid Loss: 0.4129999876022339 | Valid Accuracy: 0.96 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 12 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.41600000858306885 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.40400001406669617 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 12 |Valid Loss: 0.4059999883174896 | Valid Accuracy: 0.971 | Valid-Class: [0 1] \n",
      "==================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4309999942779541 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 13 |Valid Loss: 0.4099999964237213 | Valid Accuracy: 0.964 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 14 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 14 |Valid Loss: 0.41100001335144043 | Valid Accuracy: 0.963 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4050000011920929 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 15 |Valid Loss: 0.4099999964237213 | Valid Accuracy: 0.967 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 16 |Valid Loss: 0.4090000092983246 | Valid Accuracy: 0.965 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 17 |Valid Loss: 0.41100001335144043 | Valid Accuracy: 0.967 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 18 |Valid Loss: 0.4099999964237213 | Valid Accuracy: 0.963 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 19 |Valid Loss: 0.4099999964237213 | Valid Accuracy: 0.964 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 20 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 20 |Valid Loss: 0.4099999964237213 | Valid Accuracy: 0.967 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 21 |Valid Loss: 0.41100001335144043 | Valid Accuracy: 0.962 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.4169999957084656 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 22 |Valid Loss: 0.41200000047683716 | Valid Accuracy: 0.968 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 23 |Valid Loss: 0.4099999964237213 | Valid Accuracy: 0.967 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 24 |Valid Loss: 0.4090000092983246 | Valid Accuracy: 0.967 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3919999897480011 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 25 |Valid Loss: 0.41100001335144043 | Valid Accuracy: 0.963 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.41999998688697815 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 26 |Valid Loss: 0.4050000011920929 | Valid Accuracy: 0.969 | Valid-Class: [0 1] \n",
      "==================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 27 |Valid Loss: 0.40700000524520874 | Valid Accuracy: 0.971 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 28 |Valid Loss: 0.41100001335144043 | Valid Accuracy: 0.963 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 29 |Valid Loss: 0.40700000524520874 | Valid Accuracy: 0.968 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3919999897480011 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 30 |Valid Loss: 0.4129999876022339 | Valid Accuracy: 0.969 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 31 |Valid Loss: 0.41100001335144043 | Valid Accuracy: 0.963 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 32 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 32 |Valid Loss: 0.40400001406669617 | Valid Accuracy: 0.973 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3919999897480011 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 33 |Valid Loss: 0.4050000011920929 | Valid Accuracy: 0.973 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.40400001406669617 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 34 |Valid Loss: 0.40400001406669617 | Valid Accuracy: 0.972 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 35 |Valid Loss: 0.4059999883174896 | Valid Accuracy: 0.971 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 36 |Valid Loss: 0.40299999713897705 | Valid Accuracy: 0.973 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3930000066757202 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 37 |Valid Loss: 0.40400001406669617 | Valid Accuracy: 0.972 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 38 |Valid Loss: 0.4009999930858612 | Valid Accuracy: 0.978 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 39 |Valid Loss: 0.40299999713897705 | Valid Accuracy: 0.976 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 40 |Valid Loss: 0.40400001406669617 | Valid Accuracy: 0.974 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 41 |Valid Loss: 0.40299999713897705 | Valid Accuracy: 0.974 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 42 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 42 |Valid Loss: 0.40400001406669617 | Valid Accuracy: 0.972 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.4050000011920929 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 43 |Valid Loss: 0.4059999883174896 | Valid Accuracy: 0.967 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 44 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3919999897480011 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 44 |Valid Loss: 0.40700000524520874 | Valid Accuracy: 0.968 | Valid-Class: [0 1] \n",
      "==================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 45 |Valid Loss: 0.40700000524520874 | Valid Accuracy: 0.971 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3889999985694885 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 46 |Valid Loss: 0.4099999964237213 | Valid Accuracy: 0.964 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.38999998569488525 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 47 |Valid Loss: 0.4090000092983246 | Valid Accuracy: 0.968 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.39399999380111694 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 48 |Valid Loss: 0.4090000092983246 | Valid Accuracy: 0.964 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.4189999997615814 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.39100000262260437 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 49 |Valid Loss: 0.40799999237060547 | Valid Accuracy: 0.963 | Valid-Class: [0 1] \n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "valid_losses = []\n",
    "valid_accuracy = []\n",
    "\n",
    "each_validp = []\n",
    "each_valida = []\n",
    "\n",
    "valid_zero_class_p = []\n",
    "valid_one_class_p = []\n",
    "\n",
    "print(\"Training started...\")\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    #############################[[[trainig]]]#########################################\n",
    "    train_losses = []\n",
    "    train_accuracy = []  \n",
    "    for n, tl in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        xt = tl[0]\n",
    "        yt = tl[1]\n",
    "        out = model(xt)\n",
    "        loss = criterion(out, yt)\n",
    "        train_losses.append(loss.detach())\n",
    "        train_acc= TestAccuracy(out, yt)\n",
    "        train_accuracy.append(train_acc)\n",
    "        #checking if training predicts both the classes \n",
    "        pred_train_ix = out.argmax(dim=1)\n",
    "        train_classes = np.unique(pred_train_ix.numpy())\n",
    "        print(\"Epoch: {} |Train Loss: {} | Train Accuracy: {} | Train-Class: {} \".format(e, np.round(np.array(loss.detach()),3), train_acc, train_classes))\n",
    "        \n",
    "        #############################[[[Validation]]]#########################################\n",
    "        \n",
    "        if (n == len(train_loader)-1):\n",
    "            pred_valid, validp_ix, valida_ix, valid_acc, valid_loss = ValidationAnalysis(X_valid, Y_valid)\n",
    "            each_validp.append(validp_ix)\n",
    "            each_valida.append(valida_ix)\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_accuracy.append(valid_acc)\n",
    "            pred_valid_ix = pred_valid.argmax(dim=1)\n",
    "            valid_classes = np.unique(pred_valid_ix.numpy())\n",
    "            each_class_pred = EachAccuracyClass(valida_ix, validp_ix)\n",
    "            valid_zero_class_p.append(each_class_pred['0'])\n",
    "            valid_one_class_p.append(each_class_pred['1'])\n",
    "            print(\"==================================================================================\")\n",
    "            print(\"Epoch: {} |Valid Loss: {} | Valid Accuracy: {} | Valid-Class: {} \".format(e, valid_loss, valid_acc, valid_classes))\n",
    "            print(\"==================================================================================\")\n",
    "        \n",
    "            #############################[[[Model Save]]]#########################################\n",
    "            if (len(valid_zero_class_p) > 2):\n",
    "                if (valid_zero_class_p[-2] < valid_zero_class_p[-1]):\n",
    "                    if (valid_one_class_p[-2] < valid_one_class_p[-1]):\n",
    "                        FILE = \"model_gru.pth\"\n",
    "                        torch.save(model, FILE)\n",
    "             \n",
    "        else:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valid_zero_class_p, label = 'Class 0')\n",
    "plt.plot(valid_one_class_p, label = 'Class 1')\n",
    "plt.title(\"Validation-Each class accuracy at each epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestAnalysis(model_saved, test_loader):\n",
    "    test_actual = []\n",
    "    test_predict = []\n",
    "\n",
    "    for xtst, ytst in test_loader:\n",
    "        yp = model_saved(xtst)\n",
    "        pred_ix = yp.argmax(dim = 1)\n",
    "        test_predict.append(pred_ix.numpy())\n",
    "        test_actual.append(ytst.numpy())\n",
    "        \n",
    "    return (np.array(test_predict).reshape(-1,1), np.array(test_actual).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUSpam(\n",
       "  (embed): Embedding(7549, 50)\n",
       "  (rnn): GRU(50, 100)\n",
       "  (fc1): Linear(in_features=1000, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "MODEL = torch.load(\"model_gru.pth\")\n",
    "MODEL.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "#test \n",
    "test_pred, test_actual = TestAnalysis(MODEL, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9717948717948718"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_actual, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 84.47, '1': 99.11}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each class accuracy\n",
    "\n",
    "EachAccuracyClass(test_actual, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

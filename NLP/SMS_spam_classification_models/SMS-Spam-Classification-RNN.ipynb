{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\perei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\perei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libaries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "\n",
    "sms = pd.read_csv(\"SMSSpamCollection.csv\", sep = '\\t', names = ['label', 'message'])\n",
    "sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_text = sms['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                 Will ü b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\perei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\perei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import TextCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TextCleaner.TextCleaner(text = sms_text, text_form = 'List', stemming = True, lemmat = False)\n",
    "text_clean = tc.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n",
       " 'ok lar joke wif u oni',\n",
       " 'free entri wkli comp win fa cup final tkt st may tet fa receiv entri questionstd tt ratetc appli over']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clean[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Go until jurong point, crazy.. Available only ...\n",
       "1                        Ok lar... Joking wif u oni...\n",
       "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once all the text is cleaned, we now have to create the vocabulary of the sms messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_vocab_text = ' '.join(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_vocab_words = sorted(pre_vocab_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(pre_vocab_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('<UNK>')\n",
    "vocab.add('<PAD>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'world!!!',\n",
       " 'it!!',\n",
       " 'growrandom!',\n",
       " 'fuckinnice!selfishdeviousbitchanywayi\\x92l',\n",
       " 'subscribegbpmnth',\n",
       " 'colin',\n",
       " 'shine',\n",
       " 'confer',\n",
       " 'babysit',\n",
       " 'nigeria',\n",
       " 'wwwsmsacugoldvik',\n",
       " 'finewhen',\n",
       " 'gokila',\n",
       " 'itriedtel',\n",
       " 'wordcollect',\n",
       " 'validhr',\n",
       " 'gyno',\n",
       " 'bthere',\n",
       " 'one!!',\n",
       " 'homeleft',\n",
       " 'hoo',\n",
       " 'html',\n",
       " 'mjzgroup',\n",
       " 'eruku',\n",
       " 'url',\n",
       " 'coin',\n",
       " 'wheat',\n",
       " 'prizeto',\n",
       " 'uniquei',\n",
       " 'urgent!!',\n",
       " 'fifti',\n",
       " 'vs',\n",
       " 'vibrat',\n",
       " 'dump',\n",
       " 'belong',\n",
       " 'conform',\n",
       " 'appt',\n",
       " 'danalla',\n",
       " 'e',\n",
       " 'hallaq',\n",
       " 'enjoy',\n",
       " 'yelowi',\n",
       " 'kvb',\n",
       " 'oga',\n",
       " 'ttauction!tt',\n",
       " 'arriv',\n",
       " 'heavi',\n",
       " 'outreach',\n",
       " 'huh',\n",
       " 'incid',\n",
       " 'anand',\n",
       " 'complaint',\n",
       " 'difficulti',\n",
       " 'jiayin',\n",
       " 'fund',\n",
       " 'lttimegt',\n",
       " 'officewhat',\n",
       " 'dawher',\n",
       " 'pool',\n",
       " 'cell',\n",
       " 'lul',\n",
       " 'fraction',\n",
       " 'printer',\n",
       " 'surgic',\n",
       " 'cancer',\n",
       " 'tea',\n",
       " 'srt',\n",
       " 'tune',\n",
       " 'earth',\n",
       " 'mu',\n",
       " 'grasp',\n",
       " 'goigng',\n",
       " 'regret',\n",
       " 'le',\n",
       " 'ttcom',\n",
       " 'upset',\n",
       " 'rstm',\n",
       " 'femal',\n",
       " 'happi',\n",
       " 'nuclear',\n",
       " 'endow',\n",
       " 'nimbomson',\n",
       " 'birla',\n",
       " 'stoner',\n",
       " 'polyc',\n",
       " 'unless',\n",
       " 'steal',\n",
       " 'hasbroin',\n",
       " 'yahoo',\n",
       " 'inlud',\n",
       " 'mobno',\n",
       " 'waqt',\n",
       " 'facebook',\n",
       " 'schedul',\n",
       " 'leav',\n",
       " 'camera',\n",
       " 'dollar',\n",
       " 'pobontfp',\n",
       " 'hostel',\n",
       " 'bbdtht',\n",
       " 'view',\n",
       " 'area!',\n",
       " 'younger',\n",
       " 'nicenicehow',\n",
       " 'youso',\n",
       " 'speak',\n",
       " 'alreadysabarish',\n",
       " 'carlo',\n",
       " 'pobowwq',\n",
       " 'gravi',\n",
       " 'wrki',\n",
       " 'courag',\n",
       " 'premaricakindli',\n",
       " 'attractioni',\n",
       " 'vijay',\n",
       " 'loo',\n",
       " 'rat',\n",
       " 'uin',\n",
       " 'serv',\n",
       " 'hisher',\n",
       " 'high',\n",
       " 'place',\n",
       " 'aka',\n",
       " 'dnt',\n",
       " 'lorw',\n",
       " 'violat',\n",
       " 'chikkuil',\n",
       " 'almost',\n",
       " 'bcozi',\n",
       " 'pwk',\n",
       " 'prepar',\n",
       " 'masteriast',\n",
       " 'true',\n",
       " 'dey',\n",
       " 'loyal',\n",
       " 'cope',\n",
       " 'yor',\n",
       " 'selfish',\n",
       " 'heltiniiyo',\n",
       " 'meremov',\n",
       " 'onlydon',\n",
       " 'blank',\n",
       " 'perfect',\n",
       " 'mask',\n",
       " 'fineabsolutli',\n",
       " 'joanna',\n",
       " 'buffet',\n",
       " 'ashwini',\n",
       " 'justbeen',\n",
       " 'shoulder',\n",
       " 'improv',\n",
       " 'hopeafternoon',\n",
       " 'prevent',\n",
       " 'memori',\n",
       " 'optoutdwv',\n",
       " 'statu',\n",
       " 'passion',\n",
       " 'art!',\n",
       " 'nauseou',\n",
       " 'gga',\n",
       " 'rgent!',\n",
       " 'thrurespect',\n",
       " 'sacrific',\n",
       " 'tip',\n",
       " 'owo',\n",
       " 'gautham',\n",
       " 'itwhichturnedinto',\n",
       " 'watrdayno',\n",
       " 'obes',\n",
       " 'tour',\n",
       " 'formclark',\n",
       " 'messageit',\n",
       " 'utt',\n",
       " 'chees',\n",
       " 'yesh',\n",
       " 'bro',\n",
       " 'seri',\n",
       " 'confirmdeni',\n",
       " 'tok',\n",
       " 'wonder',\n",
       " 'nowonion',\n",
       " 'confid',\n",
       " 'footbal',\n",
       " 'crore',\n",
       " 'idconvey',\n",
       " 'timi',\n",
       " 'cram',\n",
       " 'mushi',\n",
       " 'p',\n",
       " 'riley',\n",
       " 'contract!!',\n",
       " 'clean',\n",
       " 'surf',\n",
       " 'necessari',\n",
       " 'videophon',\n",
       " 'busyi',\n",
       " 'neighbor',\n",
       " 'john',\n",
       " 'sec',\n",
       " 'variou',\n",
       " 'mush!',\n",
       " 'saeed',\n",
       " 'initi',\n",
       " 'geva',\n",
       " 'jaklin',\n",
       " 'therel',\n",
       " 'allahrakhesh',\n",
       " 'in',\n",
       " 'rather',\n",
       " 'aftr',\n",
       " 'echo',\n",
       " 'freak',\n",
       " 'wudnt',\n",
       " 'ufind',\n",
       " 'consid',\n",
       " 'out',\n",
       " 'hv',\n",
       " 'urn',\n",
       " 'milkdayno',\n",
       " 'newquaysend',\n",
       " 'onit',\n",
       " 'india',\n",
       " 'videop',\n",
       " 'instant',\n",
       " 'said',\n",
       " 'vday',\n",
       " 'otherwis',\n",
       " 'pmtmsg',\n",
       " 'countri',\n",
       " 'steak',\n",
       " 'soire',\n",
       " 'frankgood',\n",
       " 'upyeh',\n",
       " 'tm',\n",
       " 'neighbour',\n",
       " 'mk',\n",
       " 'collag',\n",
       " 'ask',\n",
       " 'macleran',\n",
       " 'citizen',\n",
       " 'misundrstud',\n",
       " 'mumbai',\n",
       " 'tctt',\n",
       " 'hey!!!',\n",
       " 'supportveri',\n",
       " 'shadow',\n",
       " 'coimbator',\n",
       " 'constant',\n",
       " 'colleagu',\n",
       " 'aberdeen',\n",
       " 'dint',\n",
       " 'it‘',\n",
       " 'dointerest',\n",
       " 'gamestar',\n",
       " 'hill',\n",
       " 'rhode',\n",
       " 'lightli',\n",
       " 'drunkard!',\n",
       " 'anythi',\n",
       " 'trebles!',\n",
       " 'els',\n",
       " 'belov',\n",
       " 'onword',\n",
       " 'silenc',\n",
       " 'sindu',\n",
       " 'stopbcm',\n",
       " 'mouth',\n",
       " 'lekdog',\n",
       " 'smash',\n",
       " 'bluetooth',\n",
       " 'yifeng',\n",
       " 'trauma',\n",
       " 'abta',\n",
       " 'control',\n",
       " 'speed',\n",
       " 'opposit',\n",
       " 'themp',\n",
       " 'click',\n",
       " 'barrel',\n",
       " 'ltgt',\n",
       " 'or',\n",
       " 'presley',\n",
       " 'pm',\n",
       " 'unintent',\n",
       " 'violet',\n",
       " 'annonc',\n",
       " 'eecut',\n",
       " 'liverpool',\n",
       " 'supos',\n",
       " 'appro',\n",
       " 'langport',\n",
       " 'vivekanand',\n",
       " 'that!',\n",
       " 'gibe',\n",
       " 'membershiptak',\n",
       " 'lo',\n",
       " 'delici',\n",
       " 'aj',\n",
       " 'ger',\n",
       " 'calld',\n",
       " 'ship',\n",
       " 'around!',\n",
       " 'refresh',\n",
       " 'diddi',\n",
       " 'goodnoon',\n",
       " 'shu',\n",
       " 'mobil',\n",
       " 'offlin',\n",
       " 'scotland',\n",
       " 'raksha',\n",
       " 'charg',\n",
       " 'bloke',\n",
       " 'content',\n",
       " 'chile',\n",
       " 'genuin',\n",
       " 'grace',\n",
       " 'strip',\n",
       " 'model',\n",
       " 'youdearwith',\n",
       " 'eplain!',\n",
       " 'ui',\n",
       " 'complet',\n",
       " 'secondari',\n",
       " 'unsoldmik',\n",
       " 'perfum',\n",
       " 'footblcrckt',\n",
       " 'qbank',\n",
       " 'paid',\n",
       " 'mmmmmmm',\n",
       " 'dealer',\n",
       " 'without',\n",
       " 'function',\n",
       " 'itlet',\n",
       " 'freephon',\n",
       " 'mathew',\n",
       " 'unhappiness!',\n",
       " 'pictt',\n",
       " 'emerg',\n",
       " 'fite',\n",
       " 'christma',\n",
       " 'couldnt',\n",
       " 'aah!',\n",
       " 'naked!',\n",
       " 'stranger!!saw',\n",
       " 'oblising',\n",
       " 'torch',\n",
       " 'lunsford',\n",
       " 'liaotoo',\n",
       " 'convinc',\n",
       " 'gower',\n",
       " 'nalli',\n",
       " 'firesar',\n",
       " 'waysmscom',\n",
       " 'aris',\n",
       " 'doingwhat',\n",
       " 'vote',\n",
       " 'velacheri',\n",
       " 'convers',\n",
       " 'lovejen',\n",
       " 'jewelri',\n",
       " 'medic',\n",
       " 'grocer',\n",
       " 'option!',\n",
       " 'add',\n",
       " 'spring',\n",
       " 'vic',\n",
       " 'hadnt',\n",
       " 'attach',\n",
       " 'mear',\n",
       " 'differb',\n",
       " 'accordingli',\n",
       " 'ink',\n",
       " 'nutter',\n",
       " 'today!',\n",
       " 'kerala',\n",
       " 'oooooh',\n",
       " 'evng',\n",
       " 'august',\n",
       " 'nottel',\n",
       " 'ladiesu',\n",
       " 'cfcaa',\n",
       " 'seeno',\n",
       " 'recoveri',\n",
       " 'treadmil',\n",
       " 'divert',\n",
       " 'etermin',\n",
       " 'you\\x92r',\n",
       " 'yoher',\n",
       " 'flatter',\n",
       " 'block',\n",
       " 'error',\n",
       " 'wwwclubzedcouk',\n",
       " 'lastest',\n",
       " 'eachoth',\n",
       " 'prompt',\n",
       " 'access!',\n",
       " 'dictionari',\n",
       " 'dot',\n",
       " 'fireplac',\n",
       " 'chat',\n",
       " 'bottl',\n",
       " 'diet',\n",
       " 'thk',\n",
       " 'hoop',\n",
       " 'rock',\n",
       " 'deeraj',\n",
       " 'curiou',\n",
       " 'makin',\n",
       " 'sankranti',\n",
       " 'atm',\n",
       " 'insur',\n",
       " 'correct!',\n",
       " 'terminatedw',\n",
       " 'su',\n",
       " 'bootydeli',\n",
       " 'deu',\n",
       " 'mattermsg',\n",
       " 'rememb',\n",
       " 'bathroom',\n",
       " 'keen',\n",
       " 'first',\n",
       " 'buddy!!',\n",
       " 'getzedcouk',\n",
       " 'é',\n",
       " 'edha',\n",
       " 'doubl',\n",
       " 'he\\x92',\n",
       " 'request',\n",
       " 'phonebook',\n",
       " 'dental',\n",
       " 'peach!',\n",
       " 'wasn‘t',\n",
       " 'watchng',\n",
       " 'postcard',\n",
       " 'arrang',\n",
       " 'basketbal',\n",
       " 'genu',\n",
       " 'mina',\n",
       " 'showroomsc',\n",
       " 'evrey',\n",
       " 'probabl',\n",
       " 'idea',\n",
       " 'woohoo!',\n",
       " 'upon!',\n",
       " 'get!',\n",
       " 'hungover!',\n",
       " 'heal',\n",
       " 'chikkusimpl',\n",
       " 'tomorrowtoday',\n",
       " 'stare',\n",
       " 'uz',\n",
       " 'oni',\n",
       " 'quiteamuz',\n",
       " 'dine',\n",
       " 'apeshit',\n",
       " 'appoint',\n",
       " 'reward',\n",
       " 'darlings!',\n",
       " 'possess',\n",
       " 'ar',\n",
       " 'vtire',\n",
       " 'ogunrind',\n",
       " 'petrol',\n",
       " 'ke',\n",
       " 'kiosk',\n",
       " 'mallika',\n",
       " 'pstra',\n",
       " 'gal',\n",
       " 'duck',\n",
       " 'years!!',\n",
       " 'yan',\n",
       " 'sh!ja',\n",
       " 'skip',\n",
       " 'dreamz',\n",
       " 'apr',\n",
       " 'cribb',\n",
       " 'vilikkamt',\n",
       " 'akonlon',\n",
       " 'angri',\n",
       " 'roller',\n",
       " 'timedhoni',\n",
       " 'sleepsweet',\n",
       " 'jog',\n",
       " 'matri',\n",
       " 'freeentri',\n",
       " 'how',\n",
       " 'phd',\n",
       " 'mah',\n",
       " 'jez',\n",
       " 'carolin',\n",
       " 'itself!',\n",
       " 'patient',\n",
       " 'soz',\n",
       " 'caller',\n",
       " 'children',\n",
       " 'resolut',\n",
       " 'juici',\n",
       " 'nigpun',\n",
       " 'swiss',\n",
       " 'marriageprogram',\n",
       " 'lip',\n",
       " 'wesley',\n",
       " 'fridge!',\n",
       " 'chocol',\n",
       " 'hlday',\n",
       " 'ikea',\n",
       " 'dem!!!',\n",
       " 'moral',\n",
       " 'case',\n",
       " 'spiral',\n",
       " 'anythingtomorrow',\n",
       " 'telli',\n",
       " 'pmsgp',\n",
       " 'warranti',\n",
       " 'cashbal',\n",
       " 'pock',\n",
       " 'twat',\n",
       " 'pmeg',\n",
       " 'ppw',\n",
       " 'readi',\n",
       " 'tomorrowcal',\n",
       " 'chuckin',\n",
       " 'pink',\n",
       " 'ngage',\n",
       " 'tkt',\n",
       " 'parisfre',\n",
       " 'eng',\n",
       " 'rakhesh',\n",
       " 'farrel',\n",
       " 'mesh',\n",
       " 'formal',\n",
       " 'design',\n",
       " 'ttyl!',\n",
       " 'admiti',\n",
       " 'witout',\n",
       " 'al!!!!!!!!!',\n",
       " 'youdo',\n",
       " 'tirunelvai',\n",
       " 'gs',\n",
       " 'semi',\n",
       " 'tarpon',\n",
       " 'hello!',\n",
       " 'no!listenedth',\n",
       " 'inform',\n",
       " 'mumtaz',\n",
       " 'spoken',\n",
       " 'btooth',\n",
       " 'gone',\n",
       " 'gaze',\n",
       " 'ready!',\n",
       " 'diaper',\n",
       " 'latest',\n",
       " 'longer',\n",
       " 'laden',\n",
       " 'slept',\n",
       " 'backward',\n",
       " 'plumber',\n",
       " 'chef',\n",
       " 'wtji',\n",
       " 'nimyapl',\n",
       " 'weirdi',\n",
       " 'rang',\n",
       " 'rp',\n",
       " 'pathaya',\n",
       " 'specialcal',\n",
       " 'sonetim',\n",
       " 'tog',\n",
       " 'ringtone!',\n",
       " 'sometim',\n",
       " 'noth',\n",
       " 'stchoicecouk',\n",
       " 'hsbc',\n",
       " 'landmark',\n",
       " 'belli',\n",
       " 'bff',\n",
       " 'alternativehop',\n",
       " 'lou',\n",
       " 'multi',\n",
       " 'young',\n",
       " 'network',\n",
       " 'slow',\n",
       " 'difficult',\n",
       " 'ilol',\n",
       " 'amus',\n",
       " 'couch',\n",
       " 'partnership',\n",
       " 'piss',\n",
       " 'seem',\n",
       " 'deni',\n",
       " 'rob',\n",
       " 'websitenow',\n",
       " 'mental',\n",
       " 'product',\n",
       " 'bike',\n",
       " 'wrd',\n",
       " 'tenerif',\n",
       " 'manda',\n",
       " 'bbdelu',\n",
       " 'ltemailgt',\n",
       " 'proov',\n",
       " 'minscal',\n",
       " 'bluetoothhdset',\n",
       " 'custom',\n",
       " 'js',\n",
       " 'posibl',\n",
       " 'freak!',\n",
       " 'moan',\n",
       " 'idu',\n",
       " 'wellda',\n",
       " 'maniac',\n",
       " 'biz',\n",
       " 'knowyetund',\n",
       " 'pobotcrw',\n",
       " 'thgt',\n",
       " 'equal',\n",
       " 'epos',\n",
       " 'possiblehop',\n",
       " 'dick!',\n",
       " 'parkph',\n",
       " 'sitter',\n",
       " 'drugdeal',\n",
       " 'huge',\n",
       " 'badrith',\n",
       " 'jersey',\n",
       " 'shija',\n",
       " 'crushes!!!',\n",
       " 'petrol!',\n",
       " 'flat',\n",
       " 'slap',\n",
       " 'fond',\n",
       " 'iknow',\n",
       " 'frosti',\n",
       " 'along',\n",
       " 'bewar',\n",
       " 'wallet',\n",
       " 'tp',\n",
       " 'wish!',\n",
       " 'drizzl',\n",
       " 'forward',\n",
       " 'libertin',\n",
       " 'messageno',\n",
       " 'gotani',\n",
       " 'er',\n",
       " 'upsetit',\n",
       " 'pole',\n",
       " 'see',\n",
       " 'happened!',\n",
       " 'galno',\n",
       " 'spous',\n",
       " 'weekday',\n",
       " 'oyster',\n",
       " 'girl!',\n",
       " 'legal',\n",
       " 'leasttim',\n",
       " 'still',\n",
       " 'wereth',\n",
       " 'swt',\n",
       " 'spam',\n",
       " 'allalo',\n",
       " 'tetoper',\n",
       " 'necess',\n",
       " 'mumha',\n",
       " 'self',\n",
       " 'lm',\n",
       " 'foley',\n",
       " 'rightli',\n",
       " '<PAD>',\n",
       " 'shey',\n",
       " 'surrend',\n",
       " 'hasnt',\n",
       " 'playi',\n",
       " 'care',\n",
       " 'agesr',\n",
       " 'watershd',\n",
       " 'httpdoit',\n",
       " 'newport',\n",
       " 'litr',\n",
       " 'zebra',\n",
       " 'callsmessagesmiss',\n",
       " 'lamp',\n",
       " 'yest',\n",
       " 'bao',\n",
       " 'anything!',\n",
       " 'activ',\n",
       " 'addi',\n",
       " 'hii',\n",
       " 'bay',\n",
       " 'none!nowher',\n",
       " 'sirjii',\n",
       " 'fifth',\n",
       " 'wuld',\n",
       " 'rearrang',\n",
       " 'boob',\n",
       " 'doesn‘t',\n",
       " 'pandi',\n",
       " 'sppok',\n",
       " 'nois',\n",
       " 'pubcaf',\n",
       " 'wktt',\n",
       " 'dontpleas',\n",
       " 'somewher',\n",
       " 'nite!',\n",
       " 'beach',\n",
       " 'sey!',\n",
       " 'random!',\n",
       " '!!',\n",
       " 'affair',\n",
       " 'toic',\n",
       " 'mustprovid',\n",
       " 'qatarrakhesh',\n",
       " 'ralph',\n",
       " 'imma',\n",
       " 'gving',\n",
       " 'intern',\n",
       " 'shud',\n",
       " 'lover!',\n",
       " 'profil',\n",
       " 'skalli',\n",
       " 'camp',\n",
       " 'starshine!',\n",
       " 'ptbo',\n",
       " 'eeri',\n",
       " 'nang',\n",
       " 'option',\n",
       " 'reltnship!!',\n",
       " 'urgh',\n",
       " 'kanji',\n",
       " 'startedindia',\n",
       " 'jule',\n",
       " 'tamilnaduthen',\n",
       " 'kaila',\n",
       " 'swann',\n",
       " 'baller',\n",
       " 'jokin',\n",
       " 'inshah',\n",
       " 'nobodi',\n",
       " 'knowwait',\n",
       " 'monlr',\n",
       " 'detroit',\n",
       " 'everywher',\n",
       " 'nevil',\n",
       " 'spec',\n",
       " 'chennai',\n",
       " 'infra',\n",
       " 'browni',\n",
       " 'okor',\n",
       " 'lead',\n",
       " 'canari',\n",
       " 'reg',\n",
       " 'egg',\n",
       " 'nation',\n",
       " 'result',\n",
       " 'shi',\n",
       " 'grown',\n",
       " 'instead!',\n",
       " 'ya!',\n",
       " 'iti',\n",
       " 'lap',\n",
       " 'eh',\n",
       " 'career',\n",
       " 'chatting!',\n",
       " 'poorli',\n",
       " 'phone!!',\n",
       " 'sm',\n",
       " 'acknowledg',\n",
       " 'argu',\n",
       " 'jane',\n",
       " 'uncount',\n",
       " 'countinlot',\n",
       " 'iron',\n",
       " 'weekend',\n",
       " 'aeroplan',\n",
       " 'dateboessecmn',\n",
       " 'shave',\n",
       " 'timin',\n",
       " 'respond',\n",
       " 'ovulatewhen',\n",
       " 'jb',\n",
       " 'kane',\n",
       " 'bocpm',\n",
       " 'rudi',\n",
       " 'sachinjust',\n",
       " 'sthi',\n",
       " 'onward',\n",
       " 'drpd',\n",
       " 'prabhaim',\n",
       " 'mathemat',\n",
       " 'spirit',\n",
       " 'clair',\n",
       " 'jobyet',\n",
       " 'christmassi',\n",
       " 'wi',\n",
       " 'incomm',\n",
       " 'btnation',\n",
       " 'munster',\n",
       " 'dead!wel',\n",
       " 'yummi',\n",
       " 'accommodationvouch',\n",
       " 'tone!',\n",
       " 'brin',\n",
       " 'wwwsmsacuhmmross',\n",
       " 'horniest',\n",
       " 'mindi',\n",
       " 'fall',\n",
       " 'hank',\n",
       " 'suit',\n",
       " 'timehop',\n",
       " 'notif',\n",
       " 'messagesim',\n",
       " 'lord',\n",
       " 'paracetamol',\n",
       " 'select',\n",
       " 'ninish',\n",
       " 'faber',\n",
       " 'sib',\n",
       " 'clearer',\n",
       " 'prof',\n",
       " 'treacl',\n",
       " 'dt',\n",
       " 'yetund',\n",
       " 'town',\n",
       " 'relation!',\n",
       " 'ranju',\n",
       " 'woot!',\n",
       " 'geeee',\n",
       " 'mwen',\n",
       " 'help',\n",
       " 'ofic',\n",
       " 'aiya',\n",
       " 'whisper',\n",
       " 'eit',\n",
       " 'pre',\n",
       " 'fool',\n",
       " 'crazi',\n",
       " 'whilltak',\n",
       " 'parkin',\n",
       " 'barkley',\n",
       " 'meim',\n",
       " 'understood',\n",
       " 'linu',\n",
       " 'light!',\n",
       " 'scotch',\n",
       " 'gentli',\n",
       " 'fan',\n",
       " 'cup',\n",
       " 'grandma',\n",
       " 'gaytetbuddycom',\n",
       " 'woot',\n",
       " 'mia',\n",
       " 'rs',\n",
       " 'guild',\n",
       " 'fine',\n",
       " 'oredi',\n",
       " 'pansy!',\n",
       " 'fran',\n",
       " 'essay',\n",
       " 'olol',\n",
       " 'ho!',\n",
       " 'daurgent',\n",
       " 'thu',\n",
       " 'lavend',\n",
       " 'nolin',\n",
       " 'byatch',\n",
       " 'insid',\n",
       " 'working!',\n",
       " 'old',\n",
       " 'haughaighgtujhyguj',\n",
       " 'ireneer',\n",
       " 'opp',\n",
       " 'ratio',\n",
       " 'dontgettet',\n",
       " 'talent',\n",
       " 'await',\n",
       " 'luuri',\n",
       " 'wedlunch',\n",
       " 'pay',\n",
       " 'tcrw',\n",
       " 'todo',\n",
       " 'kept',\n",
       " 'yowif',\n",
       " 'ehrr',\n",
       " 'cover',\n",
       " 'ind',\n",
       " 'headset',\n",
       " 'lost',\n",
       " 'larg',\n",
       " 'yesmum',\n",
       " 'colourredtetcolourttstar',\n",
       " 'tripl',\n",
       " 'wetherspoon',\n",
       " 'frequent',\n",
       " 'dick',\n",
       " 'fuck',\n",
       " 'joy',\n",
       " 'nah',\n",
       " 'bash',\n",
       " 'twilight',\n",
       " 'arm',\n",
       " 'nohe',\n",
       " 'beautifulmay',\n",
       " 'porn',\n",
       " 'motherinlaw',\n",
       " 'cu',\n",
       " 'mojibiola',\n",
       " 'guessin',\n",
       " 'posh',\n",
       " 'uslet',\n",
       " 'dat',\n",
       " 'truffl',\n",
       " 'thinghow',\n",
       " 'coupla',\n",
       " 'depend',\n",
       " 'tattoo',\n",
       " 'god!',\n",
       " 'unconvinc',\n",
       " 'babyjontet!',\n",
       " 'wotu',\n",
       " 'muhommad',\n",
       " 'monkeespeopl',\n",
       " 'up',\n",
       " 'somewhr',\n",
       " 'energi',\n",
       " 'spiderman',\n",
       " 'graze',\n",
       " 'champney',\n",
       " 'bilo',\n",
       " 'jolli',\n",
       " 'astn',\n",
       " 'eactli',\n",
       " 'mbp',\n",
       " 'ipad',\n",
       " 'galcan',\n",
       " 'inperson',\n",
       " 'hellogorg',\n",
       " 'prasanth',\n",
       " 'comuk',\n",
       " 'faitheven',\n",
       " 'think',\n",
       " 'webadr',\n",
       " 'toot',\n",
       " 'approach',\n",
       " 'ourback',\n",
       " 'homelov',\n",
       " 'my',\n",
       " 'postpon',\n",
       " 'natalja',\n",
       " 'tool',\n",
       " 'polyph',\n",
       " 'bw',\n",
       " 'etra',\n",
       " 'suganya',\n",
       " 'brisk',\n",
       " 'si',\n",
       " 'tortur',\n",
       " 'keepintouch',\n",
       " 'theyll',\n",
       " 'thia',\n",
       " 'purpleu',\n",
       " 'burgundi',\n",
       " 'teletet',\n",
       " 'afford',\n",
       " 'subpoli',\n",
       " 'wwwttcom',\n",
       " 'dessert',\n",
       " 'latei',\n",
       " 'lot',\n",
       " 'dirti',\n",
       " 'journey',\n",
       " 'slave!',\n",
       " 'tulip',\n",
       " 'sari',\n",
       " 'applebe',\n",
       " 'dasara',\n",
       " 'evon',\n",
       " 'batch',\n",
       " 'grinder',\n",
       " 'std',\n",
       " 'scrumptiou',\n",
       " 'phil',\n",
       " 'weddin',\n",
       " 'ibm',\n",
       " 'boooo',\n",
       " 'cuz',\n",
       " 'western',\n",
       " 'furnitur',\n",
       " 'reject',\n",
       " 'satsound\\x92',\n",
       " 'glass',\n",
       " 'apo',\n",
       " 'decim',\n",
       " 'buck',\n",
       " 'ramaduth',\n",
       " 'agent',\n",
       " 'happili',\n",
       " 'tall',\n",
       " 'dinnermsg',\n",
       " 'httpcareer',\n",
       " 'nokia',\n",
       " 'tiempo',\n",
       " 'ardé',\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "remv = sorted(list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "remv.remove('!')\n",
    "remv.remove('!!')\n",
    "remv.remove('!!!')\n",
    "remv.remove('!!!!')\n",
    "remv.remove('!thi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>',\n",
       " '<UNK>',\n",
       " 'aa',\n",
       " 'aah',\n",
       " 'aah!',\n",
       " 'aaniy',\n",
       " 'aaooooright',\n",
       " 'aathilov',\n",
       " 'aathiwher',\n",
       " 'ab',\n",
       " 'abbey!',\n",
       " 'abdomen',\n",
       " 'abeg',\n",
       " 'abelu',\n",
       " 'aberdeen',\n",
       " 'abi',\n",
       " 'abi!',\n",
       " 'abil',\n",
       " 'abiola',\n",
       " 'abj',\n",
       " 'abl',\n",
       " 'abnorm',\n",
       " 'about!',\n",
       " 'abouta',\n",
       " 'abroad',\n",
       " 'absenc',\n",
       " 'absolut',\n",
       " 'abstract',\n",
       " 'abt',\n",
       " 'abta',\n",
       " 'aburo',\n",
       " 'abus',\n",
       " 'ac',\n",
       " 'academ',\n",
       " 'acc',\n",
       " 'accent',\n",
       " 'accentur',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'access!',\n",
       " 'accid',\n",
       " 'accident',\n",
       " 'accommod',\n",
       " 'accommodationvouch',\n",
       " 'accomod',\n",
       " 'accordin',\n",
       " 'accordingli',\n",
       " 'accordinglyor',\n",
       " 'account',\n",
       " 'accumul',\n",
       " 'ach',\n",
       " 'achanammarakheshqatar',\n",
       " 'achiev',\n",
       " 'acid!',\n",
       " 'acknowledg',\n",
       " 'aclpm',\n",
       " 'acnt',\n",
       " 'acoentri',\n",
       " 'across',\n",
       " 'acsmsreward',\n",
       " 'act',\n",
       " 'actin',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'acwicmbcktzr!',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'addamsfa',\n",
       " 'addi',\n",
       " 'addict',\n",
       " 'address',\n",
       " 'addressul',\n",
       " 'adewal',\n",
       " 'adi',\n",
       " 'adjust',\n",
       " 'admin',\n",
       " 'administr',\n",
       " 'admir',\n",
       " 'admiss',\n",
       " 'admit',\n",
       " 'admiti',\n",
       " 'ador',\n",
       " 'adp',\n",
       " 'adress',\n",
       " 'adrian',\n",
       " 'adrink',\n",
       " 'adsens',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'adventur',\n",
       " 'advic',\n",
       " 'advis',\n",
       " 'advisor',\n",
       " 'ae',\n",
       " 'aeronaut',\n",
       " 'aeroplan',\n",
       " 'afew',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affection',\n",
       " 'affectionsamp',\n",
       " 'affidavit',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'aft',\n",
       " 'afternon',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'aftr',\n",
       " 'ag',\n",
       " 'again!',\n",
       " 'againcal',\n",
       " 'againlov',\n",
       " 'agalla',\n",
       " 'age',\n",
       " 'agenc',\n",
       " 'agent',\n",
       " 'ageppermesssubscript',\n",
       " 'agesr',\n",
       " 'agidhan',\n",
       " 'ago',\n",
       " 'agocusoon',\n",
       " 'agre',\n",
       " 'agreen',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahge',\n",
       " 'ahhh',\n",
       " 'ahhhhjust',\n",
       " 'ahmad',\n",
       " 'ahnow',\n",
       " 'ahold',\n",
       " 'ahsen',\n",
       " 'ahth',\n",
       " 'ahwhat',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aig',\n",
       " 'aight',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'airtel',\n",
       " 'aiya',\n",
       " 'aiyah',\n",
       " 'aiyar',\n",
       " 'aiyo',\n",
       " 'aj',\n",
       " 'ajith',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akonlon',\n",
       " 'al',\n",
       " 'al!!!!!!!!!',\n",
       " 'alaikkumprid',\n",
       " 'alaipayuth',\n",
       " 'albi',\n",
       " 'album',\n",
       " 'albumquit',\n",
       " 'alcohol',\n",
       " 'aldrin',\n",
       " 'ale',\n",
       " 'alert',\n",
       " 'alert!',\n",
       " 'alertfrom',\n",
       " 'alett',\n",
       " 'alfi',\n",
       " 'algarv',\n",
       " 'algebra',\n",
       " 'algorithm',\n",
       " 'ali',\n",
       " 'alian',\n",
       " 'alibi',\n",
       " 'aliv',\n",
       " 'alivebett',\n",
       " 'all',\n",
       " 'allah',\n",
       " 'allahmeet',\n",
       " 'allahrakhesh',\n",
       " 'allalo',\n",
       " 'allday!',\n",
       " 'allo!',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'along!',\n",
       " 'alot',\n",
       " 'alreadi',\n",
       " 'alreadysabarish',\n",
       " 'alright',\n",
       " 'alrightokay',\n",
       " 'alrit',\n",
       " 'alritehav',\n",
       " 'also',\n",
       " 'alsoor',\n",
       " 'alter',\n",
       " 'alternativehop',\n",
       " 'although',\n",
       " 'alwa!!',\n",
       " 'alway',\n",
       " 'alwi',\n",
       " 'am',\n",
       " 'am!!',\n",
       " 'amanda',\n",
       " 'amaz',\n",
       " 'ambiti',\n",
       " 'ambrithmaduraimet',\n",
       " 'american',\n",
       " 'ami',\n",
       " 'amigo',\n",
       " 'amk',\n",
       " 'ammaelif',\n",
       " 'ammo',\n",
       " 'amnow',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amor',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amplikat',\n",
       " 'ampm',\n",
       " 'amrca',\n",
       " 'amrita',\n",
       " 'amt',\n",
       " 'amus',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anal',\n",
       " 'analysi',\n",
       " 'anand',\n",
       " 'anderson',\n",
       " 'andor',\n",
       " 'andr',\n",
       " 'andrewsboy',\n",
       " 'andro',\n",
       " 'anetwork',\n",
       " 'angel',\n",
       " 'angri',\n",
       " 'anim',\n",
       " 'animal!',\n",
       " 'anjie!',\n",
       " 'anjola',\n",
       " 'anna',\n",
       " 'anni',\n",
       " 'annie!',\n",
       " 'anniversari',\n",
       " 'annonc',\n",
       " 'announc',\n",
       " 'annoy',\n",
       " 'annoyin!',\n",
       " 'anonym',\n",
       " 'anot',\n",
       " 'anoth',\n",
       " 'ansr',\n",
       " 'answer',\n",
       " 'answerin',\n",
       " 'answr',\n",
       " 'antelop',\n",
       " 'anthoni',\n",
       " 'anti',\n",
       " 'antibiot',\n",
       " 'anybodi',\n",
       " 'anyhow',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyplac',\n",
       " 'anyth',\n",
       " 'anythi',\n",
       " 'anythin',\n",
       " 'anything!',\n",
       " 'anythingtomorrow',\n",
       " 'anytim',\n",
       " 'anyway',\n",
       " 'anywher',\n",
       " 'aom',\n",
       " 'apart',\n",
       " 'ape',\n",
       " 'apeshit',\n",
       " 'aphe\\x92',\n",
       " 'apnt',\n",
       " 'apo',\n",
       " 'apolog',\n",
       " 'apologet',\n",
       " 'apologis',\n",
       " 'app',\n",
       " 'appar',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appendi',\n",
       " 'appi',\n",
       " 'applebe',\n",
       " 'appledayno',\n",
       " 'applespairsal',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appoint',\n",
       " 'appreci',\n",
       " 'appro',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approv',\n",
       " 'appt',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'aproach',\n",
       " 'apt',\n",
       " 'aptitud',\n",
       " 'aquariu',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabian',\n",
       " 'arcad',\n",
       " 'archiv',\n",
       " 'ard',\n",
       " 'ardé',\n",
       " 'area',\n",
       " 'area!',\n",
       " 'arent',\n",
       " 'arestaur',\n",
       " 'aretak',\n",
       " 'argentina',\n",
       " 'argh',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'ari',\n",
       " 'aris',\n",
       " 'arithmet',\n",
       " 'arm',\n",
       " 'armand',\n",
       " 'armenia',\n",
       " 'arng',\n",
       " 'arngd',\n",
       " 'arnt',\n",
       " 'around',\n",
       " 'around!',\n",
       " 'aroundn',\n",
       " 'arpraveesh',\n",
       " 'arr',\n",
       " 'arrang',\n",
       " 'arrest',\n",
       " 'arriv',\n",
       " 'arrow',\n",
       " 'arsen',\n",
       " 'art',\n",
       " 'art!',\n",
       " 'arti',\n",
       " 'artist',\n",
       " 'arul',\n",
       " 'arun',\n",
       " 'asa',\n",
       " 'asap',\n",
       " 'asap!',\n",
       " 'asapok',\n",
       " 'asda',\n",
       " 'ash',\n",
       " 'ashley',\n",
       " 'ashwini',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'ask',\n",
       " 'askd',\n",
       " 'askin',\n",
       " 'aslamalaikkuminsha',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'ass',\n",
       " 'ass!',\n",
       " 'ass!!',\n",
       " 'assess',\n",
       " 'asshol',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'assum',\n",
       " 'asther',\n",
       " 'asthma',\n",
       " 'astn',\n",
       " 'astoundingli',\n",
       " 'astrolog',\n",
       " 'astronom',\n",
       " 'asu',\n",
       " 'asusual!',\n",
       " 'at!',\n",
       " 'ate',\n",
       " 'athlet',\n",
       " 'athom',\n",
       " 'atlanta',\n",
       " 'atlast',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'atroci',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'atten',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attitud',\n",
       " 'attract',\n",
       " 'attractioni',\n",
       " 'attribut',\n",
       " 'atyour',\n",
       " 'auction',\n",
       " 'auctionpunj',\n",
       " 'audiit',\n",
       " 'audit',\n",
       " 'audrey',\n",
       " 'audri',\n",
       " 'august',\n",
       " 'august!',\n",
       " 'aunt',\n",
       " 'aunti',\n",
       " 'aunty!',\n",
       " 'aust',\n",
       " 'australia',\n",
       " 'authoris',\n",
       " 'auto',\n",
       " 'autocorrect',\n",
       " 'av',\n",
       " 'ava',\n",
       " 'avail',\n",
       " 'availa',\n",
       " 'available!',\n",
       " 'availablei',\n",
       " 'availablethey',\n",
       " 'avalarr',\n",
       " 'avatar',\n",
       " 'avbl',\n",
       " 'ave',\n",
       " 'aveng',\n",
       " 'avent',\n",
       " 'avenu',\n",
       " 'avier',\n",
       " 'avin',\n",
       " 'avo',\n",
       " 'avoid',\n",
       " 'await',\n",
       " 'awak',\n",
       " 'award',\n",
       " 'award!',\n",
       " 'away',\n",
       " 'away!!',\n",
       " 'awesom',\n",
       " 'awkward',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'ay',\n",
       " 'ayn',\n",
       " 'ayo',\n",
       " 'b',\n",
       " 'ba',\n",
       " 'baaaaaaaabe!',\n",
       " 'baaaaabe!',\n",
       " 'babe',\n",
       " 'babe!',\n",
       " 'babeprobpop',\n",
       " 'babesozi',\n",
       " 'babi',\n",
       " 'babies!',\n",
       " 'baby!',\n",
       " 'baby!hop',\n",
       " 'babygoodby',\n",
       " 'babyjontet!',\n",
       " 'babysit',\n",
       " 'bac',\n",
       " 'back',\n",
       " 'back!',\n",
       " 'backa',\n",
       " 'backdoor',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bad!',\n",
       " 'badass',\n",
       " 'badli',\n",
       " 'badrith',\n",
       " 'bag',\n",
       " 'bagi',\n",
       " 'bahama',\n",
       " 'bahamas!',\n",
       " 'baig',\n",
       " 'bailiff',\n",
       " 'bajarangabali',\n",
       " 'bak',\n",
       " 'bak!',\n",
       " 'bakra',\n",
       " 'bakrid!',\n",
       " 'balanc',\n",
       " 'ball',\n",
       " 'baller',\n",
       " 'balloon!',\n",
       " 'bam',\n",
       " 'bambl',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bandag',\n",
       " 'bang',\n",
       " 'bangb',\n",
       " 'bangbab',\n",
       " 'bani',\n",
       " 'bank',\n",
       " 'banneduk',\n",
       " 'bannfwflyppm',\n",
       " 'banter',\n",
       " 'bao',\n",
       " 'bar',\n",
       " 'barbi',\n",
       " 'barcelona',\n",
       " 'bare',\n",
       " 'bari',\n",
       " 'barkley',\n",
       " 'barm',\n",
       " 'barolla',\n",
       " 'barrel',\n",
       " 'barri',\n",
       " 'base',\n",
       " 'bash',\n",
       " 'basic',\n",
       " 'basket',\n",
       " 'basketbal',\n",
       " 'basq!ihav',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'batch!',\n",
       " 'batchlor',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batsman',\n",
       " 'batt',\n",
       " 'batteri',\n",
       " 'battl',\n",
       " 'bawl',\n",
       " 'bay',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bbdelu',\n",
       " 'bbdpooja',\n",
       " 'bbdtht',\n",
       " 'bblue',\n",
       " 'bbq',\n",
       " 'bc',\n",
       " 'bcaz',\n",
       " 'bck',\n",
       " 'bcm',\n",
       " 'bcmsfwcn',\n",
       " 'bcmwcn',\n",
       " 'bcoz',\n",
       " 'bcozi',\n",
       " 'bcum',\n",
       " 'bcz',\n",
       " 'bday',\n",
       " 'beach',\n",
       " 'bead',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beauti',\n",
       " 'beautifulmay',\n",
       " 'bec',\n",
       " 'becau',\n",
       " 'becausethey',\n",
       " 'becom',\n",
       " 'becoz',\n",
       " 'becz',\n",
       " 'bed',\n",
       " 'bed!',\n",
       " 'bedbut',\n",
       " 'bedreal',\n",
       " 'bedrm',\n",
       " 'bedroom',\n",
       " 'bedroom!lov',\n",
       " 'beeen',\n",
       " 'beehoon',\n",
       " 'beendrop',\n",
       " 'beer',\n",
       " 'beerag',\n",
       " 'beerr',\n",
       " 'befor',\n",
       " 'beforehand',\n",
       " 'beforew',\n",
       " 'beg',\n",
       " 'beggar',\n",
       " 'begin',\n",
       " 'begun',\n",
       " 'behalf',\n",
       " 'behav',\n",
       " 'behind',\n",
       " 'bein',\n",
       " 'believ',\n",
       " 'beliv',\n",
       " 'bell',\n",
       " 'bellearli',\n",
       " 'belli',\n",
       " 'belliger',\n",
       " 'belong',\n",
       " 'belov',\n",
       " 'belovd',\n",
       " 'belt',\n",
       " 'ben',\n",
       " 'bend',\n",
       " 'beneath',\n",
       " 'beneficiari',\n",
       " 'benefit',\n",
       " 'benni',\n",
       " 'bergkamp',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'bestcongrat',\n",
       " 'bestrpli',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'beth',\n",
       " 'betta',\n",
       " 'better',\n",
       " 'bettersn',\n",
       " 'beverag',\n",
       " 'bevieswaz',\n",
       " 'bewar',\n",
       " 'beware!',\n",
       " 'beyond',\n",
       " 'bf',\n",
       " 'bff',\n",
       " 'bfore',\n",
       " 'bhaskar',\n",
       " 'bhayandar',\n",
       " 'bian',\n",
       " 'biatch!',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'big!',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bill',\n",
       " 'billi',\n",
       " 'billion',\n",
       " 'bilo',\n",
       " 'bimbo',\n",
       " 'bin',\n",
       " 'biola',\n",
       " 'bipw',\n",
       " 'bird',\n",
       " 'bird!',\n",
       " 'birla',\n",
       " 'biro',\n",
       " 'birth',\n",
       " 'birthdat',\n",
       " 'birthday',\n",
       " 'bishan',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'biz',\n",
       " 'bk',\n",
       " 'black',\n",
       " 'blackand',\n",
       " 'blackberri',\n",
       " 'blackim',\n",
       " 'blacko',\n",
       " 'blah',\n",
       " 'blake',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blastin',\n",
       " 'bleak',\n",
       " 'bleh',\n",
       " 'bless',\n",
       " 'bless!',\n",
       " 'blessget',\n",
       " 'blessings!',\n",
       " 'blimey',\n",
       " 'blind',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'bloke',\n",
       " 'blond',\n",
       " 'bloo',\n",
       " 'blood',\n",
       " 'bloodblood',\n",
       " 'bloodi',\n",
       " 'bloodsend',\n",
       " 'bloomberg',\n",
       " 'bloombergcom',\n",
       " 'blow',\n",
       " 'blown',\n",
       " 'blu',\n",
       " 'blue',\n",
       " 'bluetooth',\n",
       " 'bluetooth!',\n",
       " 'bluetoothhdset',\n",
       " 'blueu',\n",
       " 'bluff',\n",
       " 'blur',\n",
       " 'bluray',\n",
       " 'bmw',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'boatin',\n",
       " 'bob',\n",
       " 'bocpm',\n",
       " 'bodi',\n",
       " 'body!!',\n",
       " 'boggi',\n",
       " 'bognor',\n",
       " 'bold',\n",
       " 'bollo',\n",
       " 'boltblu',\n",
       " 'bom',\n",
       " 'bomb',\n",
       " 'bone',\n",
       " 'bong',\n",
       " 'bonqp',\n",
       " 'bonu',\n",
       " 'bonus!',\n",
       " 'boo',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'bookedth',\n",
       " 'bookmark',\n",
       " 'bookshelf',\n",
       " 'boooo',\n",
       " 'boost',\n",
       " 'booti',\n",
       " 'bootydeli',\n",
       " 'boqu',\n",
       " 'borderlin',\n",
       " 'bore',\n",
       " 'bored!',\n",
       " 'borin',\n",
       " 'boring!',\n",
       " 'born',\n",
       " 'born!',\n",
       " 'bornpleas',\n",
       " 'borrow',\n",
       " 'boskch',\n",
       " 'boskwpppm',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'both!',\n",
       " 'bother',\n",
       " 'bottl',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bought\\x94braindance\\x94a',\n",
       " 'boundari',\n",
       " 'bout',\n",
       " 'bout!',\n",
       " 'bowa',\n",
       " 'bowl',\n",
       " 'bowrc',\n",
       " 'boy',\n",
       " 'boyf',\n",
       " 'boyfriend',\n",
       " 'boyi',\n",
       " 'boytoy',\n",
       " 'boytoy!',\n",
       " 'bpo',\n",
       " 'bra',\n",
       " 'brah',\n",
       " 'brain',\n",
       " 'braini',\n",
       " 'brainless',\n",
       " 'brand',\n",
       " 'brandi',\n",
       " 'brat',\n",
       " 'brave',\n",
       " 'bray',\n",
       " 'brb',\n",
       " 'brdget',\n",
       " 'bread',\n",
       " 'breadstick',\n",
       " 'break',\n",
       " 'breaker',\n",
       " 'breakfast',\n",
       " 'breakin',\n",
       " 'breath',\n",
       " 'breather',\n",
       " 'breez',\n",
       " 'breezi',\n",
       " 'brekkie!',\n",
       " 'bribe',\n",
       " 'bridg',\n",
       " 'bridgwat',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brighten',\n",
       " 'brilliant',\n",
       " 'brilliantli',\n",
       " 'brilliantthingi',\n",
       " 'brin',\n",
       " 'bring',\n",
       " 'brisk',\n",
       " 'brison',\n",
       " 'bristol',\n",
       " 'british',\n",
       " 'britney',\n",
       " 'bro',\n",
       " 'broad',\n",
       " 'broadband',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brolli',\n",
       " 'broth',\n",
       " 'brotha',\n",
       " 'brother',\n",
       " 'brother‘',\n",
       " 'brought',\n",
       " 'browni',\n",
       " 'brows',\n",
       " 'browser',\n",
       " 'browsin',\n",
       " 'bruce',\n",
       " 'brum!',\n",
       " 'bruv',\n",
       " 'bruv!',\n",
       " 'bslvyl',\n",
       " 'bsn',\n",
       " 'bsnl',\n",
       " 'bstfrnd',\n",
       " 'bt',\n",
       " 'bthere',\n",
       " 'bthmm',\n",
       " 'btnation',\n",
       " 'btnationalr',\n",
       " 'btooth',\n",
       " 'btw',\n",
       " 'btwn',\n",
       " 'bu',\n",
       " 'buck',\n",
       " 'bud',\n",
       " 'buddi',\n",
       " 'buddy!!',\n",
       " 'budget',\n",
       " 'buen',\n",
       " 'buff',\n",
       " 'buffet',\n",
       " 'buffi',\n",
       " 'bugi',\n",
       " 'build',\n",
       " 'built',\n",
       " 'bulb',\n",
       " 'bull',\n",
       " 'bullshit',\n",
       " 'bun',\n",
       " 'bunch',\n",
       " 'bundl',\n",
       " 'bunker',\n",
       " 'buns!',\n",
       " 'burden',\n",
       " 'burger',\n",
       " 'burgundi',\n",
       " 'burial',\n",
       " 'burn',\n",
       " 'burnt',\n",
       " 'burrito',\n",
       " 'bus!',\n",
       " 'buse',\n",
       " 'busetop',\n",
       " 'busi',\n",
       " 'busti',\n",
       " 'busyi',\n",
       " 'but',\n",
       " 'butt',\n",
       " 'butther',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buyer',\n",
       " 'buz',\n",
       " 'buzi',\n",
       " 'buzz',\n",
       " 'buzz!',\n",
       " 'buzzzz!',\n",
       " 'bw',\n",
       " 'byatch',\n",
       " 'bye',\n",
       " 'by\\x94leafcutt',\n",
       " 'b\\x92day',\n",
       " 'b‘ham',\n",
       " 'c',\n",
       " 'c!',\n",
       " 'cab',\n",
       " 'cabin',\n",
       " 'cabl',\n",
       " 'cafe',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'caken',\n",
       " 'cal',\n",
       " 'calcul',\n",
       " 'cali',\n",
       " 'calicut',\n",
       " 'california',\n",
       " 'call',\n",
       " 'callback',\n",
       " 'callcost',\n",
       " 'callcoz',\n",
       " 'calld',\n",
       " 'calldrov',\n",
       " 'caller',\n",
       " 'callertun',\n",
       " 'callfreefon',\n",
       " 'callin',\n",
       " 'calling!',\n",
       " 'callingforgot',\n",
       " 'callon',\n",
       " 'calloptout',\n",
       " 'calloptout!yhl',\n",
       " 'calloptoutfq',\n",
       " 'calloptouthf',\n",
       " 'calloptoutj',\n",
       " 'calloptoutjq',\n",
       " 'calloptoutlf',\n",
       " 'calloptoutnd',\n",
       " 'calloptoutqf',\n",
       " 'calls!',\n",
       " 'callsmessagesmiss',\n",
       " 'callsminmobsmor',\n",
       " 'callsminmobsmorelkpobohpfl',\n",
       " 'callsminmoremobsemspobopowa',\n",
       " 'callsppm',\n",
       " 'callurg',\n",
       " 'calm',\n",
       " 'cam',\n",
       " 'camcord',\n",
       " 'came',\n",
       " 'came!',\n",
       " 'camera',\n",
       " 'camera!',\n",
       " 'cameravideo',\n",
       " 'camp',\n",
       " 'campu',\n",
       " 'camri',\n",
       " 'canada',\n",
       " 'canal',\n",
       " 'canari',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candont',\n",
       " 'canlov',\n",
       " 'cannam',\n",
       " 'cannot',\n",
       " 'cannt',\n",
       " 'cant',\n",
       " 'cantdo',\n",
       " 'canteen',\n",
       " 'can\\x92t',\n",
       " 'can‘t',\n",
       " 'cap',\n",
       " 'capac',\n",
       " 'capit',\n",
       " 'cappuccino',\n",
       " 'captain',\n",
       " 'car',\n",
       " 'card',\n",
       " 'card!',\n",
       " 'cardiff',\n",
       " 'cardin',\n",
       " 'care',\n",
       " 'care!',\n",
       " 'careabout',\n",
       " 'career',\n",
       " 'careful!',\n",
       " 'careinsha',\n",
       " 'careless',\n",
       " 'carent',\n",
       " 'careswt',\n",
       " 'careumma',\n",
       " 'carewhoev',\n",
       " 'carli',\n",
       " 'carlin',\n",
       " 'carlo',\n",
       " 'carlosl',\n",
       " 'carolin',\n",
       " 'carolina',\n",
       " 'caroline!',\n",
       " 'carpark',\n",
       " 'carri',\n",
       " 'carryin',\n",
       " 'carso',\n",
       " 'carton',\n",
       " 'cartoon',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cash!',\n",
       " 'cashbal',\n",
       " 'cashbincouk',\n",
       " 'cashin',\n",
       " 'cashto',\n",
       " 'cast',\n",
       " 'castor',\n",
       " 'casualti',\n",
       " 'cat',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<UNK>': 1,\n",
       " 'aa': 2,\n",
       " 'aah': 3,\n",
       " 'aah!': 4,\n",
       " 'aaniy': 5,\n",
       " 'aaooooright': 6,\n",
       " 'aathilov': 7,\n",
       " 'aathiwher': 8,\n",
       " 'ab': 9,\n",
       " 'abbey!': 10,\n",
       " 'abdomen': 11,\n",
       " 'abeg': 12,\n",
       " 'abelu': 13,\n",
       " 'aberdeen': 14,\n",
       " 'abi': 15,\n",
       " 'abi!': 16,\n",
       " 'abil': 17,\n",
       " 'abiola': 18,\n",
       " 'abj': 19,\n",
       " 'abl': 20,\n",
       " 'abnorm': 21,\n",
       " 'about!': 22,\n",
       " 'abouta': 23,\n",
       " 'abroad': 24,\n",
       " 'absenc': 25,\n",
       " 'absolut': 26,\n",
       " 'abstract': 27,\n",
       " 'abt': 28,\n",
       " 'abta': 29,\n",
       " 'aburo': 30,\n",
       " 'abus': 31,\n",
       " 'ac': 32,\n",
       " 'academ': 33,\n",
       " 'acc': 34,\n",
       " 'accent': 35,\n",
       " 'accentur': 36,\n",
       " 'accept': 37,\n",
       " 'access': 38,\n",
       " 'access!': 39,\n",
       " 'accid': 40,\n",
       " 'accident': 41,\n",
       " 'accommod': 42,\n",
       " 'accommodationvouch': 43,\n",
       " 'accomod': 44,\n",
       " 'accordin': 45,\n",
       " 'accordingli': 46,\n",
       " 'accordinglyor': 47,\n",
       " 'account': 48,\n",
       " 'accumul': 49,\n",
       " 'ach': 50,\n",
       " 'achanammarakheshqatar': 51,\n",
       " 'achiev': 52,\n",
       " 'acid!': 53,\n",
       " 'acknowledg': 54,\n",
       " 'aclpm': 55,\n",
       " 'acnt': 56,\n",
       " 'acoentri': 57,\n",
       " 'across': 58,\n",
       " 'acsmsreward': 59,\n",
       " 'act': 60,\n",
       " 'actin': 61,\n",
       " 'action': 62,\n",
       " 'activ': 63,\n",
       " 'actor': 64,\n",
       " 'actual': 65,\n",
       " 'acwicmbcktzr!': 66,\n",
       " 'ad': 67,\n",
       " 'adam': 68,\n",
       " 'add': 69,\n",
       " 'addamsfa': 70,\n",
       " 'addi': 71,\n",
       " 'addict': 72,\n",
       " 'address': 73,\n",
       " 'addressul': 74,\n",
       " 'adewal': 75,\n",
       " 'adi': 76,\n",
       " 'adjust': 77,\n",
       " 'admin': 78,\n",
       " 'administr': 79,\n",
       " 'admir': 80,\n",
       " 'admiss': 81,\n",
       " 'admit': 82,\n",
       " 'admiti': 83,\n",
       " 'ador': 84,\n",
       " 'adp': 85,\n",
       " 'adress': 86,\n",
       " 'adrian': 87,\n",
       " 'adrink': 88,\n",
       " 'adsens': 89,\n",
       " 'adult': 90,\n",
       " 'advanc': 91,\n",
       " 'adventur': 92,\n",
       " 'advic': 93,\n",
       " 'advis': 94,\n",
       " 'advisor': 95,\n",
       " 'ae': 96,\n",
       " 'aeronaut': 97,\n",
       " 'aeroplan': 98,\n",
       " 'afew': 99,\n",
       " 'affair': 100,\n",
       " 'affect': 101,\n",
       " 'affection': 102,\n",
       " 'affectionsamp': 103,\n",
       " 'affidavit': 104,\n",
       " 'afford': 105,\n",
       " 'afghanistan': 106,\n",
       " 'afraid': 107,\n",
       " 'africa': 108,\n",
       " 'african': 109,\n",
       " 'aft': 110,\n",
       " 'afternon': 111,\n",
       " 'afternoon': 112,\n",
       " 'afterward': 113,\n",
       " 'aftr': 114,\n",
       " 'ag': 115,\n",
       " 'again!': 116,\n",
       " 'againcal': 117,\n",
       " 'againlov': 118,\n",
       " 'agalla': 119,\n",
       " 'age': 120,\n",
       " 'agenc': 121,\n",
       " 'agent': 122,\n",
       " 'ageppermesssubscript': 123,\n",
       " 'agesr': 124,\n",
       " 'agidhan': 125,\n",
       " 'ago': 126,\n",
       " 'agocusoon': 127,\n",
       " 'agre': 128,\n",
       " 'agreen': 129,\n",
       " 'ah': 130,\n",
       " 'aha': 131,\n",
       " 'ahead': 132,\n",
       " 'ahge': 133,\n",
       " 'ahhh': 134,\n",
       " 'ahhhhjust': 135,\n",
       " 'ahmad': 136,\n",
       " 'ahnow': 137,\n",
       " 'ahold': 138,\n",
       " 'ahsen': 139,\n",
       " 'ahth': 140,\n",
       " 'ahwhat': 141,\n",
       " 'ai': 142,\n",
       " 'aid': 143,\n",
       " 'aig': 144,\n",
       " 'aight': 145,\n",
       " 'aint': 146,\n",
       " 'air': 147,\n",
       " 'airport': 148,\n",
       " 'airtel': 149,\n",
       " 'aiya': 150,\n",
       " 'aiyah': 151,\n",
       " 'aiyar': 152,\n",
       " 'aiyo': 153,\n",
       " 'aj': 154,\n",
       " 'ajith': 155,\n",
       " 'ak': 156,\n",
       " 'aka': 157,\n",
       " 'akonlon': 158,\n",
       " 'al': 159,\n",
       " 'al!!!!!!!!!': 160,\n",
       " 'alaikkumprid': 161,\n",
       " 'alaipayuth': 162,\n",
       " 'albi': 163,\n",
       " 'album': 164,\n",
       " 'albumquit': 165,\n",
       " 'alcohol': 166,\n",
       " 'aldrin': 167,\n",
       " 'ale': 168,\n",
       " 'alert': 169,\n",
       " 'alert!': 170,\n",
       " 'alertfrom': 171,\n",
       " 'alett': 172,\n",
       " 'alfi': 173,\n",
       " 'algarv': 174,\n",
       " 'algebra': 175,\n",
       " 'algorithm': 176,\n",
       " 'ali': 177,\n",
       " 'alian': 178,\n",
       " 'alibi': 179,\n",
       " 'aliv': 180,\n",
       " 'alivebett': 181,\n",
       " 'all': 182,\n",
       " 'allah': 183,\n",
       " 'allahmeet': 184,\n",
       " 'allahrakhesh': 185,\n",
       " 'allalo': 186,\n",
       " 'allday!': 187,\n",
       " 'allo!': 188,\n",
       " 'allow': 189,\n",
       " 'almost': 190,\n",
       " 'alon': 191,\n",
       " 'along': 192,\n",
       " 'along!': 193,\n",
       " 'alot': 194,\n",
       " 'alreadi': 195,\n",
       " 'alreadysabarish': 196,\n",
       " 'alright': 197,\n",
       " 'alrightokay': 198,\n",
       " 'alrit': 199,\n",
       " 'alritehav': 200,\n",
       " 'also': 201,\n",
       " 'alsoor': 202,\n",
       " 'alter': 203,\n",
       " 'alternativehop': 204,\n",
       " 'although': 205,\n",
       " 'alwa!!': 206,\n",
       " 'alway': 207,\n",
       " 'alwi': 208,\n",
       " 'am': 209,\n",
       " 'am!!': 210,\n",
       " 'amanda': 211,\n",
       " 'amaz': 212,\n",
       " 'ambiti': 213,\n",
       " 'ambrithmaduraimet': 214,\n",
       " 'american': 215,\n",
       " 'ami': 216,\n",
       " 'amigo': 217,\n",
       " 'amk': 218,\n",
       " 'ammaelif': 219,\n",
       " 'ammo': 220,\n",
       " 'amnow': 221,\n",
       " 'among': 222,\n",
       " 'amongst': 223,\n",
       " 'amor': 224,\n",
       " 'amount': 225,\n",
       " 'amp': 226,\n",
       " 'amplikat': 227,\n",
       " 'ampm': 228,\n",
       " 'amrca': 229,\n",
       " 'amrita': 230,\n",
       " 'amt': 231,\n",
       " 'amus': 232,\n",
       " 'an': 233,\n",
       " 'ana': 234,\n",
       " 'anal': 235,\n",
       " 'analysi': 236,\n",
       " 'anand': 237,\n",
       " 'anderson': 238,\n",
       " 'andor': 239,\n",
       " 'andr': 240,\n",
       " 'andrewsboy': 241,\n",
       " 'andro': 242,\n",
       " 'anetwork': 243,\n",
       " 'angel': 244,\n",
       " 'angri': 245,\n",
       " 'anim': 246,\n",
       " 'animal!': 247,\n",
       " 'anjie!': 248,\n",
       " 'anjola': 249,\n",
       " 'anna': 250,\n",
       " 'anni': 251,\n",
       " 'annie!': 252,\n",
       " 'anniversari': 253,\n",
       " 'annonc': 254,\n",
       " 'announc': 255,\n",
       " 'annoy': 256,\n",
       " 'annoyin!': 257,\n",
       " 'anonym': 258,\n",
       " 'anot': 259,\n",
       " 'anoth': 260,\n",
       " 'ansr': 261,\n",
       " 'answer': 262,\n",
       " 'answerin': 263,\n",
       " 'answr': 264,\n",
       " 'antelop': 265,\n",
       " 'anthoni': 266,\n",
       " 'anti': 267,\n",
       " 'antibiot': 268,\n",
       " 'anybodi': 269,\n",
       " 'anyhow': 270,\n",
       " 'anymor': 271,\n",
       " 'anyon': 272,\n",
       " 'anyplac': 273,\n",
       " 'anyth': 274,\n",
       " 'anythi': 275,\n",
       " 'anythin': 276,\n",
       " 'anything!': 277,\n",
       " 'anythingtomorrow': 278,\n",
       " 'anytim': 279,\n",
       " 'anyway': 280,\n",
       " 'anywher': 281,\n",
       " 'aom': 282,\n",
       " 'apart': 283,\n",
       " 'ape': 284,\n",
       " 'apeshit': 285,\n",
       " 'aphe\\x92': 286,\n",
       " 'apnt': 287,\n",
       " 'apo': 288,\n",
       " 'apolog': 289,\n",
       " 'apologet': 290,\n",
       " 'apologis': 291,\n",
       " 'app': 292,\n",
       " 'appar': 293,\n",
       " 'appeal': 294,\n",
       " 'appear': 295,\n",
       " 'appendi': 296,\n",
       " 'appi': 297,\n",
       " 'applebe': 298,\n",
       " 'appledayno': 299,\n",
       " 'applespairsal': 300,\n",
       " 'appli': 301,\n",
       " 'applic': 302,\n",
       " 'appoint': 303,\n",
       " 'appreci': 304,\n",
       " 'appro': 305,\n",
       " 'approach': 306,\n",
       " 'appropri': 307,\n",
       " 'approv': 308,\n",
       " 'appt': 309,\n",
       " 'apr': 310,\n",
       " 'april': 311,\n",
       " 'aproach': 312,\n",
       " 'apt': 313,\n",
       " 'aptitud': 314,\n",
       " 'aquariu': 315,\n",
       " 'ar': 316,\n",
       " 'arab': 317,\n",
       " 'arabian': 318,\n",
       " 'arcad': 319,\n",
       " 'archiv': 320,\n",
       " 'ard': 321,\n",
       " 'ardé': 322,\n",
       " 'area': 323,\n",
       " 'area!': 324,\n",
       " 'arent': 325,\n",
       " 'arestaur': 326,\n",
       " 'aretak': 327,\n",
       " 'argentina': 328,\n",
       " 'argh': 329,\n",
       " 'argu': 330,\n",
       " 'argument': 331,\n",
       " 'ari': 332,\n",
       " 'aris': 333,\n",
       " 'arithmet': 334,\n",
       " 'arm': 335,\n",
       " 'armand': 336,\n",
       " 'armenia': 337,\n",
       " 'arng': 338,\n",
       " 'arngd': 339,\n",
       " 'arnt': 340,\n",
       " 'around': 341,\n",
       " 'around!': 342,\n",
       " 'aroundn': 343,\n",
       " 'arpraveesh': 344,\n",
       " 'arr': 345,\n",
       " 'arrang': 346,\n",
       " 'arrest': 347,\n",
       " 'arriv': 348,\n",
       " 'arrow': 349,\n",
       " 'arsen': 350,\n",
       " 'art': 351,\n",
       " 'art!': 352,\n",
       " 'arti': 353,\n",
       " 'artist': 354,\n",
       " 'arul': 355,\n",
       " 'arun': 356,\n",
       " 'asa': 357,\n",
       " 'asap': 358,\n",
       " 'asap!': 359,\n",
       " 'asapok': 360,\n",
       " 'asda': 361,\n",
       " 'ash': 362,\n",
       " 'ashley': 363,\n",
       " 'ashwini': 364,\n",
       " 'asia': 365,\n",
       " 'asian': 366,\n",
       " 'ask': 367,\n",
       " 'askd': 368,\n",
       " 'askin': 369,\n",
       " 'aslamalaikkuminsha': 370,\n",
       " 'asleep': 371,\n",
       " 'aspect': 372,\n",
       " 'ass': 373,\n",
       " 'ass!': 374,\n",
       " 'ass!!': 375,\n",
       " 'assess': 376,\n",
       " 'asshol': 377,\n",
       " 'assist': 378,\n",
       " 'associ': 379,\n",
       " 'assum': 380,\n",
       " 'asther': 381,\n",
       " 'asthma': 382,\n",
       " 'astn': 383,\n",
       " 'astoundingli': 384,\n",
       " 'astrolog': 385,\n",
       " 'astronom': 386,\n",
       " 'asu': 387,\n",
       " 'asusual!': 388,\n",
       " 'at!': 389,\n",
       " 'ate': 390,\n",
       " 'athlet': 391,\n",
       " 'athom': 392,\n",
       " 'atlanta': 393,\n",
       " 'atlast': 394,\n",
       " 'atleast': 395,\n",
       " 'atm': 396,\n",
       " 'atroci': 397,\n",
       " 'attach': 398,\n",
       " 'attack': 399,\n",
       " 'attempt': 400,\n",
       " 'atten': 401,\n",
       " 'attend': 402,\n",
       " 'attent': 403,\n",
       " 'attitud': 404,\n",
       " 'attract': 405,\n",
       " 'attractioni': 406,\n",
       " 'attribut': 407,\n",
       " 'atyour': 408,\n",
       " 'auction': 409,\n",
       " 'auctionpunj': 410,\n",
       " 'audiit': 411,\n",
       " 'audit': 412,\n",
       " 'audrey': 413,\n",
       " 'audri': 414,\n",
       " 'august': 415,\n",
       " 'august!': 416,\n",
       " 'aunt': 417,\n",
       " 'aunti': 418,\n",
       " 'aunty!': 419,\n",
       " 'aust': 420,\n",
       " 'australia': 421,\n",
       " 'authoris': 422,\n",
       " 'auto': 423,\n",
       " 'autocorrect': 424,\n",
       " 'av': 425,\n",
       " 'ava': 426,\n",
       " 'avail': 427,\n",
       " 'availa': 428,\n",
       " 'available!': 429,\n",
       " 'availablei': 430,\n",
       " 'availablethey': 431,\n",
       " 'avalarr': 432,\n",
       " 'avatar': 433,\n",
       " 'avbl': 434,\n",
       " 'ave': 435,\n",
       " 'aveng': 436,\n",
       " 'avent': 437,\n",
       " 'avenu': 438,\n",
       " 'avier': 439,\n",
       " 'avin': 440,\n",
       " 'avo': 441,\n",
       " 'avoid': 442,\n",
       " 'await': 443,\n",
       " 'awak': 444,\n",
       " 'award': 445,\n",
       " 'award!': 446,\n",
       " 'away': 447,\n",
       " 'away!!': 448,\n",
       " 'awesom': 449,\n",
       " 'awkward': 450,\n",
       " 'aww': 451,\n",
       " 'awww': 452,\n",
       " 'ay': 453,\n",
       " 'ayn': 454,\n",
       " 'ayo': 455,\n",
       " 'b': 456,\n",
       " 'ba': 457,\n",
       " 'baaaaaaaabe!': 458,\n",
       " 'baaaaabe!': 459,\n",
       " 'babe': 460,\n",
       " 'babe!': 461,\n",
       " 'babeprobpop': 462,\n",
       " 'babesozi': 463,\n",
       " 'babi': 464,\n",
       " 'babies!': 465,\n",
       " 'baby!': 466,\n",
       " 'baby!hop': 467,\n",
       " 'babygoodby': 468,\n",
       " 'babyjontet!': 469,\n",
       " 'babysit': 470,\n",
       " 'bac': 471,\n",
       " 'back': 472,\n",
       " 'back!': 473,\n",
       " 'backa': 474,\n",
       " 'backdoor': 475,\n",
       " 'backward': 476,\n",
       " 'bad': 477,\n",
       " 'bad!': 478,\n",
       " 'badass': 479,\n",
       " 'badli': 480,\n",
       " 'badrith': 481,\n",
       " 'bag': 482,\n",
       " 'bagi': 483,\n",
       " 'bahama': 484,\n",
       " 'bahamas!': 485,\n",
       " 'baig': 486,\n",
       " 'bailiff': 487,\n",
       " 'bajarangabali': 488,\n",
       " 'bak': 489,\n",
       " 'bak!': 490,\n",
       " 'bakra': 491,\n",
       " 'bakrid!': 492,\n",
       " 'balanc': 493,\n",
       " 'ball': 494,\n",
       " 'baller': 495,\n",
       " 'balloon!': 496,\n",
       " 'bam': 497,\n",
       " 'bambl': 498,\n",
       " 'ban': 499,\n",
       " 'band': 500,\n",
       " 'bandag': 501,\n",
       " 'bang': 502,\n",
       " 'bangb': 503,\n",
       " 'bangbab': 504,\n",
       " 'bani': 505,\n",
       " 'bank': 506,\n",
       " 'banneduk': 507,\n",
       " 'bannfwflyppm': 508,\n",
       " 'banter': 509,\n",
       " 'bao': 510,\n",
       " 'bar': 511,\n",
       " 'barbi': 512,\n",
       " 'barcelona': 513,\n",
       " 'bare': 514,\n",
       " 'bari': 515,\n",
       " 'barkley': 516,\n",
       " 'barm': 517,\n",
       " 'barolla': 518,\n",
       " 'barrel': 519,\n",
       " 'barri': 520,\n",
       " 'base': 521,\n",
       " 'bash': 522,\n",
       " 'basic': 523,\n",
       " 'basket': 524,\n",
       " 'basketbal': 525,\n",
       " 'basq!ihav': 526,\n",
       " 'bat': 527,\n",
       " 'batch': 528,\n",
       " 'batch!': 529,\n",
       " 'batchlor': 530,\n",
       " 'bath': 531,\n",
       " 'bathroom': 532,\n",
       " 'batsman': 533,\n",
       " 'batt': 534,\n",
       " 'batteri': 535,\n",
       " 'battl': 536,\n",
       " 'bawl': 537,\n",
       " 'bay': 538,\n",
       " 'bb': 539,\n",
       " 'bbc': 540,\n",
       " 'bbdelu': 541,\n",
       " 'bbdpooja': 542,\n",
       " 'bbdtht': 543,\n",
       " 'bblue': 544,\n",
       " 'bbq': 545,\n",
       " 'bc': 546,\n",
       " 'bcaz': 547,\n",
       " 'bck': 548,\n",
       " 'bcm': 549,\n",
       " 'bcmsfwcn': 550,\n",
       " 'bcmwcn': 551,\n",
       " 'bcoz': 552,\n",
       " 'bcozi': 553,\n",
       " 'bcum': 554,\n",
       " 'bcz': 555,\n",
       " 'bday': 556,\n",
       " 'beach': 557,\n",
       " 'bead': 558,\n",
       " 'bear': 559,\n",
       " 'beat': 560,\n",
       " 'beauti': 561,\n",
       " 'beautifulmay': 562,\n",
       " 'bec': 563,\n",
       " 'becau': 564,\n",
       " 'becausethey': 565,\n",
       " 'becom': 566,\n",
       " 'becoz': 567,\n",
       " 'becz': 568,\n",
       " 'bed': 569,\n",
       " 'bed!': 570,\n",
       " 'bedbut': 571,\n",
       " 'bedreal': 572,\n",
       " 'bedrm': 573,\n",
       " 'bedroom': 574,\n",
       " 'bedroom!lov': 575,\n",
       " 'beeen': 576,\n",
       " 'beehoon': 577,\n",
       " 'beendrop': 578,\n",
       " 'beer': 579,\n",
       " 'beerag': 580,\n",
       " 'beerr': 581,\n",
       " 'befor': 582,\n",
       " 'beforehand': 583,\n",
       " 'beforew': 584,\n",
       " 'beg': 585,\n",
       " 'beggar': 586,\n",
       " 'begin': 587,\n",
       " 'begun': 588,\n",
       " 'behalf': 589,\n",
       " 'behav': 590,\n",
       " 'behind': 591,\n",
       " 'bein': 592,\n",
       " 'believ': 593,\n",
       " 'beliv': 594,\n",
       " 'bell': 595,\n",
       " 'bellearli': 596,\n",
       " 'belli': 597,\n",
       " 'belliger': 598,\n",
       " 'belong': 599,\n",
       " 'belov': 600,\n",
       " 'belovd': 601,\n",
       " 'belt': 602,\n",
       " 'ben': 603,\n",
       " 'bend': 604,\n",
       " 'beneath': 605,\n",
       " 'beneficiari': 606,\n",
       " 'benefit': 607,\n",
       " 'benni': 608,\n",
       " 'bergkamp': 609,\n",
       " 'besid': 610,\n",
       " 'best': 611,\n",
       " 'bestcongrat': 612,\n",
       " 'bestrpli': 613,\n",
       " 'bet': 614,\n",
       " 'beta': 615,\n",
       " 'beth': 616,\n",
       " 'betta': 617,\n",
       " 'better': 618,\n",
       " 'bettersn': 619,\n",
       " 'beverag': 620,\n",
       " 'bevieswaz': 621,\n",
       " 'bewar': 622,\n",
       " 'beware!': 623,\n",
       " 'beyond': 624,\n",
       " 'bf': 625,\n",
       " 'bff': 626,\n",
       " 'bfore': 627,\n",
       " 'bhaskar': 628,\n",
       " 'bhayandar': 629,\n",
       " 'bian': 630,\n",
       " 'biatch!': 631,\n",
       " 'bid': 632,\n",
       " 'big': 633,\n",
       " 'big!': 634,\n",
       " 'bigger': 635,\n",
       " 'biggest': 636,\n",
       " 'bike': 637,\n",
       " 'bill': 638,\n",
       " 'billi': 639,\n",
       " 'billion': 640,\n",
       " 'bilo': 641,\n",
       " 'bimbo': 642,\n",
       " 'bin': 643,\n",
       " 'biola': 644,\n",
       " 'bipw': 645,\n",
       " 'bird': 646,\n",
       " 'bird!': 647,\n",
       " 'birla': 648,\n",
       " 'biro': 649,\n",
       " 'birth': 650,\n",
       " 'birthdat': 651,\n",
       " 'birthday': 652,\n",
       " 'bishan': 653,\n",
       " 'bit': 654,\n",
       " 'bitch': 655,\n",
       " 'bite': 656,\n",
       " 'biz': 657,\n",
       " 'bk': 658,\n",
       " 'black': 659,\n",
       " 'blackand': 660,\n",
       " 'blackberri': 661,\n",
       " 'blackim': 662,\n",
       " 'blacko': 663,\n",
       " 'blah': 664,\n",
       " 'blake': 665,\n",
       " 'blame': 666,\n",
       " 'blank': 667,\n",
       " 'blanket': 668,\n",
       " 'blastin': 669,\n",
       " 'bleak': 670,\n",
       " 'bleh': 671,\n",
       " 'bless': 672,\n",
       " 'bless!': 673,\n",
       " 'blessget': 674,\n",
       " 'blessings!': 675,\n",
       " 'blimey': 676,\n",
       " 'blind': 677,\n",
       " 'block': 678,\n",
       " 'blog': 679,\n",
       " 'bloke': 680,\n",
       " 'blond': 681,\n",
       " 'bloo': 682,\n",
       " 'blood': 683,\n",
       " 'bloodblood': 684,\n",
       " 'bloodi': 685,\n",
       " 'bloodsend': 686,\n",
       " 'bloomberg': 687,\n",
       " 'bloombergcom': 688,\n",
       " 'blow': 689,\n",
       " 'blown': 690,\n",
       " 'blu': 691,\n",
       " 'blue': 692,\n",
       " 'bluetooth': 693,\n",
       " 'bluetooth!': 694,\n",
       " 'bluetoothhdset': 695,\n",
       " 'blueu': 696,\n",
       " 'bluff': 697,\n",
       " 'blur': 698,\n",
       " 'bluray': 699,\n",
       " 'bmw': 700,\n",
       " 'bo': 701,\n",
       " 'board': 702,\n",
       " 'boat': 703,\n",
       " 'boatin': 704,\n",
       " 'bob': 705,\n",
       " 'bocpm': 706,\n",
       " 'bodi': 707,\n",
       " 'body!!': 708,\n",
       " 'boggi': 709,\n",
       " 'bognor': 710,\n",
       " 'bold': 711,\n",
       " 'bollo': 712,\n",
       " 'boltblu': 713,\n",
       " 'bom': 714,\n",
       " 'bomb': 715,\n",
       " 'bone': 716,\n",
       " 'bong': 717,\n",
       " 'bonqp': 718,\n",
       " 'bonu': 719,\n",
       " 'bonus!': 720,\n",
       " 'boo': 721,\n",
       " 'boob': 722,\n",
       " 'book': 723,\n",
       " 'bookedth': 724,\n",
       " 'bookmark': 725,\n",
       " 'bookshelf': 726,\n",
       " 'boooo': 727,\n",
       " 'boost': 728,\n",
       " 'booti': 729,\n",
       " 'bootydeli': 730,\n",
       " 'boqu': 731,\n",
       " 'borderlin': 732,\n",
       " 'bore': 733,\n",
       " 'bored!': 734,\n",
       " 'borin': 735,\n",
       " 'boring!': 736,\n",
       " 'born': 737,\n",
       " 'born!': 738,\n",
       " 'bornpleas': 739,\n",
       " 'borrow': 740,\n",
       " 'boskch': 741,\n",
       " 'boskwpppm': 742,\n",
       " 'boss': 743,\n",
       " 'boston': 744,\n",
       " 'bot': 745,\n",
       " 'both!': 746,\n",
       " 'bother': 747,\n",
       " 'bottl': 748,\n",
       " 'bottom': 749,\n",
       " 'bought': 750,\n",
       " 'bought\\x94braindance\\x94a': 751,\n",
       " 'boundari': 752,\n",
       " 'bout': 753,\n",
       " 'bout!': 754,\n",
       " 'bowa': 755,\n",
       " 'bowl': 756,\n",
       " 'bowrc': 757,\n",
       " 'boy': 758,\n",
       " 'boyf': 759,\n",
       " 'boyfriend': 760,\n",
       " 'boyi': 761,\n",
       " 'boytoy': 762,\n",
       " 'boytoy!': 763,\n",
       " 'bpo': 764,\n",
       " 'bra': 765,\n",
       " 'brah': 766,\n",
       " 'brain': 767,\n",
       " 'braini': 768,\n",
       " 'brainless': 769,\n",
       " 'brand': 770,\n",
       " 'brandi': 771,\n",
       " 'brat': 772,\n",
       " 'brave': 773,\n",
       " 'bray': 774,\n",
       " 'brb': 775,\n",
       " 'brdget': 776,\n",
       " 'bread': 777,\n",
       " 'breadstick': 778,\n",
       " 'break': 779,\n",
       " 'breaker': 780,\n",
       " 'breakfast': 781,\n",
       " 'breakin': 782,\n",
       " 'breath': 783,\n",
       " 'breather': 784,\n",
       " 'breez': 785,\n",
       " 'breezi': 786,\n",
       " 'brekkie!': 787,\n",
       " 'bribe': 788,\n",
       " 'bridg': 789,\n",
       " 'bridgwat': 790,\n",
       " 'brief': 791,\n",
       " 'bright': 792,\n",
       " 'brighten': 793,\n",
       " 'brilliant': 794,\n",
       " 'brilliantli': 795,\n",
       " 'brilliantthingi': 796,\n",
       " 'brin': 797,\n",
       " 'bring': 798,\n",
       " 'brisk': 799,\n",
       " 'brison': 800,\n",
       " 'bristol': 801,\n",
       " 'british': 802,\n",
       " 'britney': 803,\n",
       " 'bro': 804,\n",
       " 'broad': 805,\n",
       " 'broadband': 806,\n",
       " 'broke': 807,\n",
       " 'broken': 808,\n",
       " 'brolli': 809,\n",
       " 'broth': 810,\n",
       " 'brotha': 811,\n",
       " 'brother': 812,\n",
       " 'brother‘': 813,\n",
       " 'brought': 814,\n",
       " 'browni': 815,\n",
       " 'brows': 816,\n",
       " 'browser': 817,\n",
       " 'browsin': 818,\n",
       " 'bruce': 819,\n",
       " 'brum!': 820,\n",
       " 'bruv': 821,\n",
       " 'bruv!': 822,\n",
       " 'bslvyl': 823,\n",
       " 'bsn': 824,\n",
       " 'bsnl': 825,\n",
       " 'bstfrnd': 826,\n",
       " 'bt': 827,\n",
       " 'bthere': 828,\n",
       " 'bthmm': 829,\n",
       " 'btnation': 830,\n",
       " 'btnationalr': 831,\n",
       " 'btooth': 832,\n",
       " 'btw': 833,\n",
       " 'btwn': 834,\n",
       " 'bu': 835,\n",
       " 'buck': 836,\n",
       " 'bud': 837,\n",
       " 'buddi': 838,\n",
       " 'buddy!!': 839,\n",
       " 'budget': 840,\n",
       " 'buen': 841,\n",
       " 'buff': 842,\n",
       " 'buffet': 843,\n",
       " 'buffi': 844,\n",
       " 'bugi': 845,\n",
       " 'build': 846,\n",
       " 'built': 847,\n",
       " 'bulb': 848,\n",
       " 'bull': 849,\n",
       " 'bullshit': 850,\n",
       " 'bun': 851,\n",
       " 'bunch': 852,\n",
       " 'bundl': 853,\n",
       " 'bunker': 854,\n",
       " 'buns!': 855,\n",
       " 'burden': 856,\n",
       " 'burger': 857,\n",
       " 'burgundi': 858,\n",
       " 'burial': 859,\n",
       " 'burn': 860,\n",
       " 'burnt': 861,\n",
       " 'burrito': 862,\n",
       " 'bus!': 863,\n",
       " 'buse': 864,\n",
       " 'busetop': 865,\n",
       " 'busi': 866,\n",
       " 'busti': 867,\n",
       " 'busyi': 868,\n",
       " 'but': 869,\n",
       " 'butt': 870,\n",
       " 'butther': 871,\n",
       " 'button': 872,\n",
       " 'buy': 873,\n",
       " 'buyer': 874,\n",
       " 'buz': 875,\n",
       " 'buzi': 876,\n",
       " 'buzz': 877,\n",
       " 'buzz!': 878,\n",
       " 'buzzzz!': 879,\n",
       " 'bw': 880,\n",
       " 'byatch': 881,\n",
       " 'bye': 882,\n",
       " 'by\\x94leafcutt': 883,\n",
       " 'b\\x92day': 884,\n",
       " 'b‘ham': 885,\n",
       " 'c': 886,\n",
       " 'c!': 887,\n",
       " 'cab': 888,\n",
       " 'cabin': 889,\n",
       " 'cabl': 890,\n",
       " 'cafe': 891,\n",
       " 'cage': 892,\n",
       " 'cake': 893,\n",
       " 'caken': 894,\n",
       " 'cal': 895,\n",
       " 'calcul': 896,\n",
       " 'cali': 897,\n",
       " 'calicut': 898,\n",
       " 'california': 899,\n",
       " 'call': 900,\n",
       " 'callback': 901,\n",
       " 'callcost': 902,\n",
       " 'callcoz': 903,\n",
       " 'calld': 904,\n",
       " 'calldrov': 905,\n",
       " 'caller': 906,\n",
       " 'callertun': 907,\n",
       " 'callfreefon': 908,\n",
       " 'callin': 909,\n",
       " 'calling!': 910,\n",
       " 'callingforgot': 911,\n",
       " 'callon': 912,\n",
       " 'calloptout': 913,\n",
       " 'calloptout!yhl': 914,\n",
       " 'calloptoutfq': 915,\n",
       " 'calloptouthf': 916,\n",
       " 'calloptoutj': 917,\n",
       " 'calloptoutjq': 918,\n",
       " 'calloptoutlf': 919,\n",
       " 'calloptoutnd': 920,\n",
       " 'calloptoutqf': 921,\n",
       " 'calls!': 922,\n",
       " 'callsmessagesmiss': 923,\n",
       " 'callsminmobsmor': 924,\n",
       " 'callsminmobsmorelkpobohpfl': 925,\n",
       " 'callsminmoremobsemspobopowa': 926,\n",
       " 'callsppm': 927,\n",
       " 'callurg': 928,\n",
       " 'calm': 929,\n",
       " 'cam': 930,\n",
       " 'camcord': 931,\n",
       " 'came': 932,\n",
       " 'came!': 933,\n",
       " 'camera': 934,\n",
       " 'camera!': 935,\n",
       " 'cameravideo': 936,\n",
       " 'camp': 937,\n",
       " 'campu': 938,\n",
       " 'camri': 939,\n",
       " 'canada': 940,\n",
       " 'canal': 941,\n",
       " 'canari': 942,\n",
       " 'cancel': 943,\n",
       " 'cancer': 944,\n",
       " 'candont': 945,\n",
       " 'canlov': 946,\n",
       " 'cannam': 947,\n",
       " 'cannot': 948,\n",
       " 'cannt': 949,\n",
       " 'cant': 950,\n",
       " 'cantdo': 951,\n",
       " 'canteen': 952,\n",
       " 'can\\x92t': 953,\n",
       " 'can‘t': 954,\n",
       " 'cap': 955,\n",
       " 'capac': 956,\n",
       " 'capit': 957,\n",
       " 'cappuccino': 958,\n",
       " 'captain': 959,\n",
       " 'car': 960,\n",
       " 'card': 961,\n",
       " 'card!': 962,\n",
       " 'cardiff': 963,\n",
       " 'cardin': 964,\n",
       " 'care': 965,\n",
       " 'care!': 966,\n",
       " 'careabout': 967,\n",
       " 'career': 968,\n",
       " 'careful!': 969,\n",
       " 'careinsha': 970,\n",
       " 'careless': 971,\n",
       " 'carent': 972,\n",
       " 'careswt': 973,\n",
       " 'careumma': 974,\n",
       " 'carewhoev': 975,\n",
       " 'carli': 976,\n",
       " 'carlin': 977,\n",
       " 'carlo': 978,\n",
       " 'carlosl': 979,\n",
       " 'carolin': 980,\n",
       " 'carolina': 981,\n",
       " 'caroline!': 982,\n",
       " 'carpark': 983,\n",
       " 'carri': 984,\n",
       " 'carryin': 985,\n",
       " 'carso': 986,\n",
       " 'carton': 987,\n",
       " 'cartoon': 988,\n",
       " 'case': 989,\n",
       " 'cash': 990,\n",
       " 'cash!': 991,\n",
       " 'cashbal': 992,\n",
       " 'cashbincouk': 993,\n",
       " 'cashin': 994,\n",
       " 'cashto': 995,\n",
       " 'cast': 996,\n",
       " 'castor': 997,\n",
       " 'casualti': 998,\n",
       " 'cat': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix = {word:i for i, word in enumerate(remv)}\n",
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PAD>',\n",
       " 1: '<UNK>',\n",
       " 2: 'aa',\n",
       " 3: 'aah',\n",
       " 4: 'aah!',\n",
       " 5: 'aaniy',\n",
       " 6: 'aaooooright',\n",
       " 7: 'aathilov',\n",
       " 8: 'aathiwher',\n",
       " 9: 'ab',\n",
       " 10: 'abbey!',\n",
       " 11: 'abdomen',\n",
       " 12: 'abeg',\n",
       " 13: 'abelu',\n",
       " 14: 'aberdeen',\n",
       " 15: 'abi',\n",
       " 16: 'abi!',\n",
       " 17: 'abil',\n",
       " 18: 'abiola',\n",
       " 19: 'abj',\n",
       " 20: 'abl',\n",
       " 21: 'abnorm',\n",
       " 22: 'about!',\n",
       " 23: 'abouta',\n",
       " 24: 'abroad',\n",
       " 25: 'absenc',\n",
       " 26: 'absolut',\n",
       " 27: 'abstract',\n",
       " 28: 'abt',\n",
       " 29: 'abta',\n",
       " 30: 'aburo',\n",
       " 31: 'abus',\n",
       " 32: 'ac',\n",
       " 33: 'academ',\n",
       " 34: 'acc',\n",
       " 35: 'accent',\n",
       " 36: 'accentur',\n",
       " 37: 'accept',\n",
       " 38: 'access',\n",
       " 39: 'access!',\n",
       " 40: 'accid',\n",
       " 41: 'accident',\n",
       " 42: 'accommod',\n",
       " 43: 'accommodationvouch',\n",
       " 44: 'accomod',\n",
       " 45: 'accordin',\n",
       " 46: 'accordingli',\n",
       " 47: 'accordinglyor',\n",
       " 48: 'account',\n",
       " 49: 'accumul',\n",
       " 50: 'ach',\n",
       " 51: 'achanammarakheshqatar',\n",
       " 52: 'achiev',\n",
       " 53: 'acid!',\n",
       " 54: 'acknowledg',\n",
       " 55: 'aclpm',\n",
       " 56: 'acnt',\n",
       " 57: 'acoentri',\n",
       " 58: 'across',\n",
       " 59: 'acsmsreward',\n",
       " 60: 'act',\n",
       " 61: 'actin',\n",
       " 62: 'action',\n",
       " 63: 'activ',\n",
       " 64: 'actor',\n",
       " 65: 'actual',\n",
       " 66: 'acwicmbcktzr!',\n",
       " 67: 'ad',\n",
       " 68: 'adam',\n",
       " 69: 'add',\n",
       " 70: 'addamsfa',\n",
       " 71: 'addi',\n",
       " 72: 'addict',\n",
       " 73: 'address',\n",
       " 74: 'addressul',\n",
       " 75: 'adewal',\n",
       " 76: 'adi',\n",
       " 77: 'adjust',\n",
       " 78: 'admin',\n",
       " 79: 'administr',\n",
       " 80: 'admir',\n",
       " 81: 'admiss',\n",
       " 82: 'admit',\n",
       " 83: 'admiti',\n",
       " 84: 'ador',\n",
       " 85: 'adp',\n",
       " 86: 'adress',\n",
       " 87: 'adrian',\n",
       " 88: 'adrink',\n",
       " 89: 'adsens',\n",
       " 90: 'adult',\n",
       " 91: 'advanc',\n",
       " 92: 'adventur',\n",
       " 93: 'advic',\n",
       " 94: 'advis',\n",
       " 95: 'advisor',\n",
       " 96: 'ae',\n",
       " 97: 'aeronaut',\n",
       " 98: 'aeroplan',\n",
       " 99: 'afew',\n",
       " 100: 'affair',\n",
       " 101: 'affect',\n",
       " 102: 'affection',\n",
       " 103: 'affectionsamp',\n",
       " 104: 'affidavit',\n",
       " 105: 'afford',\n",
       " 106: 'afghanistan',\n",
       " 107: 'afraid',\n",
       " 108: 'africa',\n",
       " 109: 'african',\n",
       " 110: 'aft',\n",
       " 111: 'afternon',\n",
       " 112: 'afternoon',\n",
       " 113: 'afterward',\n",
       " 114: 'aftr',\n",
       " 115: 'ag',\n",
       " 116: 'again!',\n",
       " 117: 'againcal',\n",
       " 118: 'againlov',\n",
       " 119: 'agalla',\n",
       " 120: 'age',\n",
       " 121: 'agenc',\n",
       " 122: 'agent',\n",
       " 123: 'ageppermesssubscript',\n",
       " 124: 'agesr',\n",
       " 125: 'agidhan',\n",
       " 126: 'ago',\n",
       " 127: 'agocusoon',\n",
       " 128: 'agre',\n",
       " 129: 'agreen',\n",
       " 130: 'ah',\n",
       " 131: 'aha',\n",
       " 132: 'ahead',\n",
       " 133: 'ahge',\n",
       " 134: 'ahhh',\n",
       " 135: 'ahhhhjust',\n",
       " 136: 'ahmad',\n",
       " 137: 'ahnow',\n",
       " 138: 'ahold',\n",
       " 139: 'ahsen',\n",
       " 140: 'ahth',\n",
       " 141: 'ahwhat',\n",
       " 142: 'ai',\n",
       " 143: 'aid',\n",
       " 144: 'aig',\n",
       " 145: 'aight',\n",
       " 146: 'aint',\n",
       " 147: 'air',\n",
       " 148: 'airport',\n",
       " 149: 'airtel',\n",
       " 150: 'aiya',\n",
       " 151: 'aiyah',\n",
       " 152: 'aiyar',\n",
       " 153: 'aiyo',\n",
       " 154: 'aj',\n",
       " 155: 'ajith',\n",
       " 156: 'ak',\n",
       " 157: 'aka',\n",
       " 158: 'akonlon',\n",
       " 159: 'al',\n",
       " 160: 'al!!!!!!!!!',\n",
       " 161: 'alaikkumprid',\n",
       " 162: 'alaipayuth',\n",
       " 163: 'albi',\n",
       " 164: 'album',\n",
       " 165: 'albumquit',\n",
       " 166: 'alcohol',\n",
       " 167: 'aldrin',\n",
       " 168: 'ale',\n",
       " 169: 'alert',\n",
       " 170: 'alert!',\n",
       " 171: 'alertfrom',\n",
       " 172: 'alett',\n",
       " 173: 'alfi',\n",
       " 174: 'algarv',\n",
       " 175: 'algebra',\n",
       " 176: 'algorithm',\n",
       " 177: 'ali',\n",
       " 178: 'alian',\n",
       " 179: 'alibi',\n",
       " 180: 'aliv',\n",
       " 181: 'alivebett',\n",
       " 182: 'all',\n",
       " 183: 'allah',\n",
       " 184: 'allahmeet',\n",
       " 185: 'allahrakhesh',\n",
       " 186: 'allalo',\n",
       " 187: 'allday!',\n",
       " 188: 'allo!',\n",
       " 189: 'allow',\n",
       " 190: 'almost',\n",
       " 191: 'alon',\n",
       " 192: 'along',\n",
       " 193: 'along!',\n",
       " 194: 'alot',\n",
       " 195: 'alreadi',\n",
       " 196: 'alreadysabarish',\n",
       " 197: 'alright',\n",
       " 198: 'alrightokay',\n",
       " 199: 'alrit',\n",
       " 200: 'alritehav',\n",
       " 201: 'also',\n",
       " 202: 'alsoor',\n",
       " 203: 'alter',\n",
       " 204: 'alternativehop',\n",
       " 205: 'although',\n",
       " 206: 'alwa!!',\n",
       " 207: 'alway',\n",
       " 208: 'alwi',\n",
       " 209: 'am',\n",
       " 210: 'am!!',\n",
       " 211: 'amanda',\n",
       " 212: 'amaz',\n",
       " 213: 'ambiti',\n",
       " 214: 'ambrithmaduraimet',\n",
       " 215: 'american',\n",
       " 216: 'ami',\n",
       " 217: 'amigo',\n",
       " 218: 'amk',\n",
       " 219: 'ammaelif',\n",
       " 220: 'ammo',\n",
       " 221: 'amnow',\n",
       " 222: 'among',\n",
       " 223: 'amongst',\n",
       " 224: 'amor',\n",
       " 225: 'amount',\n",
       " 226: 'amp',\n",
       " 227: 'amplikat',\n",
       " 228: 'ampm',\n",
       " 229: 'amrca',\n",
       " 230: 'amrita',\n",
       " 231: 'amt',\n",
       " 232: 'amus',\n",
       " 233: 'an',\n",
       " 234: 'ana',\n",
       " 235: 'anal',\n",
       " 236: 'analysi',\n",
       " 237: 'anand',\n",
       " 238: 'anderson',\n",
       " 239: 'andor',\n",
       " 240: 'andr',\n",
       " 241: 'andrewsboy',\n",
       " 242: 'andro',\n",
       " 243: 'anetwork',\n",
       " 244: 'angel',\n",
       " 245: 'angri',\n",
       " 246: 'anim',\n",
       " 247: 'animal!',\n",
       " 248: 'anjie!',\n",
       " 249: 'anjola',\n",
       " 250: 'anna',\n",
       " 251: 'anni',\n",
       " 252: 'annie!',\n",
       " 253: 'anniversari',\n",
       " 254: 'annonc',\n",
       " 255: 'announc',\n",
       " 256: 'annoy',\n",
       " 257: 'annoyin!',\n",
       " 258: 'anonym',\n",
       " 259: 'anot',\n",
       " 260: 'anoth',\n",
       " 261: 'ansr',\n",
       " 262: 'answer',\n",
       " 263: 'answerin',\n",
       " 264: 'answr',\n",
       " 265: 'antelop',\n",
       " 266: 'anthoni',\n",
       " 267: 'anti',\n",
       " 268: 'antibiot',\n",
       " 269: 'anybodi',\n",
       " 270: 'anyhow',\n",
       " 271: 'anymor',\n",
       " 272: 'anyon',\n",
       " 273: 'anyplac',\n",
       " 274: 'anyth',\n",
       " 275: 'anythi',\n",
       " 276: 'anythin',\n",
       " 277: 'anything!',\n",
       " 278: 'anythingtomorrow',\n",
       " 279: 'anytim',\n",
       " 280: 'anyway',\n",
       " 281: 'anywher',\n",
       " 282: 'aom',\n",
       " 283: 'apart',\n",
       " 284: 'ape',\n",
       " 285: 'apeshit',\n",
       " 286: 'aphe\\x92',\n",
       " 287: 'apnt',\n",
       " 288: 'apo',\n",
       " 289: 'apolog',\n",
       " 290: 'apologet',\n",
       " 291: 'apologis',\n",
       " 292: 'app',\n",
       " 293: 'appar',\n",
       " 294: 'appeal',\n",
       " 295: 'appear',\n",
       " 296: 'appendi',\n",
       " 297: 'appi',\n",
       " 298: 'applebe',\n",
       " 299: 'appledayno',\n",
       " 300: 'applespairsal',\n",
       " 301: 'appli',\n",
       " 302: 'applic',\n",
       " 303: 'appoint',\n",
       " 304: 'appreci',\n",
       " 305: 'appro',\n",
       " 306: 'approach',\n",
       " 307: 'appropri',\n",
       " 308: 'approv',\n",
       " 309: 'appt',\n",
       " 310: 'apr',\n",
       " 311: 'april',\n",
       " 312: 'aproach',\n",
       " 313: 'apt',\n",
       " 314: 'aptitud',\n",
       " 315: 'aquariu',\n",
       " 316: 'ar',\n",
       " 317: 'arab',\n",
       " 318: 'arabian',\n",
       " 319: 'arcad',\n",
       " 320: 'archiv',\n",
       " 321: 'ard',\n",
       " 322: 'ardé',\n",
       " 323: 'area',\n",
       " 324: 'area!',\n",
       " 325: 'arent',\n",
       " 326: 'arestaur',\n",
       " 327: 'aretak',\n",
       " 328: 'argentina',\n",
       " 329: 'argh',\n",
       " 330: 'argu',\n",
       " 331: 'argument',\n",
       " 332: 'ari',\n",
       " 333: 'aris',\n",
       " 334: 'arithmet',\n",
       " 335: 'arm',\n",
       " 336: 'armand',\n",
       " 337: 'armenia',\n",
       " 338: 'arng',\n",
       " 339: 'arngd',\n",
       " 340: 'arnt',\n",
       " 341: 'around',\n",
       " 342: 'around!',\n",
       " 343: 'aroundn',\n",
       " 344: 'arpraveesh',\n",
       " 345: 'arr',\n",
       " 346: 'arrang',\n",
       " 347: 'arrest',\n",
       " 348: 'arriv',\n",
       " 349: 'arrow',\n",
       " 350: 'arsen',\n",
       " 351: 'art',\n",
       " 352: 'art!',\n",
       " 353: 'arti',\n",
       " 354: 'artist',\n",
       " 355: 'arul',\n",
       " 356: 'arun',\n",
       " 357: 'asa',\n",
       " 358: 'asap',\n",
       " 359: 'asap!',\n",
       " 360: 'asapok',\n",
       " 361: 'asda',\n",
       " 362: 'ash',\n",
       " 363: 'ashley',\n",
       " 364: 'ashwini',\n",
       " 365: 'asia',\n",
       " 366: 'asian',\n",
       " 367: 'ask',\n",
       " 368: 'askd',\n",
       " 369: 'askin',\n",
       " 370: 'aslamalaikkuminsha',\n",
       " 371: 'asleep',\n",
       " 372: 'aspect',\n",
       " 373: 'ass',\n",
       " 374: 'ass!',\n",
       " 375: 'ass!!',\n",
       " 376: 'assess',\n",
       " 377: 'asshol',\n",
       " 378: 'assist',\n",
       " 379: 'associ',\n",
       " 380: 'assum',\n",
       " 381: 'asther',\n",
       " 382: 'asthma',\n",
       " 383: 'astn',\n",
       " 384: 'astoundingli',\n",
       " 385: 'astrolog',\n",
       " 386: 'astronom',\n",
       " 387: 'asu',\n",
       " 388: 'asusual!',\n",
       " 389: 'at!',\n",
       " 390: 'ate',\n",
       " 391: 'athlet',\n",
       " 392: 'athom',\n",
       " 393: 'atlanta',\n",
       " 394: 'atlast',\n",
       " 395: 'atleast',\n",
       " 396: 'atm',\n",
       " 397: 'atroci',\n",
       " 398: 'attach',\n",
       " 399: 'attack',\n",
       " 400: 'attempt',\n",
       " 401: 'atten',\n",
       " 402: 'attend',\n",
       " 403: 'attent',\n",
       " 404: 'attitud',\n",
       " 405: 'attract',\n",
       " 406: 'attractioni',\n",
       " 407: 'attribut',\n",
       " 408: 'atyour',\n",
       " 409: 'auction',\n",
       " 410: 'auctionpunj',\n",
       " 411: 'audiit',\n",
       " 412: 'audit',\n",
       " 413: 'audrey',\n",
       " 414: 'audri',\n",
       " 415: 'august',\n",
       " 416: 'august!',\n",
       " 417: 'aunt',\n",
       " 418: 'aunti',\n",
       " 419: 'aunty!',\n",
       " 420: 'aust',\n",
       " 421: 'australia',\n",
       " 422: 'authoris',\n",
       " 423: 'auto',\n",
       " 424: 'autocorrect',\n",
       " 425: 'av',\n",
       " 426: 'ava',\n",
       " 427: 'avail',\n",
       " 428: 'availa',\n",
       " 429: 'available!',\n",
       " 430: 'availablei',\n",
       " 431: 'availablethey',\n",
       " 432: 'avalarr',\n",
       " 433: 'avatar',\n",
       " 434: 'avbl',\n",
       " 435: 'ave',\n",
       " 436: 'aveng',\n",
       " 437: 'avent',\n",
       " 438: 'avenu',\n",
       " 439: 'avier',\n",
       " 440: 'avin',\n",
       " 441: 'avo',\n",
       " 442: 'avoid',\n",
       " 443: 'await',\n",
       " 444: 'awak',\n",
       " 445: 'award',\n",
       " 446: 'award!',\n",
       " 447: 'away',\n",
       " 448: 'away!!',\n",
       " 449: 'awesom',\n",
       " 450: 'awkward',\n",
       " 451: 'aww',\n",
       " 452: 'awww',\n",
       " 453: 'ay',\n",
       " 454: 'ayn',\n",
       " 455: 'ayo',\n",
       " 456: 'b',\n",
       " 457: 'ba',\n",
       " 458: 'baaaaaaaabe!',\n",
       " 459: 'baaaaabe!',\n",
       " 460: 'babe',\n",
       " 461: 'babe!',\n",
       " 462: 'babeprobpop',\n",
       " 463: 'babesozi',\n",
       " 464: 'babi',\n",
       " 465: 'babies!',\n",
       " 466: 'baby!',\n",
       " 467: 'baby!hop',\n",
       " 468: 'babygoodby',\n",
       " 469: 'babyjontet!',\n",
       " 470: 'babysit',\n",
       " 471: 'bac',\n",
       " 472: 'back',\n",
       " 473: 'back!',\n",
       " 474: 'backa',\n",
       " 475: 'backdoor',\n",
       " 476: 'backward',\n",
       " 477: 'bad',\n",
       " 478: 'bad!',\n",
       " 479: 'badass',\n",
       " 480: 'badli',\n",
       " 481: 'badrith',\n",
       " 482: 'bag',\n",
       " 483: 'bagi',\n",
       " 484: 'bahama',\n",
       " 485: 'bahamas!',\n",
       " 486: 'baig',\n",
       " 487: 'bailiff',\n",
       " 488: 'bajarangabali',\n",
       " 489: 'bak',\n",
       " 490: 'bak!',\n",
       " 491: 'bakra',\n",
       " 492: 'bakrid!',\n",
       " 493: 'balanc',\n",
       " 494: 'ball',\n",
       " 495: 'baller',\n",
       " 496: 'balloon!',\n",
       " 497: 'bam',\n",
       " 498: 'bambl',\n",
       " 499: 'ban',\n",
       " 500: 'band',\n",
       " 501: 'bandag',\n",
       " 502: 'bang',\n",
       " 503: 'bangb',\n",
       " 504: 'bangbab',\n",
       " 505: 'bani',\n",
       " 506: 'bank',\n",
       " 507: 'banneduk',\n",
       " 508: 'bannfwflyppm',\n",
       " 509: 'banter',\n",
       " 510: 'bao',\n",
       " 511: 'bar',\n",
       " 512: 'barbi',\n",
       " 513: 'barcelona',\n",
       " 514: 'bare',\n",
       " 515: 'bari',\n",
       " 516: 'barkley',\n",
       " 517: 'barm',\n",
       " 518: 'barolla',\n",
       " 519: 'barrel',\n",
       " 520: 'barri',\n",
       " 521: 'base',\n",
       " 522: 'bash',\n",
       " 523: 'basic',\n",
       " 524: 'basket',\n",
       " 525: 'basketbal',\n",
       " 526: 'basq!ihav',\n",
       " 527: 'bat',\n",
       " 528: 'batch',\n",
       " 529: 'batch!',\n",
       " 530: 'batchlor',\n",
       " 531: 'bath',\n",
       " 532: 'bathroom',\n",
       " 533: 'batsman',\n",
       " 534: 'batt',\n",
       " 535: 'batteri',\n",
       " 536: 'battl',\n",
       " 537: 'bawl',\n",
       " 538: 'bay',\n",
       " 539: 'bb',\n",
       " 540: 'bbc',\n",
       " 541: 'bbdelu',\n",
       " 542: 'bbdpooja',\n",
       " 543: 'bbdtht',\n",
       " 544: 'bblue',\n",
       " 545: 'bbq',\n",
       " 546: 'bc',\n",
       " 547: 'bcaz',\n",
       " 548: 'bck',\n",
       " 549: 'bcm',\n",
       " 550: 'bcmsfwcn',\n",
       " 551: 'bcmwcn',\n",
       " 552: 'bcoz',\n",
       " 553: 'bcozi',\n",
       " 554: 'bcum',\n",
       " 555: 'bcz',\n",
       " 556: 'bday',\n",
       " 557: 'beach',\n",
       " 558: 'bead',\n",
       " 559: 'bear',\n",
       " 560: 'beat',\n",
       " 561: 'beauti',\n",
       " 562: 'beautifulmay',\n",
       " 563: 'bec',\n",
       " 564: 'becau',\n",
       " 565: 'becausethey',\n",
       " 566: 'becom',\n",
       " 567: 'becoz',\n",
       " 568: 'becz',\n",
       " 569: 'bed',\n",
       " 570: 'bed!',\n",
       " 571: 'bedbut',\n",
       " 572: 'bedreal',\n",
       " 573: 'bedrm',\n",
       " 574: 'bedroom',\n",
       " 575: 'bedroom!lov',\n",
       " 576: 'beeen',\n",
       " 577: 'beehoon',\n",
       " 578: 'beendrop',\n",
       " 579: 'beer',\n",
       " 580: 'beerag',\n",
       " 581: 'beerr',\n",
       " 582: 'befor',\n",
       " 583: 'beforehand',\n",
       " 584: 'beforew',\n",
       " 585: 'beg',\n",
       " 586: 'beggar',\n",
       " 587: 'begin',\n",
       " 588: 'begun',\n",
       " 589: 'behalf',\n",
       " 590: 'behav',\n",
       " 591: 'behind',\n",
       " 592: 'bein',\n",
       " 593: 'believ',\n",
       " 594: 'beliv',\n",
       " 595: 'bell',\n",
       " 596: 'bellearli',\n",
       " 597: 'belli',\n",
       " 598: 'belliger',\n",
       " 599: 'belong',\n",
       " 600: 'belov',\n",
       " 601: 'belovd',\n",
       " 602: 'belt',\n",
       " 603: 'ben',\n",
       " 604: 'bend',\n",
       " 605: 'beneath',\n",
       " 606: 'beneficiari',\n",
       " 607: 'benefit',\n",
       " 608: 'benni',\n",
       " 609: 'bergkamp',\n",
       " 610: 'besid',\n",
       " 611: 'best',\n",
       " 612: 'bestcongrat',\n",
       " 613: 'bestrpli',\n",
       " 614: 'bet',\n",
       " 615: 'beta',\n",
       " 616: 'beth',\n",
       " 617: 'betta',\n",
       " 618: 'better',\n",
       " 619: 'bettersn',\n",
       " 620: 'beverag',\n",
       " 621: 'bevieswaz',\n",
       " 622: 'bewar',\n",
       " 623: 'beware!',\n",
       " 624: 'beyond',\n",
       " 625: 'bf',\n",
       " 626: 'bff',\n",
       " 627: 'bfore',\n",
       " 628: 'bhaskar',\n",
       " 629: 'bhayandar',\n",
       " 630: 'bian',\n",
       " 631: 'biatch!',\n",
       " 632: 'bid',\n",
       " 633: 'big',\n",
       " 634: 'big!',\n",
       " 635: 'bigger',\n",
       " 636: 'biggest',\n",
       " 637: 'bike',\n",
       " 638: 'bill',\n",
       " 639: 'billi',\n",
       " 640: 'billion',\n",
       " 641: 'bilo',\n",
       " 642: 'bimbo',\n",
       " 643: 'bin',\n",
       " 644: 'biola',\n",
       " 645: 'bipw',\n",
       " 646: 'bird',\n",
       " 647: 'bird!',\n",
       " 648: 'birla',\n",
       " 649: 'biro',\n",
       " 650: 'birth',\n",
       " 651: 'birthdat',\n",
       " 652: 'birthday',\n",
       " 653: 'bishan',\n",
       " 654: 'bit',\n",
       " 655: 'bitch',\n",
       " 656: 'bite',\n",
       " 657: 'biz',\n",
       " 658: 'bk',\n",
       " 659: 'black',\n",
       " 660: 'blackand',\n",
       " 661: 'blackberri',\n",
       " 662: 'blackim',\n",
       " 663: 'blacko',\n",
       " 664: 'blah',\n",
       " 665: 'blake',\n",
       " 666: 'blame',\n",
       " 667: 'blank',\n",
       " 668: 'blanket',\n",
       " 669: 'blastin',\n",
       " 670: 'bleak',\n",
       " 671: 'bleh',\n",
       " 672: 'bless',\n",
       " 673: 'bless!',\n",
       " 674: 'blessget',\n",
       " 675: 'blessings!',\n",
       " 676: 'blimey',\n",
       " 677: 'blind',\n",
       " 678: 'block',\n",
       " 679: 'blog',\n",
       " 680: 'bloke',\n",
       " 681: 'blond',\n",
       " 682: 'bloo',\n",
       " 683: 'blood',\n",
       " 684: 'bloodblood',\n",
       " 685: 'bloodi',\n",
       " 686: 'bloodsend',\n",
       " 687: 'bloomberg',\n",
       " 688: 'bloombergcom',\n",
       " 689: 'blow',\n",
       " 690: 'blown',\n",
       " 691: 'blu',\n",
       " 692: 'blue',\n",
       " 693: 'bluetooth',\n",
       " 694: 'bluetooth!',\n",
       " 695: 'bluetoothhdset',\n",
       " 696: 'blueu',\n",
       " 697: 'bluff',\n",
       " 698: 'blur',\n",
       " 699: 'bluray',\n",
       " 700: 'bmw',\n",
       " 701: 'bo',\n",
       " 702: 'board',\n",
       " 703: 'boat',\n",
       " 704: 'boatin',\n",
       " 705: 'bob',\n",
       " 706: 'bocpm',\n",
       " 707: 'bodi',\n",
       " 708: 'body!!',\n",
       " 709: 'boggi',\n",
       " 710: 'bognor',\n",
       " 711: 'bold',\n",
       " 712: 'bollo',\n",
       " 713: 'boltblu',\n",
       " 714: 'bom',\n",
       " 715: 'bomb',\n",
       " 716: 'bone',\n",
       " 717: 'bong',\n",
       " 718: 'bonqp',\n",
       " 719: 'bonu',\n",
       " 720: 'bonus!',\n",
       " 721: 'boo',\n",
       " 722: 'boob',\n",
       " 723: 'book',\n",
       " 724: 'bookedth',\n",
       " 725: 'bookmark',\n",
       " 726: 'bookshelf',\n",
       " 727: 'boooo',\n",
       " 728: 'boost',\n",
       " 729: 'booti',\n",
       " 730: 'bootydeli',\n",
       " 731: 'boqu',\n",
       " 732: 'borderlin',\n",
       " 733: 'bore',\n",
       " 734: 'bored!',\n",
       " 735: 'borin',\n",
       " 736: 'boring!',\n",
       " 737: 'born',\n",
       " 738: 'born!',\n",
       " 739: 'bornpleas',\n",
       " 740: 'borrow',\n",
       " 741: 'boskch',\n",
       " 742: 'boskwpppm',\n",
       " 743: 'boss',\n",
       " 744: 'boston',\n",
       " 745: 'bot',\n",
       " 746: 'both!',\n",
       " 747: 'bother',\n",
       " 748: 'bottl',\n",
       " 749: 'bottom',\n",
       " 750: 'bought',\n",
       " 751: 'bought\\x94braindance\\x94a',\n",
       " 752: 'boundari',\n",
       " 753: 'bout',\n",
       " 754: 'bout!',\n",
       " 755: 'bowa',\n",
       " 756: 'bowl',\n",
       " 757: 'bowrc',\n",
       " 758: 'boy',\n",
       " 759: 'boyf',\n",
       " 760: 'boyfriend',\n",
       " 761: 'boyi',\n",
       " 762: 'boytoy',\n",
       " 763: 'boytoy!',\n",
       " 764: 'bpo',\n",
       " 765: 'bra',\n",
       " 766: 'brah',\n",
       " 767: 'brain',\n",
       " 768: 'braini',\n",
       " 769: 'brainless',\n",
       " 770: 'brand',\n",
       " 771: 'brandi',\n",
       " 772: 'brat',\n",
       " 773: 'brave',\n",
       " 774: 'bray',\n",
       " 775: 'brb',\n",
       " 776: 'brdget',\n",
       " 777: 'bread',\n",
       " 778: 'breadstick',\n",
       " 779: 'break',\n",
       " 780: 'breaker',\n",
       " 781: 'breakfast',\n",
       " 782: 'breakin',\n",
       " 783: 'breath',\n",
       " 784: 'breather',\n",
       " 785: 'breez',\n",
       " 786: 'breezi',\n",
       " 787: 'brekkie!',\n",
       " 788: 'bribe',\n",
       " 789: 'bridg',\n",
       " 790: 'bridgwat',\n",
       " 791: 'brief',\n",
       " 792: 'bright',\n",
       " 793: 'brighten',\n",
       " 794: 'brilliant',\n",
       " 795: 'brilliantli',\n",
       " 796: 'brilliantthingi',\n",
       " 797: 'brin',\n",
       " 798: 'bring',\n",
       " 799: 'brisk',\n",
       " 800: 'brison',\n",
       " 801: 'bristol',\n",
       " 802: 'british',\n",
       " 803: 'britney',\n",
       " 804: 'bro',\n",
       " 805: 'broad',\n",
       " 806: 'broadband',\n",
       " 807: 'broke',\n",
       " 808: 'broken',\n",
       " 809: 'brolli',\n",
       " 810: 'broth',\n",
       " 811: 'brotha',\n",
       " 812: 'brother',\n",
       " 813: 'brother‘',\n",
       " 814: 'brought',\n",
       " 815: 'browni',\n",
       " 816: 'brows',\n",
       " 817: 'browser',\n",
       " 818: 'browsin',\n",
       " 819: 'bruce',\n",
       " 820: 'brum!',\n",
       " 821: 'bruv',\n",
       " 822: 'bruv!',\n",
       " 823: 'bslvyl',\n",
       " 824: 'bsn',\n",
       " 825: 'bsnl',\n",
       " 826: 'bstfrnd',\n",
       " 827: 'bt',\n",
       " 828: 'bthere',\n",
       " 829: 'bthmm',\n",
       " 830: 'btnation',\n",
       " 831: 'btnationalr',\n",
       " 832: 'btooth',\n",
       " 833: 'btw',\n",
       " 834: 'btwn',\n",
       " 835: 'bu',\n",
       " 836: 'buck',\n",
       " 837: 'bud',\n",
       " 838: 'buddi',\n",
       " 839: 'buddy!!',\n",
       " 840: 'budget',\n",
       " 841: 'buen',\n",
       " 842: 'buff',\n",
       " 843: 'buffet',\n",
       " 844: 'buffi',\n",
       " 845: 'bugi',\n",
       " 846: 'build',\n",
       " 847: 'built',\n",
       " 848: 'bulb',\n",
       " 849: 'bull',\n",
       " 850: 'bullshit',\n",
       " 851: 'bun',\n",
       " 852: 'bunch',\n",
       " 853: 'bundl',\n",
       " 854: 'bunker',\n",
       " 855: 'buns!',\n",
       " 856: 'burden',\n",
       " 857: 'burger',\n",
       " 858: 'burgundi',\n",
       " 859: 'burial',\n",
       " 860: 'burn',\n",
       " 861: 'burnt',\n",
       " 862: 'burrito',\n",
       " 863: 'bus!',\n",
       " 864: 'buse',\n",
       " 865: 'busetop',\n",
       " 866: 'busi',\n",
       " 867: 'busti',\n",
       " 868: 'busyi',\n",
       " 869: 'but',\n",
       " 870: 'butt',\n",
       " 871: 'butther',\n",
       " 872: 'button',\n",
       " 873: 'buy',\n",
       " 874: 'buyer',\n",
       " 875: 'buz',\n",
       " 876: 'buzi',\n",
       " 877: 'buzz',\n",
       " 878: 'buzz!',\n",
       " 879: 'buzzzz!',\n",
       " 880: 'bw',\n",
       " 881: 'byatch',\n",
       " 882: 'bye',\n",
       " 883: 'by\\x94leafcutt',\n",
       " 884: 'b\\x92day',\n",
       " 885: 'b‘ham',\n",
       " 886: 'c',\n",
       " 887: 'c!',\n",
       " 888: 'cab',\n",
       " 889: 'cabin',\n",
       " 890: 'cabl',\n",
       " 891: 'cafe',\n",
       " 892: 'cage',\n",
       " 893: 'cake',\n",
       " 894: 'caken',\n",
       " 895: 'cal',\n",
       " 896: 'calcul',\n",
       " 897: 'cali',\n",
       " 898: 'calicut',\n",
       " 899: 'california',\n",
       " 900: 'call',\n",
       " 901: 'callback',\n",
       " 902: 'callcost',\n",
       " 903: 'callcoz',\n",
       " 904: 'calld',\n",
       " 905: 'calldrov',\n",
       " 906: 'caller',\n",
       " 907: 'callertun',\n",
       " 908: 'callfreefon',\n",
       " 909: 'callin',\n",
       " 910: 'calling!',\n",
       " 911: 'callingforgot',\n",
       " 912: 'callon',\n",
       " 913: 'calloptout',\n",
       " 914: 'calloptout!yhl',\n",
       " 915: 'calloptoutfq',\n",
       " 916: 'calloptouthf',\n",
       " 917: 'calloptoutj',\n",
       " 918: 'calloptoutjq',\n",
       " 919: 'calloptoutlf',\n",
       " 920: 'calloptoutnd',\n",
       " 921: 'calloptoutqf',\n",
       " 922: 'calls!',\n",
       " 923: 'callsmessagesmiss',\n",
       " 924: 'callsminmobsmor',\n",
       " 925: 'callsminmobsmorelkpobohpfl',\n",
       " 926: 'callsminmoremobsemspobopowa',\n",
       " 927: 'callsppm',\n",
       " 928: 'callurg',\n",
       " 929: 'calm',\n",
       " 930: 'cam',\n",
       " 931: 'camcord',\n",
       " 932: 'came',\n",
       " 933: 'came!',\n",
       " 934: 'camera',\n",
       " 935: 'camera!',\n",
       " 936: 'cameravideo',\n",
       " 937: 'camp',\n",
       " 938: 'campu',\n",
       " 939: 'camri',\n",
       " 940: 'canada',\n",
       " 941: 'canal',\n",
       " 942: 'canari',\n",
       " 943: 'cancel',\n",
       " 944: 'cancer',\n",
       " 945: 'candont',\n",
       " 946: 'canlov',\n",
       " 947: 'cannam',\n",
       " 948: 'cannot',\n",
       " 949: 'cannt',\n",
       " 950: 'cant',\n",
       " 951: 'cantdo',\n",
       " 952: 'canteen',\n",
       " 953: 'can\\x92t',\n",
       " 954: 'can‘t',\n",
       " 955: 'cap',\n",
       " 956: 'capac',\n",
       " 957: 'capit',\n",
       " 958: 'cappuccino',\n",
       " 959: 'captain',\n",
       " 960: 'car',\n",
       " 961: 'card',\n",
       " 962: 'card!',\n",
       " 963: 'cardiff',\n",
       " 964: 'cardin',\n",
       " 965: 'care',\n",
       " 966: 'care!',\n",
       " 967: 'careabout',\n",
       " 968: 'career',\n",
       " 969: 'careful!',\n",
       " 970: 'careinsha',\n",
       " 971: 'careless',\n",
       " 972: 'carent',\n",
       " 973: 'careswt',\n",
       " 974: 'careumma',\n",
       " 975: 'carewhoev',\n",
       " 976: 'carli',\n",
       " 977: 'carlin',\n",
       " 978: 'carlo',\n",
       " 979: 'carlosl',\n",
       " 980: 'carolin',\n",
       " 981: 'carolina',\n",
       " 982: 'caroline!',\n",
       " 983: 'carpark',\n",
       " 984: 'carri',\n",
       " 985: 'carryin',\n",
       " 986: 'carso',\n",
       " 987: 'carton',\n",
       " 988: 'cartoon',\n",
       " 989: 'case',\n",
       " 990: 'cash',\n",
       " 991: 'cash!',\n",
       " 992: 'cashbal',\n",
       " 993: 'cashbincouk',\n",
       " 994: 'cashin',\n",
       " 995: 'cashto',\n",
       " 996: 'cast',\n",
       " 997: 'castor',\n",
       " 998: 'casualti',\n",
       " 999: 'cat',\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_word = {i:word for i, word in enumerate(remv)}\n",
    "ix_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert the words to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_to_ix = []\n",
    "for i in text_clean:\n",
    "    each_ix = []\n",
    "    for w in i.split():\n",
    "        if w not in word_to_ix:\n",
    "            each_ix.append(word_to_ix['<UNK>'])\n",
    "        else:\n",
    "            each_ix.append(word_to_ix[w])\n",
    "    sent_to_ix.append(each_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5418, 6709, 4223]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6771, 1821, 5540, 1842, 2913, 6771, 886, 195, 5540]\n",
      "['u', 'dun', 'say', 'earli', 'hor', 'u', 'c', 'alreadi', 'say']\n"
     ]
    }
   ],
   "source": [
    "print(sent_to_ix[3])\n",
    "print([ix_to_word[i] for i in sent_to_ix[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u dun say earli hor u c alreadi say'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clean[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2e3eb68d5e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#distribution of length of SMS\n",
    "# most of the sms length lies in 10, so we consider max length=10\n",
    "length = []\n",
    "for s in sent_to_ix:\n",
    "    length.append(len(s))\n",
    "import seaborn as sns\n",
    "sns.displot(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sentence = []\n",
    "max_length=10\n",
    "for s in sent_to_ix:\n",
    "    if (len(s)<max_length):\n",
    "        pad_req = max_length-len(s)\n",
    "        pad_zero = [0]*pad_req\n",
    "        padded_sentence.append(s+pad_zero)\n",
    "    elif (len(s)>=10):\n",
    "        padded_sentence.append(s[:max_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5418, 6709]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2509, 3345, 4913, 1370, 427, 845, 4210, 2605, 7297, 3487],\n",
       " [4507, 3522, 3307, 7196, 6771, 4541, 0, 0, 0, 0],\n",
       " [2312, 1968, 7252, 1241, 7211, 2075, 1422, 2186, 6562, 6052],\n",
       " [6771, 1821, 5540, 1842, 2913, 6771, 886, 195, 5540, 0],\n",
       " [4216, 1735, 6484, 2523, 6898, 3652, 341, 6504, 0, 0],\n",
       " [2321, 2813, 1477, 7107, 7285, 473, 3018, 3620, 2379, 6106],\n",
       " [2038, 812, 3620, 5979, 6690, 3620, 143, 4723, 0, 0],\n",
       " [4762, 5339, 3936, 3936, 4601, 4009, 4441, 6952, 5642, 907],\n",
       " [7221, 6926, 4285, 1432, 5605, 5264, 5055, 5377, 1146, 900],\n",
       " [4063, 4101, 6771, 5182, 1966, 6860, 3537, 1217, 4063, 934],\n",
       " [3045, 2539, 2884, 5935, 1735, 7051, 6322, 6170, 271, 6624],\n",
       " [5754, 1035, 7211, 991, 4966, 6725, 1402, 5616, 1332, 4743],\n",
       " [6878, 7107, 2312, 3941, 5055, 3239, 6725, 7285, 1146, 6348],\n",
       " [3221, 5581, 5388, 7285, 6425, 784, 5089, 7275, 6314, 2790],\n",
       " [1486, 6218, 7209, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4065, 6895, 1378, 1162, 7053, 3636, 4280, 6725, 3964, 1162],\n",
       " [4499, 3416, 7068, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1898, 6771, 5318, 5991, 4223, 7425, 6918, 4243, 3829, 6918],\n",
       " [2191, 6439, 7080, 6771, 2146, 6439, 7080, 2569, 456, 0],\n",
       " [1952, 6918, 3795, 1735, 4027, 2514, 4296, 6725, 6874, 4237],\n",
       " [5637, 5991, 4223, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3231, 2509, 6696, 4101, 2672, 2672, 3307, 0, 0, 0],\n",
       " [7539, 4733, 2208, 3522, 1447, 6110, 1232, 0, 0, 0],\n",
       " [110, 2198, 3772, 2509, 6133, 3700, 321, 5875, 3700, 6771],\n",
       " [2160, 197, 7080, 3925, 5938, 0, 0, 0, 0, 0],\n",
       " [2269, 1856, 5835, 3045, 5248, 2979, 6498, 6195, 3864, 2461],\n",
       " [3679, 207, 1309, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1000, 835, 2337, 1894, 3829, 6358, 1856, 4083, 3568, 1651],\n",
       " [3045, 472, 226, 4657, 960, 3041, 3589, 3454, 6461, 5427],\n",
       " [134, 7290, 6920, 5318, 6431, 2146, 3620, 3679, 0, 0],\n",
       " [7029, 6430, 6106, 1158, 6244, 5515, 6430, 1707, 7051, 3652],\n",
       " [7426, 2568, 6918, 290, 4210, 2100, 61, 3620, 6016, 1102],\n",
       " [3351, 6378, 274, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2137, 2090, 2932, 5171, 1424, 0, 0, 0, 0, 0],\n",
       " [6425, 6189, 5396, 6789, 4063, 1044, 4101, 4868, 1278, 5333],\n",
       " [7513, 4507, 2509, 2884, 3692, 6540, 4149, 7539, 6784, 2509],\n",
       " [4562, 3041, 3589, 3454, 5429, 1731, 0, 0, 0, 0],\n",
       " [5593, 3590, 456, 960, 0, 0, 0, 0, 0, 0],\n",
       " [274, 3700, 6771, 1536, 0, 0, 0, 0, 0, 0],\n",
       " [2784, 2933, 5531, 2509, 6412, 5593, 7476, 1536, 274, 6607],\n",
       " [4847, 2509, 132, 7078, 7051, 6244, 2605, 7110, 18, 0],\n",
       " [2277, 6378, 7051, 4262, 1369, 3724, 6272, 318, 6089, 4052],\n",
       " [5417, 860, 4149, 6696, 900, 5333, 5850, 2312, 4363, 4063],\n",
       " [5593, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2606, 2909, 3620, 3839, 7128, 1944, 3756, 3071, 0, 0],\n",
       " [923, 900, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1627, 2461, 2798, 456, 3055, 4315, 0, 0, 0, 0],\n",
       " [2091, 1961, 274, 2509, 0, 0, 0, 0, 0, 0],\n",
       " [7426, 2909, 6767, 950, 1340, 3898, 367, 341, 654, 0],\n",
       " [6771, 1735, 3454, 6160, 1627, 2038, 7051, 2509, 2919, 3394],\n",
       " [6484, 2208, 6540, 5539, 1152, 0, 0, 0, 0, 0],\n",
       " [2588, 6906, 5462, 3620, 3756, 2690, 1903, 5856, 6504, 2461],\n",
       " [3351, 2394, 5387, 1842, 6611, 4112, 2750, 1368, 4848, 6624],\n",
       " [7319, 4288, 5247, 1927, 44, 6506, 3620, 5780, 611, 1340],\n",
       " [5850, 32, 6035, 4291, 3281, 1606, 1602, 5279, 7218, 4860],\n",
       " [3454, 3836, 5691, 7452, 2190, 3760, 0, 0, 0, 0],\n",
       " [1284, 7429, 5981, 1140, 4714, 900, 4405, 886, 6242, 6918],\n",
       " [5947, 3041, 900, 3535, 3925, 0, 0, 0, 0, 0],\n",
       " [6378, 5235, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7445, 5603, 4475, 5635, 0, 0, 0, 0, 0, 0],\n",
       " [2539, 4822, 857, 7080, 2884, 950, 2038, 4133, 4664, 3414],\n",
       " [2672, 2672, 2672, 2541, 3307, 2485, 5799, 5597, 0, 0],\n",
       " [4704, 1065, 3167, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 5429, 6632, 2272, 4507, 1224, 0, 0, 0, 0],\n",
       " [4507, 3522, 1751, 1065, 7196, 1447, 2685, 1781, 195, 5481],\n",
       " [6926, 1432, 4868, 94, 2255, 5265, 5374, 4059, 445, 719],\n",
       " [6578, 5930, 1542, 1496, 5930, 6771, 1542, 5616, 6874, 6927],\n",
       " [6877, 6874, 445, 1256, 6698, 2030, 6685, 57, 1146, 6725],\n",
       " [2762, 4291, 1687, 512, 1224, 3391, 6171, 0, 0, 0],\n",
       " [4854, 2492, 4101, 1941, 0, 0, 0, 0, 0, 0],\n",
       " [7022, 3766, 3839, 5537, 4090, 2775, 0, 0, 0, 0],\n",
       " [2198, 1152, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 460, 3045, 2884, 7049, 5915, 0, 0, 0, 0],\n",
       " [3445, 7479, 4768, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 900, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7029, 3797, 900, 2312, 0, 0, 0, 0, 0, 0],\n",
       " [6430, 1313, 2452, 6690, 1643, 5353, 0, 0, 0, 0],\n",
       " [3620, 4760, 4166, 5695, 4655, 0, 0, 0, 0, 0],\n",
       " [4565, 3756, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6106, 3692, 3296, 4166, 6299, 1846, 0, 0, 0, 0],\n",
       " [5947, 3041, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [3351, 900, 130, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4507, 7080, 2884, 2821, 2821, 0, 0, 0, 0, 0],\n",
       " [4848, 3839, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7513, 4280, 6118, 0, 0, 0, 0, 0, 0, 0],\n",
       " [900, 3535, 1735, 4285, 6883, 5850, 0, 0, 0, 0],\n",
       " [5243, 6771, 2461, 7464, 4262, 6529, 4537, 3238, 3045, 1731],\n",
       " [7425, 6070, 5616, 5339, 3829, 4664, 932, 472, 3045, 472],\n",
       " [3045, 5248, 6106, 6624, 460, 0, 0, 0, 0, 0],\n",
       " [1910, 3370, 1759, 1224, 7136, 6874, 2312, 0, 0, 0],\n",
       " [7426, 1696, 1742, 6063, 1167, 6498, 7500, 1000, 5917, 0],\n",
       " [5947, 4664, 4507, 3925, 260, 4317, 5993, 3531, 112, 998],\n",
       " [5863, 4872, 5863, 4664, 5863, 6704, 4967, 3620, 5193, 5863],\n",
       " [4868, 900, 1432, 5640, 5337, 228, 2642, 990, 5056, 0],\n",
       " [2742, 4852, 873, 3535, 1065, 195, 3601, 2568, 5738, 1835],\n",
       " [2312, 5396, 7029, 1213, 5777, 6406, 4719, 3980, 6949, 2461],\n",
       " [7068, 6382, 4135, 28, 6771, 0, 0, 0, 0, 0],\n",
       " [5593, 2198, 3662, 3664, 4733, 0, 0, 0, 0, 0],\n",
       " [2821, 7247, 4507, 2873, 4405, 7425, 654, 5462, 2281, 2687],\n",
       " [5593, 1422, 1200, 246, 0, 0, 0, 0, 0, 0],\n",
       " [4868, 1735, 6406, 271, 4390, 1922, 5540, 0, 0, 0],\n",
       " [4509, 4223, 6874, 5036, 3687, 3572, 7136, 4822, 6771, 435],\n",
       " [3045, 6106, 3692, 960, 873, 2536, 1786, 6405, 7454, 0],\n",
       " [4762, 5339, 3936, 3936, 4601, 4009, 4441, 6952, 5642, 907],\n",
       " [7319, 7489, 5389, 1627, 3910, 2651, 2422, 744, 3946, 1037],\n",
       " [6797, 3603, 6937, 6797, 3724, 3708, 1519, 0, 0, 0],\n",
       " [6425, 3708, 7231, 652, 6425, 3829, 652, 6712, 3943, 0],\n",
       " [145, 3041, 2843, 2461, 990, 0, 0, 0, 0, 0],\n",
       " [7315, 3161, 73, 6405, 1291, 1261, 3183, 4004, 5639, 0],\n",
       " [3455, 2634, 4526, 4760, 4083, 3620, 618, 3602, 207, 4537],\n",
       " [1735, 7303, 2651, 2750, 866, 0, 0, 0, 0, 0],\n",
       " [4882, 4402, 5342, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2509, 1652, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 4507, 7196, 1187, 3620, 6696, 4291, 6481, 5551, 6771],\n",
       " [2450, 6696, 1296, 3529, 7110, 1770, 5738, 5055, 2642, 900],\n",
       " [7018, 6874, 4564, 5627, 2285, 280, 3045, 2191, 3350, 6725],\n",
       " [1962, 889, 4655, 5481, 2715, 556, 743, 1, 2153, 5981],\n",
       " [7219, 6771, 5981, 5605, 5263, 2879, 2228, 3070, 5979, 3652],\n",
       " [2557, 7425, 4192, 5979, 2339, 1895, 5222, 6650, 4264, 0],\n",
       " [2861, 6805, 3102, 2750, 4733, 5558, 1658, 4847, 873, 2261],\n",
       " [5053, 48, 6077, 5738, 6844, 719, 4913, 1146, 900, 3024],\n",
       " [6878, 4063, 445, 719, 906, 5055, 2186, 6696, 1296, 6772],\n",
       " [4291, 73, 300, 3833, 0, 0, 0, 0, 0, 0],\n",
       " [6578, 6997, 4434, 1941, 5605, 5263, 445, 3883, 4868, 900],\n",
       " [2509, 5509, 4165, 6578, 1731, 0, 0, 0, 0, 0],\n",
       " [7539, 5003, 7067, 6540, 7540, 2198, 873, 0, 0, 0],\n",
       " [2541, 6170, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3461, 2731, 5625, 4090, 7454, 5625, 6406, 747, 5616, 1735],\n",
       " [5427, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2813, 2485, 5182, 6771, 2909, 6771, 5182, 7128, 1557, 5182],\n",
       " [3439, 4166, 1332, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 2884, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1519, 900, 6567, 44, 0, 0, 0, 0, 0, 0],\n",
       " [2208, 262, 5169, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6225, 5176, 7252, 5155, 7211, 6642, 5931, 1830, 4862, 6771],\n",
       " [7051, 2461, 3501, 6624, 7051, 5243, 1710, 3668, 5625, 1657],\n",
       " [2679, 4159, 7461, 0, 0, 0, 0, 0, 0, 0],\n",
       " [900, 3925, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1065, 5427, 582, 63, 0, 0, 0, 0, 0, 0],\n",
       " [7483, 5231, 4149, 1053, 6258, 2312, 2722, 5640, 6406, 2509],\n",
       " [2568, 886, 3549, 6768, 2281, 7539, 3566, 5539, 4965, 3620],\n",
       " [3351, 6406, 7489, 7080, 0, 0, 0, 0, 0, 0],\n",
       " [5789, 7029, 3821, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6287, 6506, 4445, 2461, 6552, 3651, 6481, 3723, 4779, 1359],\n",
       " [3454, 4847, 4563, 472, 0, 0, 0, 0, 0, 0],\n",
       " [7425, 5593, 7407, 1750, 0, 0, 0, 0, 0, 0],\n",
       " [7160, 6056, 4223, 6314, 1152, 6891, 0, 0, 0, 0],\n",
       " [2321, 2742, 5333, 6406, 3045, 5209, 5649, 2154, 3652, 3667],\n",
       " [6798, 900, 1065, 3119, 3603, 587, 5156, 4847, 4995, 2720],\n",
       " [3407, 1559, 1296, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5782, 2568, 3296, 648, 5898, 0, 0, 0, 0, 0],\n",
       " [7217, 2240, 3045, 4288, 0, 0, 0, 0, 0, 0],\n",
       " [7513, 6490, 1139, 618, 1187, 4262, 2509, 4867, 3817, 0],\n",
       " [4507, 6874, 6770, 5333, 0, 0, 0, 0, 0, 0],\n",
       " [4762, 5339, 3936, 3936, 4601, 4009, 4441, 6952, 5642, 907],\n",
       " [2055, 1660, 2237, 7216, 2038, 5704, 5918, 4563, 4132, 1224],\n",
       " [6, 7290, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 3565, 2929, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2783, 3724, 2461, 3145, 6578, 2715, 2541, 758, 6484, 3915],\n",
       " [1432, 5640, 254, 4291, 7429, 1564, 7029, 4868, 900, 346],\n",
       " [7219, 6771, 5981, 5605, 5263, 990, 2879, 2228, 3070, 5979],\n",
       " [3387, 5477, 4262, 4027, 195, 1973, 2049, 5593, 5243, 3603],\n",
       " [4291, 960, 2929, 4696, 4291, 3296, 2699, 0, 0, 0],\n",
       " [3045, 3724, 3045, 1866, 1496, 5992, 3829, 2715, 0, 0],\n",
       " [4847, 6118, 730, 2074, 3156, 2342, 5333, 7425, 5593, 7391],\n",
       " [504, 6874, 4588, 7080, 6771, 5263, 5640, 4149, 1759, 6874],\n",
       " [4848, 6874, 4913, 1835, 1419, 4077, 195, 0, 0, 0],\n",
       " [6878, 6696, 1296, 3529, 7110, 1770, 5738, 5055, 2642, 900],\n",
       " [2821, 2351, 611, 7080, 442, 4035, 7236, 600, 4537, 0],\n",
       " [2605, 2009, 2107, 789, 4262, 3500, 5593, 6607, 0, 0],\n",
       " [7425, 1254, 2288, 201, 6910, 7065, 0, 0, 0, 0],\n",
       " [5789, 4262, 142, 506, 48, 506, 73, 0, 0, 0],\n",
       " [2858, 6490, 6244, 2568, 6540, 2908, 321, 7407, 2509, 2312],\n",
       " [6540, 1224, 3535, 0, 0, 0, 0, 0, 0, 0],\n",
       " [685, 2781, 950, 593, 2281, 6249, 4140, 3041, 2492, 6771],\n",
       " [7128, 3045, 2539, 2198, 531, 2546, 4317, 0, 0, 0],\n",
       " [3589, 3454, 7496, 2568, 4090, 978, 3829, 900, 0, 0],\n",
       " [6771, 6106, 2509, 3835, 0, 0, 0, 0, 0, 0],\n",
       " [6750, 2342, 6080, 7186, 5738, 7275, 472, 6537, 3756, 2146],\n",
       " [6406, 1707, 5333, 3589, 3454, 3671, 0, 0, 0, 0],\n",
       " [2822, 6017, 3847, 6918, 7099, 3620, 3454, 5525, 1979, 5333],\n",
       " [3614, 2909, 4482, 4090, 4262, 2012, 1941, 4101, 306, 2989],\n",
       " [3679, 6771, 6714, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4507, 2452, 6690, 1643, 5353, 0, 0, 0, 0, 0],\n",
       " [2662, 1167, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2509, 4390, 2608, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2783, 2703, 1, 2190, 3296, 3549, 7290, 6662, 2461, 472],\n",
       " [2680, 449, 4018, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4868, 900, 1432, 5640, 5337, 2325, 228, 2642, 990, 5056],\n",
       " [2568, 3790, 5187, 6540, 2461, 0, 0, 0, 0, 0],\n",
       " [3332, 5235, 2884, 2509, 531, 2208, 5754, 6895, 4280, 6378],\n",
       " [6830, 1961, 2190, 6420, 415, 7360, 0, 0, 0, 0],\n",
       " [3045, 5947, 3221, 3304, 3559, 4760, 1735, 3387, 6658, 3910],\n",
       " [2821, 2186, 1254, 1351, 0, 0, 0, 0, 0, 0],\n",
       " [6118, 2937, 6207, 6080, 5910, 20, 2492, 4582, 2045, 6117],\n",
       " [2909, 7496, 5644, 4291, 5558, 7429, 7233, 2583, 1496, 0],\n",
       " [2645, 4143, 1519, 2738, 4307, 1496, 0, 0, 0, 0],\n",
       " [6771, 2568, 4779, 6131, 0, 0, 0, 0, 0, 0],\n",
       " [2698, 1512, 2813, 6568, 3925, 4885, 4587, 4146, 0, 0],\n",
       " [2821, 3376, 2038, 2909, 5593, 6611, 654, 685, 469, 6725],\n",
       " [2294, 1940, 3756, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5625, 3756, 836, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2783, 1478, 3221, 2198, 1214, 6725, 6771, 2198, 6771, 3724],\n",
       " [48, 5289, 6194, 3122, 3752, 3396, 5009, 48, 493, 5444],\n",
       " [2550, 5826, 2396, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 900, 203, 4507, 0, 0, 0, 0, 0, 0],\n",
       " [7539, 5540, 3620, 1484, 1821, 873, 1997, 4604, 948, 4590],\n",
       " [1962, 889, 4655, 5481, 2715, 556, 743, 1, 2153, 5981],\n",
       " [145, 7464, 1484, 6134, 1712, 0, 0, 0, 0, 0],\n",
       " [4868, 2492, 6891, 1287, 6578, 3752, 5294, 638, 0, 0],\n",
       " [5717, 633, 3662, 2461, 5241, 0, 0, 0, 0, 0],\n",
       " [7160, 821, 2909, 2605, 779, 5376, 5612, 0, 0, 0],\n",
       " [2884, 207, 1053, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3438, 7128, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7513, 7539, 4353, 3574, 0, 0, 0, 0, 0, 0],\n",
       " [5960, 2606, 2884, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2186, 3883, 2752, 6662, 1770, 5003, 0, 0, 0, 0],\n",
       " [6552, 2742, 5834, 7128, 4721, 4317, 0, 0, 0, 0],\n",
       " [1849, 139, 2568, 5605, 3910, 2541, 0, 0, 0, 0],\n",
       " [6314, 1840, 3859, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7426, 6484, 6895, 2638, 396, 5299, 6244, 6461, 280, 2790],\n",
       " [4507, 5061, 6314, 6874, 6540, 0, 0, 0, 0, 0],\n",
       " [4602, 900, 6775, 5462, 7240, 3129, 2720, 1675, 6895, 4602],\n",
       " [5947, 3041, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 5540, 3574, 1351, 4390, 2711, 3522, 5540, 6918, 5423],\n",
       " [4291, 4063, 4192, 2510, 6725, 4363, 1213, 6580, 7397, 4580],\n",
       " [7315, 5248, 304, 900, 4262, 5910, 6322, 0, 0, 0],\n",
       " [6771, 3925, 6874, 1774, 4710, 5935, 6874, 968, 2247, 6070],\n",
       " [2813, 1242, 1913, 4896, 4173, 0, 0, 0, 0, 0],\n",
       " [3603, 6146, 6360, 552, 6360, 6359, 3588, 226, 1273, 1840],\n",
       " [1519, 2541, 4112, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2461, 2409, 7037, 1392, 1435, 5410, 5388, 5760, 3756, 6140],\n",
       " [1519, 2509, 5452, 4848, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 535, 1632, 7426, 3045, 0, 0, 0, 0, 0],\n",
       " [7447, 6752, 207, 427, 7290, 4848, 0, 0, 0, 0],\n",
       " [6406, 3925, 5910, 5649, 6578, 6771, 2190, 1486, 2038, 2233],\n",
       " [5046, 4499, 3756, 1224, 6870, 0, 0, 0, 0, 0],\n",
       " [3041, 3651, 1170, 3620, 835, 6118, 6140, 0, 0, 0],\n",
       " [7498, 7203, 5235, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4291, 6458, 331, 7211, 5799, 3704, 4779, 1735, 330, 6874],\n",
       " [6771, 5587, 80, 3692, 3829, 1296, 6778, 5443, 6484, 6874],\n",
       " [6604, 2186, 2762, 3521, 989, 950, 0, 0, 0, 0],\n",
       " [4871, 6375, 6918, 437, 1731, 6024, 0, 0, 0, 0],\n",
       " [4509, 5701, 3913, 5764, 5960, 618, 0, 0, 0, 0],\n",
       " [205, 6597, 6771, 1484, 3045, 486, 2078, 7068, 5248, 3620],\n",
       " [6771, 1735, 5318, 4526, 1237, 0, 0, 0, 0, 0],\n",
       " [3531, 5481, 7097, 1627, 1735, 5839, 0, 0, 0, 0],\n",
       " [367, 900, 4507, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3362, 7275, 527, 4249, 3116, 0, 0, 0, 0, 0],\n",
       " [1627, 7290, 4499, 4507, 2552, 3041, 2164, 5240, 6540, 7034],\n",
       " [1285, 6874, 445, 1010, 7007, 2478, 2642, 2312, 1968, 7252],\n",
       " [5215, 895, 1795, 1548, 1545, 3996, 2875, 0, 0, 0],\n",
       " [7136, 6874, 3723, 554, 245, 7194, 6771, 1695, 6314, 5637],\n",
       " [1719, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6855, 1496, 201, 5703, 1242, 6314, 7247, 7080, 6905, 6314],\n",
       " [3045, 472, 3578, 3454, 7489, 5240, 0, 0, 0, 0],\n",
       " [1735, 4258, 1977, 1731, 2461, 472, 6504, 3045, 2754, 0],\n",
       " [4049, 7507, 460, 4307, 3314, 6257, 0, 0, 0, 0],\n",
       " [3730, 4262, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6696, 1296, 5333, 4482, 6961, 2702, 279, 4285, 3996, 6839],\n",
       " [3231, 4700, 4280, 4006, 1224, 6578, 6484, 0, 0, 0],\n",
       " [7513, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [280, 3045, 2509, 5718, 1187, 5754, 1731, 7454, 1821, 1682],\n",
       " [3777, 5394, 6874, 342, 2671, 0, 0, 0, 0, 0],\n",
       " [2813, 5248, 2914, 7051, 1053, 5593, 4219, 6406, 2923, 6406],\n",
       " [1654, 1224, 6891, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7048, 4852, 6698, 5921, 0, 0, 0, 0, 0, 0],\n",
       " [6244, 7454, 6106, 6696, 2461, 2875, 0, 0, 0, 0],\n",
       " [6874, 5396, 5640, 1038, 2312, 1380, 2509, 1177, 1122, 1298],\n",
       " [2061, 1759, 2220, 3269, 0, 0, 0, 0, 0, 0],\n",
       " [5396, 1175, 2461, 6789, 5785, 1050, 4063, 7107, 1122, 6642],\n",
       " [1224, 4165, 5953, 4230, 5799, 0, 0, 0, 0, 0],\n",
       " [4317, 1941, 260, 1496, 4112, 1224, 5981, 7080, 3897, 5863],\n",
       " [2866, 719, 5981, 4966, 2455, 2866, 7007, 262, 1849, 5169],\n",
       " [6898, 2651, 3986, 7128, 6314, 960, 0, 0, 0, 0],\n",
       " [4463, 625, 1224, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6378, 5413, 3801, 2472, 6444, 0, 0, 0, 0, 0],\n",
       " [449, 3041, 5593, 654, 0, 0, 0, 0, 0, 0],\n",
       " [5625, 6768, 2261, 3620, 0, 0, 0, 0, 0, 0],\n",
       " [1731, 2699, 1015, 2376, 6281, 7454, 0, 0, 0, 0],\n",
       " [2568, 900, 6634, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7136, 6771, 4027, 5910, 4779, 1552, 5981, 6771, 4779, 5981],\n",
       " [4507, 367, 4090, 2110, 0, 0, 0, 0, 0, 0],\n",
       " [4515, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7426, 6484, 6906, 2662, 6106, 4714, 3529, 4317, 2461, 138],\n",
       " [3351, 3986, 1224, 6624, 1152, 3589, 1842, 0, 0, 0],\n",
       " [4507, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 464, 3045, 1399, 2485, 2342, 5182, 6771, 2492, 900],\n",
       " [3603, 3910, 3708, 3724, 3603, 3724, 4760, 3603, 7297, 900],\n",
       " [1527, 3821, 6628, 6141, 6860, 6629, 3692, 4521, 1877, 5203],\n",
       " [2813, 6597, 4223, 2421, 130, 0, 0, 0, 0, 0],\n",
       " [2679, 6771, 2294, 2146, 6176, 1447, 6918, 930, 7290, 0],\n",
       " [4562, 2568, 654, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4166, 876, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [41, 1559, 3964, 5343, 4868, 0, 0, 0, 0, 0],\n",
       " [6566, 1432, 3897, 1146, 2312, 934, 4808, 6862, 4733, 2509],\n",
       " [6837, 5799, 2509, 2660, 7315, 307, 0, 0, 0, 0],\n",
       " [2989, 6364, 3829, 1384, 1941, 3603, 1632, 4884, 3387, 4537],\n",
       " [950, 4822, 4808, 5388, 4847, 5616, 3964, 0, 0, 0],\n",
       " [4262, 1200, 5462, 6609, 593, 6540, 7107, 195, 0, 0],\n",
       " [449, 5318, 3529, 6540, 2568, 5908, 2828, 2208, 6540, 1633],\n",
       " [5705, 5248, 5714, 5553, 950, 3048, 5585, 1549, 4317, 6771],\n",
       " [4499, 7080, 2261, 2341, 7051, 2509, 3909, 6624, 0, 0],\n",
       " [7269, 64, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5850, 32, 677, 1486, 6772, 5416, 14, 6832, 3422, 1065],\n",
       " [7513, 5317, 6484, 723, 0, 0, 0, 0, 0, 0],\n",
       " [3294, 367, 6771, 7048, 3925, 0, 0, 0, 0, 0],\n",
       " [3679, 7425, 2346, 2704, 6511, 1003, 6771, 7275, 873, 6170],\n",
       " [6451, 1065, 4293, 5605, 1298, 2405, 6617, 2567, 460, 6024],\n",
       " [2413, 3399, 325, 726, 0, 0, 0, 0, 0, 0],\n",
       " [6578, 37, 1508, 37, 812, 5793, 3730, 1519, 611, 1165],\n",
       " [6484, 6874, 5854, 7211, 7107, 7112, 5176, 6406, 4860, 4413],\n",
       " [5540, 2781, 2492, 900, 2342, 2568, 4090, 2750, 1552, 873],\n",
       " [2821, 7080, 6771, 1496, 4380, 7083, 5243, 6874, 6831, 2909],\n",
       " [3806, 1496, 2605, 1496, 0, 0, 0, 0, 0, 0],\n",
       " [3432, 2715, 4929, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2858, 2651, 2509, 3381, 4210, 4969, 7466, 2680, 1823, 6309],\n",
       " [5248, 1813, 2342, 3045, 107, 0, 0, 0, 0, 0],\n",
       " [1534, 4548, 4063, 4163, 1966, 6860, 3537, 1217, 934, 4063],\n",
       " [1200, 893, 2651, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3959, 1130, 460, 3724, 7407, 3427, 0, 0, 0, 0],\n",
       " [2813, 1735, 2509, 7068, 3946, 3772, 2680, 0, 0, 0],\n",
       " [1414, 6771, 6378, 4972, 3045, 2535, 456, 654, 3486, 1187],\n",
       " [7315, 2605, 7128, 2655, 1340, 3925, 801, 5410, 5923, 2461],\n",
       " [5063, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [923, 900, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 1457, 6578, 1152, 0, 0, 0, 0, 0, 0],\n",
       " [3018, 5540, 6430, 2541, 5764, 7128, 3454, 6668, 5273, 5238],\n",
       " [1313, 6406, 7489, 4700, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 5238, 6406, 5625, 3913, 3307, 5238, 3615, 0, 0],\n",
       " [3434, 3405, 4134, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3898, 1340, 2461, 723, 6607, 5370, 3054, 5915, 0, 0],\n",
       " [900, 2460, 4754, 4762, 4019, 900, 2167, 3630, 6954, 38],\n",
       " [1035, 3986, 2034, 5935, 6977, 5051, 6086, 4808, 4434, 1935],\n",
       " [6923, 1496, 5982, 7211, 5176, 6314, 4710, 6698, 3611, 5616],\n",
       " [6306, 2884, 460, 6106, 0, 0, 0, 0, 0, 0],\n",
       " [1313, 1224, 2742, 7217, 1648, 0, 0, 0, 0, 0],\n",
       " [5830, 6246, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 3041, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 900, 5388, 900, 2699, 4808, 0, 0, 0, 0],\n",
       " [4507, 6430, 2605, 3708, 0, 0, 0, 0, 0, 0],\n",
       " [6314, 4956, 1224, 6455, 4192, 6406, 4405, 2715, 5238, 4537],\n",
       " [6771, 2826, 6137, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3139, 3620, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5793, 1158, 6765, 5432, 648, 5898, 7452, 0, 0, 0],\n",
       " [2649, 2509, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1615, 7460, 3332, 5539, 6874, 3821, 989, 2970, 2742, 5625],\n",
       " [4537, 5852, 5025, 5063, 0, 0, 0, 0, 0, 0],\n",
       " [2107, 5664, 1722, 5643, 6725, 6789, 6257, 6725, 1332, 4762],\n",
       " [1065, 5248, 4027, 5593, 3277, 2605, 4101, 0, 0, 0],\n",
       " [4216, 950, 2790, 3221, 4288, 3164, 0, 0, 0, 0],\n",
       " [7489, 960, 2927, 2690, 3045, 2509, 285, 0, 0, 0],\n",
       " [6578, 5947, 1497, 2042, 245, 2042, 4022, 2989, 4884, 4884],\n",
       " [7464, 2662, 2042, 2178, 4166, 4262, 166, 3261, 6696, 2178],\n",
       " [3756, 3178, 4018, 4018, 126, 7347, 0, 0, 0, 0],\n",
       " [6425, 911, 5540, 2715, 4534, 5791, 2191, 5318, 3974, 3135],\n",
       " [1285, 6874, 445, 1010, 7007, 2478, 2642, 2312, 1968, 7252],\n",
       " [6874, 992, 1427, 4966, 3824, 6874, 994, 5616, 990, 4889],\n",
       " [3045, 64, 7290, 7290, 2038, 5826, 3531, 5780, 3045, 6819],\n",
       " [2784, 2568, 6052, 241, 3687, 7081, 1206, 3387, 4956, 0],\n",
       " [2672, 2672, 1313, 1313, 1093, 1096, 0, 0, 0, 0],\n",
       " [4499, 4507, 5061, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1065, 413, 6079, 5388, 0, 0, 0, 0, 0, 0],\n",
       " [866, 6696, 2198, 4291, 7429, 3692, 2293, 2186, 3925, 0],\n",
       " [2541, 112, 6226, 1495, 1496, 5293, 2715, 180, 783, 147],\n",
       " [7128, 3454, 7516, 6314, 965, 7303, 0, 0, 0, 0],\n",
       " [6861, 3790, 4483, 3537, 4129, 5933, 4363, 2312, 694, 1751],\n",
       " [1671, 1199, 5439, 6118, 3964, 5333, 6118, 7385, 1432, 5640],\n",
       " [7067, 6828, 2461, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1313, 6406, 7489, 5240, 0, 0, 0, 0, 0, 0],\n",
       " [2783, 762, 2441, 4027, 195, 7266, 7231, 569, 1415, 3724],\n",
       " [6015, 569, 7128, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 2509, 531, 4149, 4280, 3756, 3996, 0, 0, 0],\n",
       " [950, 3387, 6322, 4760, 6244, 4733, 128, 5036, 4847, 6378],\n",
       " [6425, 5396, 4588, 5286, 1044, 2429, 4762, 7107, 6851, 279],\n",
       " [5540, 2711, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1340, 5599, 3931, 1631, 5272, 2078, 0, 0, 0, 0],\n",
       " [7128, 6461, 3708, 6481, 2711, 3629, 4291, 7429, 5762, 511],\n",
       " [3387, 4734, 5402, 798, 0, 0, 0, 0, 0, 0],\n",
       " [6342, 5215, 5789, 900, 5850, 3620, 564, 2750, 6949, 5085],\n",
       " [2651, 6430, 7303, 4192, 3454, 6461, 7080, 707, 5329, 3045],\n",
       " [7426, 6244, 2492, 1348, 4018, 6668, 7041, 0, 0, 0],\n",
       " [2813, 3565, 633, 1514, 6314, 965, 0, 0, 0, 0],\n",
       " [2813, 3531, 130, 3925, 0, 0, 0, 0, 0, 0],\n",
       " [1751, 3996, 6725, 4101, 2312, 693, 4584, 427, 5931, 4363],\n",
       " [6632, 4140, 4646, 3600, 0, 0, 0, 0, 0, 0],\n",
       " [1432, 4848, 900, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4048, 6540, 1735, 3620, 2379, 0, 0, 0, 0, 0],\n",
       " [4163, 2690, 5036, 4584, 3630, 5327, 3537, 934, 4808, 2312],\n",
       " [7513, 3772, 843, 6771, 1856, 195, 0, 0, 0, 0],\n",
       " [2968, 3531, 2301, 1651, 0, 0, 0, 0, 0, 0],\n",
       " [2813, 5521, 2509, 3150, 4834, 3410, 0, 0, 0, 0],\n",
       " [4112, 4507, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7425, 6484, 4485, 3519, 5427, 6484, 6430, 3529, 1496, 1627],\n",
       " [4822, 753, 3178, 6540, 2509, 0, 0, 0, 0, 0],\n",
       " [4768, 445, 896, 2045, 6765, 4104, 1427, 4537, 4101, 4772],\n",
       " [65, 5826, 6106, 3986, 6771, 900, 472, 6406, 2583, 5415],\n",
       " [207, 5148, 866, 5148, 4826, 373, 2081, 4537, 4563, 4760],\n",
       " [2541, 2038, 5789, 159, 5486, 7027, 2715, 4298, 2585, 2516],\n",
       " [2862, 7051, 1037, 2169, 5172, 1458, 7049, 2461, 6298, 79],\n",
       " [2312, 5396, 6406, 2208, 4919, 6406, 2461, 6709, 6618, 2790],\n",
       " [1519, 1064, 6322, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2685, 1374, 5703, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4368, 6430, 2711, 6537, 2461, 6504, 0, 0, 0, 0],\n",
       " [7440, 2605, 3663, 3790, 6693, 860, 3756, 6070, 2927, 0],\n",
       " [2680, 2461, 6895, 1786, 6898, 3839, 3454, 3708, 6116, 0],\n",
       " [7128, 5837, 1667, 1152, 4885, 2130, 1480, 2909, 1496, 4507],\n",
       " [2784, 2541, 7107, 2107, 1783, 5915, 3535, 0, 0, 0],\n",
       " [2754, 6662, 865, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3969, 6406, 4027, 5618, 4027, 4434, 4027, 5626, 4027, 4027],\n",
       " [1224, 5427, 4913, 3171, 4852, 7110, 0, 0, 0, 0],\n",
       " [1187, 7051, 6481, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4515, 3041, 2509, 7417, 3292, 5815, 321, 4604, 2509, 1139],\n",
       " [798, 2884, 7137, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1486, 5640, 900, 741, 0, 0, 0, 0, 0, 0],\n",
       " [7163, 1735, 6771, 7051, 5826, 0, 0, 0, 0, 0],\n",
       " [197, 4291, 2512, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2312, 1968, 7112, 1248, 6406, 7285, 7211, 6348, 7404, 0],\n",
       " [197, 3041, 2752, 4018, 6406, 3925, 0, 0, 0, 0],\n",
       " [5616, 3673, 6874, 3730, 4223, 3304, 2765, 6725, 3724, 4223],\n",
       " [7444, 3529, 7107, 3045, 6314, 3652, 900, 0, 0, 0],\n",
       " [5910, 1296, 1486, 5640, 1962, 4808, 2107, 7471, 2190, 900],\n",
       " [5800, 2921, 131, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6878, 4063, 4434, 445, 5055, 2642, 900, 3509, 3630, 1146],\n",
       " [5616, 6874, 2342, 5263, 5915, 6874, 7000, 5979, 1992, 1103],\n",
       " [4507, 5689, 4507, 2651, 0, 0, 0, 0, 0, 0],\n",
       " [8, 1519, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4664, 6886, 6481, 1922, 0, 0, 0, 0, 0, 0],\n",
       " [2014, 7539, 3999, 2492, 3614, 1187, 2568, 960, 6578, 0],\n",
       " [7262, 873, 700, 960, 6881, 7012, 6880, 2994, 5727, 3756],\n",
       " [2884, 7068, 6752, 3700, 0, 0, 0, 0, 0, 0],\n",
       " [6906, 6314, 2173, 2368, 4018, 5355, 7425, 5169, 0, 0],\n",
       " [1284, 4363, 6961, 934, 4808, 900, 900, 1332, 4974, 435],\n",
       " [723, 6529, 4929, 0, 0, 0, 0, 0, 0, 0],\n",
       " [427, 3045, 3620, 5388, 341, 2833, 226, 3756, 6420, 0],\n",
       " [3964, 5625, 369, 3756, 1726, 5732, 4733, 3756, 3756, 0],\n",
       " [367, 2395, 3160, 3221, 6597, 6131, 3620, 6388, 6540, 195],\n",
       " [3687, 298, 2368, 6314, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 2909, 6771, 2461, 6732, 2731, 2437, 3996, 3531, 6484],\n",
       " [3620, 3724, 346, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7446, 5248, 2607, 6597, 3362, 611, 1386, 5470, 7301, 6659],\n",
       " [6240, 7034, 2638, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4504, 5539, 6655, 1647, 886, 2294, 2626, 3594, 0, 0],\n",
       " [5947, 3041, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [2813, 2813, 7145, 4094, 5540, 4096, 2936, 2562, 2939, 1716],\n",
       " [5947, 535, 1632, 1224, 3045, 2461, 2588, 7173, 4848, 0],\n",
       " [7128, 1731, 676, 1883, 7426, 3418, 5318, 7311, 2856, 0],\n",
       " [7275, 2461, 1267, 1519, 3454, 3999, 2051, 0, 0, 0],\n",
       " [3679, 3806, 4852, 4291, 7429, 0, 0, 0, 0, 0],\n",
       " [3996, 3535, 3351, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2707, 3711, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6425, 2909, 2541, 1496, 6578, 0, 0, 0, 0, 0],\n",
       " [3443, 1598, 7051, 6680, 1961, 0, 0, 0, 0, 0],\n",
       " [4507, 6378, 6080, 7426, 6659, 4576, 6481, 3065, 4101, 0],\n",
       " [3664, 5142, 2890, 6389, 7126, 5033, 5296, 6106, 2790, 900],\n",
       " [5754, 5754, 6484, 3041, 2509, 3829, 4591, 6711, 0, 0],\n",
       " [3692, 216, 6875, 561, 3136, 7268, 3620, 6771, 3708, 3454],\n",
       " [2909, 6430, 5365, 1292, 3136, 3417, 6070, 367, 4985, 3636],\n",
       " [900, 1332, 2651, 3183, 477, 4027, 7407, 4262, 7407, 7051],\n",
       " [2509, 6520, 1636, 2149, 1538, 1319, 3092, 2758, 2051, 593],\n",
       " [6771, 2509, 4808, 2539, 1632, 6080, 0, 0, 0, 0],\n",
       " [2605, 4288, 618, 1496, 2492, 2038, 5252, 6425, 2516, 0],\n",
       " [6863, 4584, 1432, 3897, 1146, 2312, 934, 4808, 6862, 3742],\n",
       " [5947, 3041, 900, 3535, 4507, 882, 0, 0, 0, 0],\n",
       " [4507, 7080, 5192, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2605, 5045, 3724, 2492, 5263, 4583, 1713, 6178, 2131, 4952],\n",
       " [1735, 5148, 6170, 5410, 3387, 2461, 5840, 0, 0, 0],\n",
       " [2509, 5387, 637, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7513, 4262, 3041, 3332, 7029, 1835, 5193, 6118, 0, 0],\n",
       " [3850, 1242, 6378, 3516, 0, 0, 0, 0, 0, 0],\n",
       " [4516, 1519, 1492, 2186, 4395, 1213, 6391, 2879, 990, 446],\n",
       " [3687, 5780, 5570, 5044, 0, 0, 0, 0, 0, 0],\n",
       " [4390, 3913, 4090, 1962, 48, 506, 5323, 2221, 5219, 5910],\n",
       " [7051, 2461, 3501, 6624, 7051, 5243, 1710, 3668, 5625, 1657],\n",
       " [4307, 3630, 5481, 808, 2765, 4884, 1735, 1420, 6540, 3108],\n",
       " [4507, 3045, 2539, 2752, 6898, 3620, 2173, 4018, 0, 0],\n",
       " [3724, 7, 6771, 3708, 0, 0, 0, 0, 0, 0],\n",
       " [6393, 141, 3798, 5063, 0, 0, 0, 0, 0, 0],\n",
       " [3351, 4822, 260, 6420, 7489, 1731, 0, 0, 0, 0],\n",
       " [7171, 2662, 2461, 472, 2395, 5481, 6484, 6080, 3906, 0],\n",
       " [190, 5593, 6771, 5584, 0, 0, 0, 0, 0, 0],\n",
       " [7464, 978, 2342, 195, 367, 7290, 7110, 0, 0, 0],\n",
       " [7068, 6752, 3700, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6425, 466, 950, 7029, 6337, 5243, 6481, 0, 0, 0],\n",
       " [1037, 2136, 3263, 6524, 2098, 0, 0, 0, 0, 0],\n",
       " [7211, 5248, 5760, 3687, 6540, 0, 0, 0, 0, 0],\n",
       " [2312, 3964, 63, 2312, 6406, 3964, 5333, 3964, 7285, 2312],\n",
       " [1519, 5235, 5192, 2711, 0, 0, 0, 0, 0, 0],\n",
       " [1578, 5164, 7051, 6768, 5625, 758, 2085, 2501, 7051, 5205],\n",
       " [6484, 3221, 2167, 5616, 6405, 3964, 0, 0, 0, 0],\n",
       " [5947, 3839, 48, 1782, 7315, 7051, 1340, 6670, 472, 2690],\n",
       " [1284, 7429, 5981, 1140, 4714, 900, 4405, 886, 6242, 6918],\n",
       " [5952, 3925, 3041, 900, 3535, 0, 0, 0, 0, 0],\n",
       " [1152, 3756, 5371, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2312, 4417, 900, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2568, 3930, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4375, 6484, 2509, 4086, 5947, 5333, 3531, 0, 0, 0],\n",
       " [6597, 36, 1278, 6709, 0, 0, 0, 0, 0, 0],\n",
       " [3376, 3240, 5258, 1018, 3178, 5388, 0, 0, 0, 0],\n",
       " [1519, 5235, 5427, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2176, 7297, 1849, 6771, 1908, 7211, 3704, 827, 2177, 1167],\n",
       " [7539, 1224, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1065, 4432, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3681, 7139, 2209, 7072, 0, 0, 0, 0, 0, 0],\n",
       " [1285, 7107, 1248, 1770, 6771, 5055, 1146, 900, 456, 6354],\n",
       " [7029, 1835, 960, 1484, 733, 7067, 1187, 7029, 4628, 2568],\n",
       " [3898, 7151, 2999, 4700, 6975, 4848, 4251, 2929, 0, 0],\n",
       " [3454, 2933, 266, 798, 4090, 3221, 5558, 2144, 4733, 5326],\n",
       " [7160, 5766, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4566, 3242, 3481, 3723, 5770, 6007, 1043, 3896, 6179, 5775],\n",
       " [3537, 2635, 6106, 5573, 220, 7051, 2492, 4291, 156, 6696],\n",
       " [4981, 5956, 2765, 3045, 5946, 0, 0, 0, 0, 0],\n",
       " [3679, 4507, 2279, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4361, 1037, 6338, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2642, 3537, 4363, 4808, 2428, 3165, 4137, 4862, 5056, 6725],\n",
       " [5884, 1248, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [713, 6617, 4654, 5333, 4919, 4098, 1891, 4919, 1027, 1027],\n",
       " [1378, 6642, 2955, 5325, 4839, 6419, 0, 0, 0, 0],\n",
       " [7080, 6682, 3586, 5065, 5521, 4317, 7080, 6771, 7051, 367],\n",
       " [6906, 4779, 6809, 6430, 1105, 90, 3897, 590, 21, 3041],\n",
       " [6430, 1859, 3986, 3586, 1923, 0, 0, 0, 0, 0],\n",
       " [5670, 1224, 2461, 4823, 0, 0, 0, 0, 0, 0],\n",
       " [2539, 2509, 2461, 6303, 0, 0, 0, 0, 0, 0],\n",
       " [6430, 5453, 938, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6878, 4063, 445, 719, 906, 5055, 1, 4249, 400, 1296],\n",
       " [2821, 7275, 456, 321, 1130, 1955, 4210, 3959, 3790, 0],\n",
       " [6578, 4483, 1146, 6874, 7309, 1671, 7008, 6406, 7425, 4405],\n",
       " [7442, 5029, 3495, 3620, 5785, 0, 0, 0, 0, 0],\n",
       " [5270, 6617, 7239, 4280, 2944, 6395, 1271, 4868, 5593, 1039],\n",
       " [3261, 5540, 7489, 1752, 0, 0, 0, 0, 0, 0],\n",
       " [5053, 48, 6077, 5738, 6844, 5773, 4913, 900, 3024, 1199],\n",
       " [6585, 2881, 7290, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2649, 2509, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3041, 3531, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3221, 900, 2909, 3744, 3832, 3454, 4027, 2662, 4027, 505],\n",
       " [2541, 112, 3725, 2523, 1496, 2909, 3898, 2568, 3556, 3296],\n",
       " [5062, 2539, 5593, 3535, 6624, 3750, 0, 0, 0, 0],\n",
       " [3898, 2121, 2197, 5022, 872, 1707, 3454, 0, 0, 0],\n",
       " [6799, 3850, 3850, 2715, 5370, 1496, 1519, 6272, 2765, 2715],\n",
       " [6555, 1447, 6070, 4485, 900, 0, 0, 0, 0, 0],\n",
       " [7359, 4103, 3838, 6353, 7092, 120, 6118, 6725, 6118, 0],\n",
       " [2105, 5181, 1604, 17, 3645, 274, 6808, 7240, 3704, 6386],\n",
       " [2509, 1214, 4655, 1922, 3041, 1224, 5606, 4655, 0, 0],\n",
       " [4471, 4002, 522, 2221, 4852, 0, 0, 0, 0, 0],\n",
       " [2485, 6080, 569, 2485, 1707, 4262, 5275, 6540, 3018, 5221],\n",
       " [5981, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3454, 4262, 2461, 2924, 2568, 3156, 291, 897, 6272, 1224],\n",
       " [5947, 6632, 3687, 4532, 0, 0, 0, 0, 0, 0],\n",
       " [7029, 3756, 3996, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4507, 2492, 4018, 6484, 5593, 833, 7489, 179, 1435, 2685],\n",
       " [3048, 2186, 2461, 5786, 531, 5148, 4656, 3898, 2038, 1856],\n",
       " [2987, 3221, 7106, 3620, 6513, 1496, 0, 0, 0, 0],\n",
       " [6244, 2461, 54, 384, 6305, 2448, 2086, 1569, 683, 4459],\n",
       " [4507, 2045, 4317, 6314, 7056, 531, 1783, 1422, 3991, 7483],\n",
       " [3230, 3692, 2337, 4670, 989, 3219, 1060, 723, 4770, 6441],\n",
       " [7128, 6912, 1003, 4197, 6224, 3620, 2016, 6467, 0, 0],\n",
       " [3774, 4546, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3454, 2342, 195, 6597, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 5045, 6425, 4821, 5029, 0, 0, 0, 0, 0],\n",
       " [153, 6771, 207, 886, 1835, 4537, 1823, 28, 3931, 5333],\n",
       " [2821, 4149, 3932, 4485, 0, 0, 0, 0, 0, 0],\n",
       " [1835, 815, 6918, 4307, 0, 0, 0, 0, 0, 0],\n",
       " [2442, 3724, 4166, 514, 6063, 0, 0, 0, 0, 0],\n",
       " [2450, 6696, 1296, 3529, 7110, 1770, 5738, 5055, 2642, 900],\n",
       " [2368, 460, 4027, 195, 3454, 950, 3589, 5616, 4090, 6662],\n",
       " [3041, 900, 6771, 4147, 4332, 73, 3016, 215, 2318, 7275],\n",
       " [4559, 569, 5386, 2069, 6484, 0, 0, 0, 0, 0],\n",
       " [280, 2509, 2666, 7162, 3724, 5863, 2909, 4507, 2541, 1496],\n",
       " [3724, 3188, 1453, 3829, 5570, 4873, 2509, 5823, 373, 1623],\n",
       " [7311, 6771, 7049, 4029, 0, 0, 0, 0, 0, 0],\n",
       " [7418, 3700, 7029, 4180, 2198, 5556, 3772, 3700, 7186, 4112],\n",
       " [3454, 3488, 2524, 7139, 0, 0, 0, 0, 0, 0],\n",
       " [4563, 1744, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7029, 900, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4375, 7029, 5556, 1453, 0, 0, 0, 0, 0, 0],\n",
       " [990, 5056, 1146, 900, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 6552, 330, 7107, 7107, 7051, 3041, 0, 0, 0],\n",
       " [7539, 7029, 5556, 2198, 321, 0, 0, 0, 0, 0],\n",
       " [4063, 4434, 1146, 900, 6891, 472, 5394, 1146, 2923, 3630],\n",
       " [339, 3869, 6771, 5182, 7039, 6823, 5877, 656, 6771, 827],\n",
       " [2968, 1842, 7539, 1651, 4628, 3225, 0, 0, 0, 0],\n",
       " [4507, 280, 4262, 1037, 5481, 0, 0, 0, 0, 0],\n",
       " [6696, 1296, 5333, 4482, 3996, 6408, 4291, 6961, 4808, 900],\n",
       " [2068, 20, 3412, 7051, 3412, 4537, 1496, 0, 0, 0],\n",
       " [2933, 5564, 2909, 5738, 3293, 6390, 6314, 965, 3652, 1774],\n",
       " [6378, 6771, 2753, 7051, 6895, 2927, 5758, 6540, 0, 0],\n",
       " [1821, 6490, 3041, 5174, 7454, 2858, 2509, 3265, 7467, 4604],\n",
       " [4789, 4868, 5394, 3933, 2725, 2570, 1378, 0, 0, 0],\n",
       " [7407, 6046, 618, 7458, 6498, 0, 0, 0, 0, 0],\n",
       " [3045, 3925, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [6874, 1035, 7211, 7252, 5718, 6031, 6725, 5718, 6721, 7403],\n",
       " [5981, 5605, 5263, 4966, 446, 900, 3630, 1167, 1332, 4974],\n",
       " [5053, 48, 6077, 5738, 6844, 4913, 900, 3024, 1199, 1983],\n",
       " [6106, 2590, 5035, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3974, 6137, 1122, 2342, 3687, 7297, 6063, 2346, 4288, 1941],\n",
       " [2606, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2645, 4143, 1519, 4307, 1496, 0, 0, 0, 0, 0],\n",
       " [3059, 1432, 5640, 255, 900, 2325, 4405, 0, 0, 0],\n",
       " [1899, 6673, 4112, 4166, 7217, 4827, 5826, 7128, 0, 0],\n",
       " [3045, 2509, 873, 4180, 5018, 316, 0, 0, 0, 0],\n",
       " [3999, 669, 6724, 4469, 5201, 6118, 6279, 3088, 4470, 0],\n",
       " [6771, 5616, 2884, 2208, 4507, 3700, 3045, 5240, 7454, 0],\n",
       " [5979, 990, 7454, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2715, 1224, 4372, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3925, 3772, 3487, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6314, 965, 4210, 2461, 7128, 5935, 0, 0, 0, 0],\n",
       " [1179, 4118, 5901, 5981, 7529, 4310, 4698, 5430, 3495, 1],\n",
       " [3913, 5540, 950, 7029, 5593, 6771, 2461, 733, 790, 509],\n",
       " [4286, 3999, 4507, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2191, 3053, 2461, 1783, 5916, 7051, 1224, 2190, 0, 0],\n",
       " [1496, 3409, 4477, 2029, 6771, 3394, 1486, 3537, 4296, 5365],\n",
       " [6923, 2405, 5616, 1615, 4149, 6874, 2342, 262, 5182, 5910],\n",
       " [3850, 1578, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6578, 1021, 4307, 1000, 435, 2190, 6540, 4495, 4499, 7128],\n",
       " [900, 5481, 2836, 1122, 2391, 0, 0, 0, 0, 0],\n",
       " [2715, 6923, 1496, 3454, 1842, 2976, 2703, 561, 7231, 6506],\n",
       " [3620, 6918, 5714, 3574, 1187, 6378, 5750, 3620, 6378, 3583],\n",
       " [2102, 2715, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1224, 4210, 4822, 7539, 1224, 3054, 110, 6874, 3588, 0],\n",
       " [3589, 5888, 3589, 5888, 3417, 7091, 798, 4972, 6588, 2346],\n",
       " [1519, 2568, 3756, 1726, 2821, 2821, 0, 0, 0, 0],\n",
       " [2541, 7285, 7285, 3897, 3565, 6771, 1677, 3850, 6540, 0],\n",
       " [3829, 6244, 168, 3454, 652, 2173, 4018, 2110, 7489, 1268],\n",
       " [5947, 2568, 6481, 3897, 5125, 3535, 0, 0, 0, 0],\n",
       " [4216, 6134, 798, 837, 1783, 5915, 6430, 65, 3651, 6895],\n",
       " [2680, 2541, 2762, 3045, 4490, 4663, 3865, 6420, 0, 0],\n",
       " [3850, 3600, 6314, 2461, 1018, 6641, 4939, 0, 0, 0],\n",
       " [7513, 6490, 5182, 1835, 6360, 5481, 3829, 2078, 3692, 3689],\n",
       " [4291, 6410, 1053, 2914, 2662, 6874, 323, 4654, 2312, 5263],\n",
       " [6578, 6998, 4434, 1941, 5605, 5263, 445, 4434, 3883, 900],\n",
       " [4868, 1735, 5540, 3620, 2821, 2821, 2821, 0, 0, 0],\n",
       " [6425, 6772, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4499, 2293, 3964, 6506, 5616, 0, 0, 0, 0, 0],\n",
       " [2568, 5647, 4966, 5646, 2976, 4047, 7541, 2909, 4507, 0],\n",
       " [1519, 7007, 2876, 1146, 7107, 4482, 4741, 2509, 2956, 6721],\n",
       " [4210, 2387, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6275, 2909, 3417, 1497, 4537, 3662, 5252, 5863, 644, 0],\n",
       " [7539, 3672, 1484, 6540, 1452, 2157, 7539, 2884, 0, 0],\n",
       " [5739, 464, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [368, 6771, 5169, 2927, 262, 0, 0, 0, 0, 0],\n",
       " [7128, 3053, 1552, 4262, 5360, 6426, 3041, 3589, 3454, 3045],\n",
       " [5481, 3427, 3427, 950, 5960, 1888, 2562, 3839, 3183, 2751],\n",
       " [5062, 2539, 6281, 7104, 654, 0, 0, 0, 0, 0],\n",
       " [7407, 4307, 5240, 6526, 0, 0, 0, 0, 0, 0],\n",
       " [188, 773, 864, 6316, 6673, 6702, 3910, 7158, 885, 3313],\n",
       " [7068, 988, 3645, 4191, 226, 2035, 2509, 6387, 226, 1136],\n",
       " [3999, 367, 2711, 1735, 5540, 6807, 0, 0, 0, 0],\n",
       " [5053, 48, 6077, 5738, 6844, 4913, 900, 3024, 1199, 1983],\n",
       " [5061, 5616, 1926, 0, 0, 0, 0, 0, 0, 0],\n",
       " [990, 5056, 1146, 900, 6348, 5446, 6259, 6048, 4974, 0],\n",
       " [6430, 1314, 5918, 5846, 2451, 5929, 5431, 2720, 0, 0],\n",
       " [3045, 2539, 5540, 5947, 7315, 4380, 6070, 4674, 6540, 5947],\n",
       " [7029, 3454, 7146, 6663, 614, 2782, 1798, 0, 0, 0],\n",
       " [2191, 4027, 4166, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 2568, 4779, 6131, 0, 0, 0, 0, 0, 0],\n",
       " [6378, 1796, 1515, 2461, 3057, 0, 0, 0, 0, 0],\n",
       " [6217, 950, 1224, 1847, 5616, 3779, 5225, 1173, 950, 1224],\n",
       " [4848, 3839, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1707, 3829, 5621, 6314, 6837, 2312, 4262, 3454, 7202, 0],\n",
       " [5008, 4808, 5640, 900, 0, 0, 0, 0, 0, 0],\n",
       " [5580, 3547, 5415, 5415, 1972, 1972, 4683, 4683, 7285, 0],\n",
       " [4180, 5331, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 2509, 2884, 2208, 1453, 1224, 2157, 7539, 3535, 0],\n",
       " [3565, 1511, 6070, 5010, 4280, 0, 0, 0, 0, 0],\n",
       " [7425, 466, 6166, 4952, 3364, 6256, 0, 0, 0, 0],\n",
       " [1938, 1093, 4227, 491, 4149, 3363, 6361, 0, 0, 0],\n",
       " [979, 4018, 6106, 4262, 873, 0, 0, 0, 0, 0],\n",
       " [4733, 3752, 3504, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2541, 2039, 6736, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 5263, 4149, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2867, 2867, 633, 597, 3540, 5593, 7407, 6607, 0, 0],\n",
       " [5850, 32, 6217, 4956, 2789, 5598, 1313, 7051, 5540, 2821],\n",
       " [2461, 6874, 6052, 5396, 2312, 4405, 5333, 4149, 6617, 2583],\n",
       " [1684, 7275, 7303, 5540, 274, 271, 3620, 5481, 3529, 4317],\n",
       " [3221, 2568, 3756, 7080, 1340, 4822, 0, 0, 0, 0],\n",
       " [1735, 3462, 4655, 1783, 3991, 0, 0, 0, 0, 0],\n",
       " [3899, 5540, 2821, 2190, 2568, 961, 2605, 2009, 7153, 0],\n",
       " [4833, 5182, 6771, 444, 614, 6875, 6106, 5826, 3045, 2509],\n",
       " [1003, 3045, 2310, 3679, 0, 0, 0, 0, 0, 0],\n",
       " [4027, 900, 1003, 7435, 5568, 4027, 6771, 950, 7029, 6771],\n",
       " [4848, 6322, 1987, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7539, 3671, 7067, 5578, 0, 0, 0, 0, 0, 0],\n",
       " [2509, 1835, 3772, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 3045, 6200, 7429, 4526, 7290, 3520, 3724, 5579, 6406],\n",
       " [7051, 367, 7539, 7029, 2198, 3566, 1187, 3566, 2198, 2927],\n",
       " [2198, 7290, 7454, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2045, 3420, 1384, 464, 2045, 2605, 846, 3854, 3066, 6771],\n",
       " [1524, 1082, 989, 6771, 5182, 1224, 1194, 4847, 900, 627],\n",
       " [6425, 3724, 6648, 711, 0, 0, 0, 0, 0, 0],\n",
       " [2293, 4868, 900, 3054, 6877, 3964, 7029, 0, 0, 0],\n",
       " [2112, 4563, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 6704, 6771, 873, 1452, 633, 5852, 5521, 4210, 6217],\n",
       " [5793, 3545, 2909, 2605, 4101, 5540, 2813, 18, 0, 0],\n",
       " [5138, 6170, 6578, 3821, 4896, 701, 4434, 0, 0, 0],\n",
       " [130, 4935, 3692, 3620, 3041, 5061, 5616, 3521, 2461, 2167],\n",
       " [2541, 2541, 3296, 3620, 1967, 0, 0, 0, 0, 0],\n",
       " [145, 1167, 6106, 341, 168, 4848, 0, 0, 0, 0],\n",
       " [3925, 1323, 6052, 4628, 2412, 7542, 5593, 3999, 7294, 0],\n",
       " [4180, 367, 7539, 873, 2261, 2884, 0, 0, 0, 0],\n",
       " [3478, 201, 1735, 4149, 5333, 4149, 0, 0, 0, 0],\n",
       " [4166, 5182, 7539, 7207, 4733, 0, 0, 0, 0, 0],\n",
       " [5947, 3041, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [3059, 5030, 1556, 2492, 1961, 2242, 0, 0, 0, 0],\n",
       " [6430, 654, 7121, 2038, 6240, 2711, 2541, 3021, 6244, 5126],\n",
       " [6709, 1521, 5521, 4995, 2038, 2153, 5958, 5871, 6540, 0],\n",
       " [1735, 6484, 2461, 447, 6694, 3687, 2102, 6663, 5947, 0],\n",
       " [7049, 2666, 2729, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5174, 3531, 3522, 321, 280, 7356, 456, 1789, 0, 0],\n",
       " [5374, 3387, 2109, 4363, 4302, 2405, 1539, 1175, 4363, 2509],\n",
       " [4163, 2690, 5036, 4584, 3630, 5327, 3537, 934, 4808, 2312],\n",
       " [2778, 1276, 97, 5080, 7141, 904, 226, 7141, 368, 5794],\n",
       " [5598, 3620, 7121, 6540, 4317, 2395, 7051, 1224, 5868, 1496],\n",
       " [228, 1332, 4654, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5537, 6142, 4779, 1745, 48, 5616, 48, 1598, 4090, 5625],\n",
       " [201, 3454, 3772, 3952, 1447, 3454, 0, 0, 0, 0],\n",
       " [6170, 5610, 3041, 6378, 0, 0, 0, 0, 0, 0],\n",
       " [6878, 4249, 400, 1296, 6773, 900, 456, 6351, 902, 4974],\n",
       " [723, 3588, 4149, 900, 7290, 6100, 3045, 2509, 2461, 5980],\n",
       " [2642, 990, 5055, 1146, 7504, 5055, 900, 1432, 5640, 5337],\n",
       " [3796, 1735, 2146, 6868, 380, 4001, 4537, 2038, 7274, 4852],\n",
       " [4499, 5616, 73, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5655, 279, 611, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7272, 2376, 2230, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7407, 2038, 1312, 3273, 0, 0, 0, 0, 0, 0],\n",
       " [7297, 5462, 6107, 2146, 5500, 3208, 83, 3810, 1327, 3589],\n",
       " [2568, 3188, 3692, 5574, 1453, 7051, 1856, 4317, 3688, 0],\n",
       " [1187, 3522, 3045, 457, 1471, 4507, 4885, 3700, 6771, 4288],\n",
       " [197, 4532, 2574, 1037, 4588, 2691, 0, 0, 0, 0],\n",
       " [1839, 280, 2110, 3291, 6166, 6986, 0, 0, 0, 0],\n",
       " [1823, 6771, 367, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1926, 171, 3278, 6098, 3382, 3739, 5015, 1804, 3645, 1926],\n",
       " [1627, 6032, 1224, 1842, 7422, 0, 0, 0, 0, 0],\n",
       " [3679, 7275, 2146, 477, 6895, 4090, 6314, 6085, 1651, 0],\n",
       " [2038, 6771, 1735, 2461, 6704, 1310, 6375, 6759, 6375, 4271],\n",
       " [3565, 5156, 6626, 5581, 4570, 7139, 2120, 69, 6874, 4997],\n",
       " [4537, 6322, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6425, 3692, 5248, 304, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 1432, 3742, 4484, 4291, 4363, 4063, 6727, 6725, 7285],\n",
       " [7231, 4405, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2680, 3898, 6875, 5406, 6771, 3454, 7128, 1447, 2146, 3620],\n",
       " [7425, 2495, 3806, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7128, 3651, 6540, 6481, 2541, 6540, 132, 0, 0, 0],\n",
       " [2568, 5427, 5935, 7542, 2677, 5148, 1166, 472, 6537, 5736],\n",
       " [4507, 3897, 2312, 2666, 0, 0, 0, 0, 0, 0],\n",
       " [3946, 3620, 5729, 3495, 2427, 2071, 0, 0, 0, 0],\n",
       " [1823, 3332, 5540, 2509, 3601, 6540, 0, 0, 0, 0],\n",
       " [5089, 6314, 2541, 965, 5044, 5462, 4868, 5616, 4821, 2461],\n",
       " [6771, 6187, 611, 4063, 1298, 5640, 6789, 4762, 1496, 5616],\n",
       " [5252, 7154, 6018, 7429, 280, 2605, 7107, 611, 1840, 0],\n",
       " [4086, 4280, 7107, 2492, 2376, 2490, 0, 0, 0, 0],\n",
       " [5247, 7429, 7128, 6509, 4526, 3495, 5462, 341, 6340, 0],\n",
       " [3059, 1432, 5640, 255, 5007, 0, 0, 0, 0, 0],\n",
       " [1735, 2482, 3641, 1005, 0, 0, 0, 0, 0, 0],\n",
       " [2461, 3599, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5244, 5951, 1735, 5272, 4434, 1282, 5182, 6771, 4870, 0],\n",
       " [1627, 2882, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [950, 6484, 272, 5975, 5427, 6642, 2752, 0, 0, 0],\n",
       " [2092, 3829, 6481, 4955, 3829, 6481, 7295, 3829, 6481, 562],\n",
       " [6771, 3806, 303, 0, 0, 0, 0, 0, 0, 0],\n",
       " [900, 7474, 3176, 4808, 6956, 60, 3986, 2762, 6406, 0],\n",
       " [5423, 4697, 4317, 2228, 723, 4280, 7429, 900, 6721, 301],\n",
       " [2592, 4499, 1519, 6771, 6106, 3041, 2153, 5705, 4112, 6484],\n",
       " [6877, 6874, 2642, 445, 6106, 6806, 900, 1171, 1147, 4048],\n",
       " [4390, 3332, 6655, 6771, 7315, 367, 1187, 6771, 457, 2640],\n",
       " [7231, 2102, 3959, 3790, 2715, 4291, 7429, 91, 0, 0],\n",
       " [6874, 445, 1141, 779, 1340, 7211, 6213, 5718, 6031, 2045],\n",
       " [3045, 4424, 2526, 2568, 5916, 6837, 3927, 1651, 3700, 2680],\n",
       " [5947, 3041, 900, 3535, 0, 0, 0, 0, 0, 0],\n",
       " [950, 4822, 4808, 5388, 4847, 5616, 3964, 0, 0, 0],\n",
       " [3679, 3455, 6475, 1768, 5558, 195, 1167, 6611, 293, 950],\n",
       " [2461, 281, 1462, 3296, 2986, 2799, 0, 0, 0, 0],\n",
       " [3680, 6771, 1802, 2685, 4084, 7426, 6106, 6624, 7067, 4852],\n",
       " [3019, 2461, 7090, 7080, 5705, 6759, 5435, 0, 0, 0],\n",
       " [7203, 3756, 4018, 2568, 5969, 0, 0, 0, 0, 0],\n",
       " [5830, 6246, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6425, 4822, 6683, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1735, 2509, 6378, 2342, 7489, 6244, 7051, 3652, 5868, 4166],\n",
       " [2821, 3376, 3724, 5593, 6624, 3041, 4808, 6611, 2568, 5783],\n",
       " [2715, 4291, 7429, 1519, 812, 5248, 4027, 2568, 4434, 1536],\n",
       " [3910, 2461, 1744, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4566, 3242, 3481, 3723, 5770, 6007, 1043, 3896, 6179, 5775],\n",
       " [2858, 6506, 5481, 2927, 5824, 3531, 5134, 0, 0, 0],\n",
       " [580, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3059, 1432, 5640, 255, 5007, 900, 2325, 4405, 0, 0],\n",
       " [1735, 6484, 6750, 3620, 5213, 7239, 3996, 4563, 0, 0],\n",
       " [6240, 1342, 3829, 5684, 6106, 6663, 6504, 0, 0, 0],\n",
       " [6540, 2167, 5991, 5918, 2461, 1254, 1635, 7285, 2509, 2178],\n",
       " [2042, 6506, 3652, 2541, 3603, 4766, 4710, 6725, 472, 4223],\n",
       " [2312, 6642, 4927, 6617, 900, 4237, 5219, 2461, 6646, 6747],\n",
       " [2645, 4143, 1519, 2738, 4307, 1496, 0, 0, 0, 0],\n",
       " [2909, 1955, 2405, 7452, 5947, 3221, 6658, 4847, 3454, 2258],\n",
       " [1835, 611, 6874, 1786, 6568, 0, 0, 0, 0, 0],\n",
       " [7515, 6771, 1711, 5960, 3620, 3252, 886, 6439, 160, 0],\n",
       " [4531, 7051, 5570, 7116, 3707, 7118, 7279, 0, 0, 0],\n",
       " [2448, 3183, 4537, 6811, 4402, 6771, 1625, 4829, 5342, 0],\n",
       " [5248, 2461, 2704, 341, 0, 0, 0, 0, 0, 0],\n",
       " [4584, 1432, 3897, 1146, 2312, 934, 4808, 6862, 3742, 900],\n",
       " [4792, 758, 7174, 2345, 6448, 1224, 946, 4306, 0, 0],\n",
       " [4507, 4149, 6771, 456, 3565, 2929, 0, 0, 0, 0],\n",
       " [2482, 3756, 4018, 126, 0, 0, 0, 0, 0, 0],\n",
       " [3529, 1036, 1146, 6874, 7309, 1671, 7007, 6579, 6406, 5718],\n",
       " [309, 3758, 2127, 6771, 1735, 3645, 6597, 6771, 6759, 0],\n",
       " [2312, 6052, 7108, 4363, 6617, 6874, 4063, 2045, 7107, 6725],\n",
       " [2642, 445, 2038, 995, 1146, 6874, 445, 900, 2312, 6118],\n",
       " [3351, 3041, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1692, 3056, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6244, 3829, 6244, 3454, 146, 5869, 7454, 0, 0, 0],\n",
       " [727, 207, 7290, 5174, 0, 0, 0, 0, 0, 0],\n",
       " [6314, 2690, 1496, 3565, 563, 7128, 0, 0, 0, 0],\n",
       " [6780, 1735, 7049, 2461, 569, 7056, 0, 0, 0, 0],\n",
       " [6051, 3756, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6461, 5394, 1224, 2662, 1336, 2478, 2391, 7502, 2837, 2837],\n",
       " [1285, 6874, 445, 1908, 1010, 2478, 7007, 2312, 1968, 7112],\n",
       " [740, 6874, 482, 4507, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 4618, 5774, 5699, 1830, 4883, 632, 6986, 5850, 59],\n",
       " [7173, 762, 4027, 2711, 0, 0, 0, 0, 0, 0],\n",
       " [3708, 6895, 4537, 460, 4074, 1707, 2790, 7480, 798, 2781],\n",
       " [201, 798, 2401, 1698, 0, 0, 0, 0, 0, 0],\n",
       " [5355, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [721, 461, 6771, 1957, 7491, 6771, 5598, 456, 2469, 7128],\n",
       " [2541, 112, 6069, 2933, 762, 1369, 7454, 50, 2368, 5787],\n",
       " [5410, 950, 6725, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5873, 7490, 6406, 1378, 4847, 2573, 7370, 3672, 5162, 6851],\n",
       " [4654, 173, 4106, 1105, 4262, 5930, 6874, 4059, 6378, 6874],\n",
       " [2541, 2039, 6736, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2856, 654, 4829, 3679, 5762, 0, 0, 0, 0, 0],\n",
       " [2681, 767, 1519, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2813, 2568, 3821, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 3615, 6750, 2612, 3913, 260, 2342, 7051, 3756, 7309],\n",
       " [6425, 7452, 5789, 7274, 2909, 1955, 859, 4080, 0, 0],\n",
       " [6771, 5587, 80, 5372, 6484, 6771, 5182, 5981, 900, 4574],\n",
       " [2821, 3884, 5466, 6771, 2738, 4307, 2873, 3964, 5540, 2783],\n",
       " [1519, 7007, 2876, 1146, 7107, 4482, 4741, 4868, 2509, 2956],\n",
       " [6425, 4166, 5819, 7236, 3485, 6243, 1627, 2461, 4872, 1242],\n",
       " [6244, 5365, 4482, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2541, 4112, 1519, 2605, 226, 6194, 1496, 0, 0, 0],\n",
       " [7051, 279, 4285, 3996, 6406, 4291, 6961, 4808, 2214, 4966],\n",
       " [5789, 3531, 4733, 5326, 4721, 4101, 4733, 3756, 1044, 2153],\n",
       " [6696, 1296, 4482, 4291, 6961, 4808, 279, 4285, 3996, 2690],\n",
       " [3529, 1035, 1146, 6874, 7309, 1671, 7009, 7425, 4408, 4482],\n",
       " [3779, 6771, 5934, 4166, 6771, 1741, 6814, 5981, 6771, 5182],\n",
       " [4847, 5616, 1258, 3821, 3045, 4733, 4166, 0, 0, 0],\n",
       " [4994, 4124, 4714, 447, 3529, 4317, 4995, 2102, 0, 0],\n",
       " [6878, 900, 3510, 1256, 3006, 2879, 990, 443, 1213, 5475],\n",
       " [3444, 2509, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3914, 5705, 6208, 439, 1536, 2492, 6891, 3756, 5585, 7057],\n",
       " [6113, 6520, 4166, 6684, 6269, 950, 1856, 618, 3704, 7117],\n",
       " [4489, 3894, 4418, 900, 779, 0, 0, 0, 0, 0],\n",
       " [7426, 6461, 514, 1961, 5427, 6765, 6891, 3850, 2368, 5715],\n",
       " [6578, 4483, 1146, 6874, 7309, 1671, 7008, 6406, 7425, 4405],\n",
       " [6771, 5235, 4587, 195, 6771, 7047, 2509, 873, 6529, 2208],\n",
       " [5243, 466, 7051, 798, 3115, 6534, 0, 0, 0, 0],\n",
       " [1447, 5462, 63, 2376, 6950, 1447, 0, 0, 0, 0],\n",
       " [130, 4936, 467, 6876, 619, 3780, 5071, 4637, 7290, 2813],\n",
       " [6118, 6131, 3221, 6597, 3221, 5370, 2750, 5540, 4588, 0],\n",
       " [6322, 5651, 3829, 4291, 2342, 2099, 3724, 7297, 1672, 6406],\n",
       " [2509, 6314, 460, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2683, 234, 6604, 1224, 4112, 3752, 3041, 5523, 2509, 5449],\n",
       " [6022, 4509, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5540, 5908, 4223, 6329, 0, 0, 0, 0, 0, 0],\n",
       " [7290, 2509, 3996, 0, 0, 0, 0, 0, 0, 0],\n",
       " [812, 2449, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 2651, 7169, 2461, 2875, 1287, 3898, 2927, 6765, 3041],\n",
       " [6771, 2190, 6540, 835, 1357, 4262, 5953, 6170, 0, 0],\n",
       " [1813, 3221, 5593, 3713, 1330, 3531, 0, 0, 0, 0],\n",
       " [1285, 6874, 445, 1908, 7504, 6235, 1010, 6982, 5273, 4208],\n",
       " [1291, 7040, 854, 5705, 3059, 4288, 4860, 4745, 2651, 4848],\n",
       " [5053, 48, 6077, 5738, 6844, 4913, 900, 3024, 1199, 1983],\n",
       " [2783, 4262, 4950, 646, 1040, 6897, 6697, 5076, 1034, 5148],\n",
       " [6771, 7051, 3790, 2312, 6406, 3964, 4291, 6961, 4808, 2690],\n",
       " [7128, 4490, 4804, 2877, 6771, 7049, 900, 2884, 5240, 5538],\n",
       " [2509, 2555, 5066, 6106, 4262, 3651, 1979, 6814, 215, 1432],\n",
       " [3041, 6406, 1793, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6780, 3687, 1496, 3045, 1899, 7051, 1415, 6314, 4229, 0],\n",
       " [6322, 395, 1498, 4608, 4027, 611, 2342, 7298, 5669, 5692],\n",
       " [5718, 6538, 6771, 1793, 1908, 3351, 3351, 990, 6686, 7007],\n",
       " [997, 4262, 5593, 5915, 0, 0, 0, 0, 0, 0],\n",
       " [6225, 5176, 7252, 5155, 7211, 6642, 5931, 1830, 4862, 6771],\n",
       " [6771, 5587, 80, 3692, 3829, 1296, 6778, 5443, 6484, 6874],\n",
       " [6771, 5587, 80, 3692, 3829, 1296, 6778, 5443, 6484, 6874],\n",
       " [5322, 1759, 1298, 195, 4663, 2573, 2950, 4205, 6752, 1213],\n",
       " [5593, 3451, 2492, 779, 6540, 7314, 3556, 207, 7051, 4027],\n",
       " [3724, 2492, 3877, 6895, 3708, 464, 4505, 2131, 4952, 0],\n",
       " [1813, 2509, 6228, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7503, 6771, 3454, 1037, 4775, 1786, 3794, 6892, 2220, 1786],\n",
       " [2476, 6847, 2991, 0, 0, 0, 0, 0, 0, 0],\n",
       " [3620, 6322, 4655, 20, 1735, 3454, 0, 0, 0, 0],\n",
       " [1821, 1435, 5726, 3574, 6771, 1821, 3620, 130, 2088, 5684],\n",
       " [6803, 2087, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7199, 3451, 6540, 4188, 1839, 0, 0, 0, 0, 0],\n",
       " [367, 5044, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2605, 5045, 6484, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4444, 1440, 1410, 1411, 1409, 1406, 1405, 3029, 0, 0],\n",
       " [4507, 4353, 6875, 866, 3045, 5248, 733, 4149, 6771, 4604],\n",
       " [1707, 2395, 1152, 1842, 6611, 6523, 5734, 6696, 5868, 3756],\n",
       " [6230, 6506, 2597, 6771, 1735, 2051, 6771, 7051, 3910, 6771],\n",
       " [2909, 2541, 7107, 1065, 0, 0, 0, 0, 0, 0],\n",
       " [3045, 6895, 2909, 122, 1735, 1793, 5780, 3221, 723, 6481],\n",
       " [6526, 4317, 7426, 6244, 6481, 7128, 7290, 0, 0, 0],\n",
       " [2312, 5396, 7029, 1213, 5777, 6406, 4719, 3980, 6949, 2461],\n",
       " [5062, 4090, 7303, 6481, 1224, 1816, 5648, 4630, 3158, 7290],\n",
       " [4954, 6359, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7274, 4808, 535, 7139, 1512, 6378, 3724, 460, 0, 0],\n",
       " [3724, 5860, 835, 146, 6574, 0, 0, 0, 0, 0],\n",
       " [2461, 7303, 1583, 6344, 195, 380, 7308, 0, 0, 0],\n",
       " [2813, 7160, 1047, 5947, 3531, 5333, 0, 0, 0, 0],\n",
       " [3530, 6093, 3866, 1690, 5184, 3598, 6151, 7211, 4371, 2405],\n",
       " [3041, 2492, 4878, 5481, 2619, 2614, 7169, 5979, 0, 0],\n",
       " [7183, 2371, 4591, 6129, 0, 0, 0, 0, 0, 0],\n",
       " [3256, 3834, 5489, 2923, 2423, 1053, 1062, 900, 4237, 5219],\n",
       " [3724, 1, 1224, 6632, 3687, 3565, 7518, 2568, 7285, 7462],\n",
       " [5947, 2989, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [950, 2146, 4244, 3045, 4844, 1627, 1856, 6272, 7107, 1003],\n",
       " [4507, 3700, 1842, 6106, 5085, 3925, 0, 0, 0, 0],\n",
       " [900, 1447, 7029, 900, 0, 0, 0, 0, 0, 0],\n",
       " [1340, 367, 978, 1340, 2461, 269, 1922, 1116, 0, 0],\n",
       " [65, 5616, 5322, 6578, 7274, 7110, 0, 0, 0, 0],\n",
       " [4760, 5593, 4149, 6484, 3003, 72, 4150, 7339, 552, 1735],\n",
       " [2813, 2422, 4813, 5299, 1786, 130, 6568, 7049, 3925, 7423],\n",
       " [1735, 6322, 2042, 4507, 7285, 0, 0, 0, 0, 0],\n",
       " [6771, 7048, 5593, 0, 0, 0, 0, 0, 0, 0],\n",
       " [7080, 5558, 4847, 5616, 363, 4434, 0, 0, 0, 0],\n",
       " [5670, 2191, 432, 2883, 0, 0, 0, 0, 0, 0],\n",
       " [7139, 402, 260, 6765, 5432, 6581, 6106, 1631, 5235, 2884],\n",
       " [65, 1559, 4526, 7098, 679, 3816, 0, 0, 0, 0],\n",
       " [3351, 7029, 1098, 5616, 114, 3756, 3996, 0, 0, 0],\n",
       " [3045, 1634, 390, 3850, 5835, 4846, 7452, 6780, 3045, 207],\n",
       " [3407, 2492, 3482, 34, 1598, 0, 0, 0, 0, 0],\n",
       " [4499, 1224, 130, 0, 0, 0, 0, 0, 0, 0],\n",
       " [4091, 5182, 3766, 7219, 1, 1146, 5055, 6406, 4090, 3994],\n",
       " [3045, 5248, 5947, 7275, 456, 20, 2340, 6771, 2190, 204],\n",
       " [1285, 4589, 4057, 4649, 7018, 1955, 7231, 3850, 2715, 4084],\n",
       " [5501, 5733, 7454, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6540, 6484, 7483, 4262, 3454, 4251, 938, 0, 0, 0],\n",
       " [1519, 3895, 4868, 900, 3510, 1256, 3761, 6391, 2879, 990],\n",
       " [1821, 7089, 3270, 3700, 0, 0, 0, 0, 0, 0],\n",
       " [5780, 5760, 2158, 7005, 0, 0, 0, 0, 0, 0],\n",
       " [3435, 1214, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6878, 900, 3510, 1256, 6391, 2879, 990, 443, 1213, 5475],\n",
       " [618, 3806, 2339, 6169, 3620, 4832, 7452, 2146, 671, 3562],\n",
       " [5610, 7128, 6616, 1203, 5610, 1203, 5910, 6520, 4740, 7002],\n",
       " [6475, 3708, 4848, 2919, 3921, 4848, 5477, 0, 0, 0],\n",
       " [2461, 6658, 2254, 7029, 1242, 6725, 472, 4223, 120, 4574],\n",
       " [201, 3221, 5954, 690, 1348, 6540, 5265, 3018, 5221, 6406],\n",
       " [5625, 5562, 5943, 5586, 302, 5558, 6484, 6484, 301, 5342],\n",
       " [950, 7029, 5593, 7471, 4813, 6895, 0, 0, 0, 0],\n",
       " [6874, 992, 1427, 4966, 3824, 6874, 994, 5616, 2509, 4889],\n",
       " [2813, 723, 3381, 5521, 195, 3588, 2509, 130, 3387, 5521],\n",
       " [1118, 6874, 601, 4148, 1624, 0, 0, 0, 0, 0],\n",
       " [6540, 7051, 1224, 0, 0, 0, 0, 0, 0, 0],\n",
       " [449, 3578, 3454, 7169, 7489, 341, 0, 0, 0, 0],\n",
       " [5682, 456, 4507, 3700, 0, 0, 0, 0, 0, 0],\n",
       " [561, 6715, 2601, 5238, 965, 2765, 2146, 3615, 5910, 2146],\n",
       " [201, 5318, 2461, 1698, 756, 960, 0, 0, 0, 0],\n",
       " [2184, 6131, 2485, 7029, 0, 0, 0, 0, 0, 0],\n",
       " [5947, 886, 6874, 4149, 7418, 3700, 4936, 6481, 4537, 4317],\n",
       " [3724, 3183, 1538, 2146, 1340, 1536, 3724, 3603, 7315, 4166],\n",
       " [7135, 293, 5368, 0, 0, 0, 0, 0, 0, 0],\n",
       " [5953, 1199, 34, 506, 4242, 5333, 1278, 3221, 5625, 5388],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [6771, 6244, 6771, 950, 6314, 5758, 6540, 0, 0, 0],\n",
       " [6878, 6696, 1296, 6771, 6578, 1770, 5738, 5055, 2642, 900],\n",
       " [7068, 988, 3645, 4191, 226, 2035, 2509, 6387, 226, 1136],\n",
       " [7464, 1029, 2668, 1152, 7049, 6314, 5795, 5540, 1129, 1152],\n",
       " [4166, 876, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [618, 6106, 1000, 3589, 367, 5610, 3756, 0, 0, 0],\n",
       " [6244, 4317, 3952, 3454, 4372, 3952, 0, 0, 0, 0],\n",
       " [6771, 7051, 1224, 474, 561, 4260, 6595, 2765, 7494, 2492],\n",
       " [7207, 2509, 314, 1152, 0, 0, 0, 0, 0, 0],\n",
       " [7275, 456, 6696, 5953, 2929, 4507, 0, 0, 0, 0],\n",
       " [7418, 3700, 7047, 2509, 886, 2918, 5185, 6578, 3817, 1856],\n",
       " [2680, 449, 4532, 472, 0, 0, 0, 0, 0, 0],\n",
       " [7513, 6490, 1835, 5718, 1167, 3700, 0, 0, 0, 0],\n",
       " [48, 4434, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1898, 6771, 5616, 7342, 3522, 0, 0, 0, 0, 0],\n",
       " [2813, 67, 1367, 4337, 735, 7240, 7407, 709, 6771, 733],\n",
       " [4507, 5670, 6322, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1735, 2812, 3454, 5585, 6540, 7087, 3620, 3387, 4389, 1856],\n",
       " [2813, 4733, 5487, 1511, 3756, 0, 0, 0, 0, 0],\n",
       " [260, 4101, 4262, 1120, 7105, 166, 0, 0, 0, 0],\n",
       " [6070, 5581, 2461, 3296, 1503, 2605, 4963, 6319, 0, 0],\n",
       " [5271, 4262, 6663, 1904, 7037, 983, 0, 0, 0, 0],\n",
       " [1284, 4063, 2395, 6964, 5182, 900, 4405, 6962, 7194, 3884],\n",
       " [3692, 2369, 6540, 2368, 6484, 0, 0, 0, 0, 0],\n",
       " [7464, 2651, 1793, 0, 0, 0, 0, 0, 0, 0],\n",
       " [978, 5540, 2781, 4165, 3756, 4018, 0, 0, 0, 0],\n",
       " [3045, 4485, 900, 3756, 3996, 0, 0, 0, 0, 0],\n",
       " [2441, 4027, 195, 3454, 6484, 2368, 950, 7029, 6538, 4280],\n",
       " [7509, 140, 6776, 4537, 5540, 7539, 7047, 900, 6613, 3692],\n",
       " [6780, 2574, 1786, 472, 5576, 3487, 870, 5944, 0, 0],\n",
       " [6420, 3337, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [2821, 3045, 5305, 6540, 2043, 2461, 2045, 1497, 4706, 2541],\n",
       " [7539, 7539, 7047, 1224, 1224, 3700, 1647, 886, 6150, 5816],\n",
       " [3790, 6131, 4745, 3790, 4149, 3724, 3790, 4020, 3283, 2738],\n",
       " [950, 1735, 4435, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1037, 1835, 4537, 4280, 2008, 0, 0, 0, 0, 0],\n",
       " [7456, 3045, 1152, 5462, 7072, 3829, 4507, 4847, 0, 0],\n",
       " [3708, 2711, 2146, 5173, 616, 417, 1048, 7290, 3708, 2780],\n",
       " [7539, 7029, 835, 6118, 110, 6874, 3566, 3522, 1821, 886],\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(sms['label']=='ham', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split in batch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "xarray = np.array(padded_sentence)\n",
    "yarray = np.array(y)\n",
    "\n",
    "ix_train = int(xarray.shape[0]*0.7)\n",
    "ix_valid = int(xarray.shape[0]*0.85)\n",
    "\n",
    "X_train = torch.tensor(xarray[:ix_train], dtype = torch.long)\n",
    "Y_train = torch.tensor(yarray[:ix_train], dtype = torch.long)\n",
    "\n",
    "X_valid = torch.tensor(xarray[ix_train:ix_valid], dtype = torch.long)\n",
    "Y_valid = torch.tensor(yarray[ix_train:ix_valid], dtype = torch.long)\n",
    "\n",
    "X_test = torch.tensor(xarray[ix_valid:], dtype = torch.long)\n",
    "Y_test = torch.tensor(yarray[ix_valid:], dtype = torch.long)\n",
    "\n",
    "Batch=60\n",
    "train = TensorDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train, batch_size = Batch, shuffle = True, drop_last=True)\n",
    "\n",
    "valid = TensorDataset(X_valid, Y_valid)\n",
    "valid_loader = DataLoader(valid, batch_size = Batch, shuffle = False, drop_last=True)\n",
    "\n",
    "test = TensorDataset(X_test, Y_test)\n",
    "test_loader = DataLoader(test, batch_size = Batch, shuffle = False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model class\n",
    "\n",
    "class RNNSpam(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embedding, emed_dim, batch, seq_len, inp_sz, rnn_hid_sz, nlayer, fc_in1,fc_out2):\n",
    "        super(RNNSpam, self).__init__()\n",
    "        \n",
    "        self.num_embedding = num_embedding\n",
    "        self.emed_dim = emed_dim\n",
    "        self.batch = batch\n",
    "        self.seq_len = seq_len\n",
    "        self.inp_sz = inp_sz\n",
    "        self.rnn_hid_sz = rnn_hid_sz\n",
    "        self.nlayer = nlayer\n",
    "        self.fc_in1 = fc_in1\n",
    "        self.fc_out = fc_out2\n",
    "        self.embed = nn.Embedding(self.num_embedding, self.emed_dim)\n",
    "        self.rnn = nn.RNN(self.inp_sz,self.rnn_hid_sz,self.nlayer)\n",
    "        self.fc1 = nn.Linear(self.fc_in1, self.fc_out)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = x.view(self.seq_len, self.batch, self.inp_sz)\n",
    "        hidden = torch.randn(self.nlayer, self.batch, self.rnn_hid_sz)\n",
    "        x, hidden = self.rnn(x, hidden)\n",
    "        x = x.view(self.batch, self.fc_in1)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = self.softmax(x)\n",
    "        return (x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7549"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "num_embedding = len(vocab)\n",
    "embed_dim = 50\n",
    "batch = Batch\n",
    "seq_len = xarray.shape[1]\n",
    "inp_sz = embed_dim\n",
    "rnn_hid_sz = 100\n",
    "nlayer = 1\n",
    "fc_in1 = rnn_hid_sz*seq_len\n",
    "out_sz = 2\n",
    "fc_out2 = out_sz\n",
    "\n",
    "model = RNNSpam(num_embedding, embed_dim, batch, seq_len, inp_sz, rnn_hid_sz, nlayer, fc_in1,fc_out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNSpam(\n",
      "  (embed): Embedding(7549, 50)\n",
      "  (rnn): RNN(50, 100)\n",
      "  (fc1): Linear(in_features=1000, out_features=2, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestAccuracy(pred, yt):\n",
    "    \n",
    "    pred_ix = pred.argmax(dim = 1)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc = accuracy_score(yt.numpy(), pred_ix.numpy())\n",
    "    return (np.round(acc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ValidationAnalysis(xtest, ytest):\n",
    "    valid_actual = []\n",
    "    valid_predict = []\n",
    "    avg_valid_loss = []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for xv, yv in valid_loader:\n",
    "            yp = model(xv)\n",
    "            pred_ix = yp.argmax(dim = 1)\n",
    "            valid_loss = criterion(yp, yv)\n",
    "            avg_valid_loss.append(valid_loss)\n",
    "            valid_predict.append(pred_ix.numpy())\n",
    "            valid_actual.append(yv.numpy())\n",
    "                     \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc = accuracy_score(np.array(valid_actual).reshape(-1,1), np.array(valid_predict).reshape(-1,1)) \n",
    "    return (yp, np.array(valid_predict).reshape(-1,1), np.array(valid_actual).reshape(-1,1), np.round(acc, 3), np.round(np.mean(avg_valid_loss),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EachAccuracyClass(yt, pt):\n",
    "    cls, ncls = np.unique(yt, return_counts = True)\n",
    "    acc = pd.DataFrame()\n",
    "    acc['ytest'] = yt.squeeze()\n",
    "    acc['pred'] = pt.squeeze()\n",
    "    class_acc = {}\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    for c in cls:\n",
    "        sig = acc.loc[acc.loc[acc['ytest']==c].index]\n",
    "        class_acc[str(c)] = round(accuracy_score(sig['ytest'], sig['pred'])*100, 2)\n",
    "    return (class_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Epoch: 0 |Train Loss: 0.6779999732971191 | Train Accuracy: 0.633 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 |Train Loss: 0.5130000114440918 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5009999871253967 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.47999998927116394 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4819999933242798 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4740000069141388 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5120000243186951 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.49399998784065247 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5680000185966492 | Train Accuracy: 0.75 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.5170000195503235 | Train Accuracy: 0.817 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.47999998927116394 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5040000081062317 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.5139999985694885 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.515999972820282 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.43299999833106995 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4950000047683716 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.46000000834465027 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4690000116825104 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.5049999952316284 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.49900001287460327 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5609999895095825 | Train Accuracy: 0.767 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4569999873638153 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5199999809265137 | Train Accuracy: 0.817 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.48399999737739563 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4580000042915344 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4490000009536743 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.46299999952316284 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4869999885559082 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4830000102519989 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5400000214576721 | Train Accuracy: 0.8 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.550000011920929 | Train Accuracy: 0.783 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.48399999737739563 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.5230000019073486 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5580000281333923 | Train Accuracy: 0.767 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.5360000133514404 | Train Accuracy: 0.8 | Train-Class: [1] \n",
      "Epoch: 0 |Train Loss: 0.44200000166893005 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.5090000033378601 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 0 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 0 |Valid Loss: 0.4950000047683716 | Valid Accuracy: 0.853 | Valid-Class: [1] \n",
      "==================================================================================\n",
      "Epoch: 1 |Train Loss: 0.4959999918937683 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.4729999899864197 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5059999823570251 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.48100000619888306 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.43700000643730164 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5440000295639038 | Train Accuracy: 0.783 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5230000019073486 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.4490000009536743 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5130000114440918 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.46000000834465027 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5230000019073486 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.4749999940395355 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5350000262260437 | Train Accuracy: 0.8 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5120000243186951 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5230000019073486 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.4830000102519989 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5230000019073486 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.46000000834465027 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.47600001096725464 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5220000147819519 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5479999780654907 | Train Accuracy: 0.783 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.49300000071525574 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.4480000138282776 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.5230000019073486 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.5339999794960022 | Train Accuracy: 0.8 | Train-Class: [0 1] \n",
      "Epoch: 1 |Train Loss: 0.5479999780654907 | Train Accuracy: 0.783 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 1 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "==================================================================================\n",
      "Epoch: 1 |Valid Loss: 0.49300000071525574 | Valid Accuracy: 0.855 | Valid-Class: [1] \n",
      "==================================================================================\n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.5350000262260437 | Train Accuracy: 0.8 | Train-Class: [1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.5230000019073486 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.5230000019073486 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.5230000019073486 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.5479999780654907 | Train Accuracy: 0.783 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.5550000071525574 | Train Accuracy: 0.767 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.5230000019073486 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.4519999921321869 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.41999998688697815 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.5230000019073486 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.5479999780654907 | Train Accuracy: 0.783 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.492000013589859 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.5120000243186951 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.4659999907016754 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.5450000166893005 | Train Accuracy: 0.783 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.47099998593330383 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.4729999899864197 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.5149999856948853 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 2 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 2 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "==================================================================================\n",
      "Epoch: 2 |Valid Loss: 0.49300000071525574 | Valid Accuracy: 0.856 | Valid-Class: [1] \n",
      "==================================================================================\n",
      "Epoch: 3 |Train Loss: 0.4880000054836273 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.44600000977516174 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.47099998593330383 | Train Accuracy: 0.883 | Train-Class: [1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4410000145435333 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.5149999856948853 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.5230000019073486 | Train Accuracy: 0.817 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.5109999775886536 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4740000069141388 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.49900001287460327 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.503000020980835 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.49799999594688416 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.48500001430511475 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.5070000290870667 | Train Accuracy: 0.8 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4740000069141388 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4690000116825104 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.5289999842643738 | Train Accuracy: 0.767 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4410000145435333 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.40400001406669617 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4659999907016754 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.503000020980835 | Train Accuracy: 0.833 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4909999966621399 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4970000088214874 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4909999966621399 | Train Accuracy: 0.85 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4779999852180481 | Train Accuracy: 0.867 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.47099998593330383 | Train Accuracy: 0.883 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.45500001311302185 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4449999928474426 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.45899999141693115 | Train Accuracy: 0.9 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.49000000953674316 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.503000020980835 | Train Accuracy: 0.833 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [1] \n",
      "Epoch: 3 |Train Loss: 0.4749999940395355 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.43799999356269836 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.5099999904632568 | Train Accuracy: 0.817 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.46299999952316284 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4490000009536743 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4790000021457672 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4790000021457672 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.49399998784065247 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4399999976158142 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.48399999737739563 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 3 |Train Loss: 0.4359999895095825 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 3 |Valid Loss: 0.4560000002384186 | Valid Accuracy: 0.899 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 4 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.44999998807907104 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4790000021457672 | Train Accuracy: 0.883 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 |Train Loss: 0.43299999833106995 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4350000023841858 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.421999990940094 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.41600000858306885 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4230000078678131 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4359999895095825 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4449999928474426 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4320000112056732 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4429999887943268 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.46799999475479126 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.453000009059906 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4230000078678131 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4309999942779541 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4309999942779541 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4819999933242798 | Train Accuracy: 0.867 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4569999873638153 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4189999997615814 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.40400001406669617 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4399999976158142 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4189999997615814 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4300000071525574 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4309999942779541 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4449999928474426 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.47999998927116394 | Train Accuracy: 0.9 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4519999921321869 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.43700000643730164 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4410000145435333 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4519999921321869 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.44200000166893005 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.421999990940094 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 4 |Train Loss: 0.4490000009536743 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 4 |Valid Loss: 0.4309999942779541 | Valid Accuracy: 0.946 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 5 |Train Loss: 0.4350000023841858 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4490000009536743 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4189999997615814 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4480000138282776 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 |Train Loss: 0.42899999022483826 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4180000126361847 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.42899999022483826 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.39399999380111694 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.38999998569488525 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.460999995470047 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4189999997615814 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.44999998807907104 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4269999861717224 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4390000104904175 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.42899999022483826 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4050000011920929 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.421999990940094 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.40299999713897705 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.40400001406669617 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 5 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 5 |Valid Loss: 0.414000004529953 | Valid Accuracy: 0.958 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4180000126361847 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.967 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3889999985694885 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.38999998569488525 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.40400001406669617 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.43799999356269836 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.41499999165534973 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4390000104904175 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.39100000262260437 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.41499999165534973 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4230000078678131 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4390000104904175 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.47200000286102295 | Train Accuracy: 0.883 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.421999990940094 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 6 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 6 |Valid Loss: 0.4090000092983246 | Valid Accuracy: 0.965 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.45100000500679016 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4169999957084656 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.421999990940094 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4050000011920929 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4189999997615814 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4189999997615814 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.42399999499320984 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 7 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 7 |Valid Loss: 0.41999998688697815 | Valid Accuracy: 0.947 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.38999998569488525 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3930000066757202 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.42500001192092896 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4480000138282776 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.42899999022483826 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.40299999713897705 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4300000071525574 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.4189999997615814 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 8 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 8 |Valid Loss: 0.4090000092983246 | Valid Accuracy: 0.964 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.40400001406669617 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.41499999165534973 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 9 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 9 |Valid Loss: 0.41200000047683716 | Valid Accuracy: 0.962 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.41600000858306885 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4180000126361847 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3930000066757202 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 10 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 10 |Valid Loss: 0.41100001335144043 | Valid Accuracy: 0.963 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4169999957084656 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.38999998569488525 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 11 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 11 |Valid Loss: 0.4059999883174896 | Valid Accuracy: 0.969 | Valid-Class: [0 1] \n",
      "==================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4050000011920929 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3930000066757202 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3919999897480011 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 12 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 12 |Valid Loss: 0.4050000011920929 | Valid Accuracy: 0.971 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.43299999833106995 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4169999957084656 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 13 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 13 |Valid Loss: 0.4059999883174896 | Valid Accuracy: 0.972 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.40299999713897705 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.40299999713897705 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3889999985694885 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 14 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 14 |Valid Loss: 0.40400001406669617 | Valid Accuracy: 0.972 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 15 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 15 |Valid Loss: 0.414000004529953 | Valid Accuracy: 0.954 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 16 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3919999897480011 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3930000066757202 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 16 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 16 |Valid Loss: 0.40400001406669617 | Valid Accuracy: 0.976 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.41999998688697815 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.44699999690055847 | Train Accuracy: 0.917 | Train-Class: [0 1] \n",
      "Epoch: 17 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 17 |Valid Loss: 0.4050000011920929 | Valid Accuracy: 0.971 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 18 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3919999897480011 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3930000066757202 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 18 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 18 |Valid Loss: 0.40799999237060547 | Valid Accuracy: 0.967 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.421999990940094 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 19 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 19 |Valid Loss: 0.4050000011920929 | Valid Accuracy: 0.969 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 20 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 20 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 20 |Valid Loss: 0.4059999883174896 | Valid Accuracy: 0.968 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.40299999713897705 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 21 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 21 |Valid Loss: 0.4059999883174896 | Valid Accuracy: 0.969 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 22 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 22 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 22 |Valid Loss: 0.4050000011920929 | Valid Accuracy: 0.969 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 23 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 23 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 23 |Valid Loss: 0.40400001406669617 | Valid Accuracy: 0.971 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 24 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 24 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3889999985694885 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 24 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 24 |Valid Loss: 0.4050000011920929 | Valid Accuracy: 0.972 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.4020000100135803 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 25 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 25 |Valid Loss: 0.40400001406669617 | Valid Accuracy: 0.973 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 26 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.421999990940094 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 26 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 26 |Valid Loss: 0.4059999883174896 | Valid Accuracy: 0.971 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 27 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 27 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 27 |Valid Loss: 0.40400001406669617 | Valid Accuracy: 0.973 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 28 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 28 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 28 |Valid Loss: 0.40700000524520874 | Valid Accuracy: 0.971 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3930000066757202 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4269999861717224 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.40299999713897705 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3919999897480011 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 29 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 29 |Valid Loss: 0.4050000011920929 | Valid Accuracy: 0.973 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 30 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 30 |Valid Loss: 0.4020000100135803 | Valid Accuracy: 0.974 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.40700000524520874 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 31 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 31 |Valid Loss: 0.40799999237060547 | Valid Accuracy: 0.964 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 32 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 32 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 32 |Valid Loss: 0.4099999964237213 | Valid Accuracy: 0.964 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 33 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 33 |Valid Loss: 0.40700000524520874 | Valid Accuracy: 0.963 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.4189999997615814 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 34 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 34 |Valid Loss: 0.40799999237060547 | Valid Accuracy: 0.968 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 35 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 35 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 35 |Valid Loss: 0.4090000092983246 | Valid Accuracy: 0.964 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 36 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.40299999713897705 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 36 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 36 |Valid Loss: 0.4099999964237213 | Valid Accuracy: 0.965 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.4339999854564667 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 37 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 37 |Valid Loss: 0.4090000092983246 | Valid Accuracy: 0.965 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 38 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.41100001335144043 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 38 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 38 |Valid Loss: 0.41100001335144043 | Valid Accuracy: 0.968 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3930000066757202 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.4320000112056732 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 39 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 39 |Valid Loss: 0.40400001406669617 | Valid Accuracy: 0.971 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.40299999713897705 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3919999897480011 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.4050000011920929 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.41499999165534973 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 40 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 40 |Valid Loss: 0.4059999883174896 | Valid Accuracy: 0.969 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.38999998569488525 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4390000104904175 | Train Accuracy: 0.933 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3889999985694885 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.39399999380111694 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3930000066757202 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.414000004529953 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3930000066757202 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 41 |Train Loss: 0.3930000066757202 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 41 |Valid Loss: 0.40400001406669617 | Valid Accuracy: 0.971 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 42 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 42 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3869999945163727 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3889999985694885 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 42 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 42 |Valid Loss: 0.4059999883174896 | Valid Accuracy: 0.969 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3930000066757202 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.40400001406669617 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.40299999713897705 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 43 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 43 |Valid Loss: 0.40700000524520874 | Valid Accuracy: 0.968 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.39100000262260437 | Train Accuracy: 0.983 | Train-Class: [0 1] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3840000033378601 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.4050000011920929 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 44 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 44 |Valid Loss: 0.40400001406669617 | Valid Accuracy: 0.973 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 45 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.40299999713897705 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.39899998903274536 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.38600000739097595 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3930000066757202 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 45 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 45 |Valid Loss: 0.40700000524520874 | Valid Accuracy: 0.971 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 46 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3889999985694885 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.40799999237060547 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.4259999990463257 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 46 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 46 |Valid Loss: 0.40700000524520874 | Valid Accuracy: 0.969 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.4059999883174896 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.39500001072883606 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 47 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 47 |Valid Loss: 0.40700000524520874 | Valid Accuracy: 0.968 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4099999964237213 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.38499999046325684 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4189999997615814 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 48 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 48 |Valid Loss: 0.4059999883174896 | Valid Accuracy: 0.969 | Valid-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.42100000381469727 | Train Accuracy: 0.95 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3919999897480011 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.4009999930858612 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.41200000047683716 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.39800000190734863 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.4090000092983246 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3880000114440918 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3880000114440918 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.414000004529953 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.4129999876022339 | Train Accuracy: 0.967 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3959999978542328 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.382999986410141 | Train Accuracy: 1.0 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.3970000147819519 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "Epoch: 49 |Train Loss: 0.4000000059604645 | Train Accuracy: 0.983 | Train-Class: [0 1] \n",
      "==================================================================================\n",
      "Epoch: 49 |Valid Loss: 0.4090000092983246 | Valid Accuracy: 0.964 | Valid-Class: [0 1] \n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "valid_losses = []\n",
    "valid_accuracy = []\n",
    "\n",
    "each_validp = []\n",
    "each_valida = []\n",
    "\n",
    "valid_zero_class_p = []\n",
    "valid_one_class_p = []\n",
    "\n",
    "print(\"Training started...\")\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    #############################[[[trainig]]]#########################################\n",
    "    train_losses = []\n",
    "    train_accuracy = []  \n",
    "    for n, tl in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        xt = tl[0]\n",
    "        yt = tl[1]\n",
    "        out = model(xt)\n",
    "        loss = criterion(out, yt)\n",
    "        train_losses.append(loss.detach())\n",
    "        train_acc= TestAccuracy(out, yt)\n",
    "        train_accuracy.append(train_acc)\n",
    "        #checking if training predicts both the classes \n",
    "        pred_train_ix = out.argmax(dim=1)\n",
    "        train_classes = np.unique(pred_train_ix.numpy())\n",
    "        print(\"Epoch: {} |Train Loss: {} | Train Accuracy: {} | Train-Class: {} \".format(e, np.round(np.array(loss.detach()),3), train_acc, train_classes))\n",
    "        \n",
    "        #############################[[[Validation]]]#########################################\n",
    "        \n",
    "        if (n == len(train_loader)-1):\n",
    "            pred_valid, validp_ix, valida_ix, valid_acc, valid_loss = ValidationAnalysis(X_valid, Y_valid)\n",
    "            each_validp.append(validp_ix)\n",
    "            each_valida.append(valida_ix)\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_accuracy.append(valid_acc)\n",
    "            pred_valid_ix = pred_valid.argmax(dim=1)\n",
    "            valid_classes = np.unique(pred_valid_ix.numpy())\n",
    "            each_class_pred = EachAccuracyClass(valida_ix, validp_ix)\n",
    "            valid_zero_class_p.append(each_class_pred['0'])\n",
    "            valid_one_class_p.append(each_class_pred['1'])\n",
    "            print(\"==================================================================================\")\n",
    "            print(\"Epoch: {} |Valid Loss: {} | Valid Accuracy: {} | Valid-Class: {} \".format(e, valid_loss, valid_acc, valid_classes))\n",
    "            print(\"==================================================================================\")\n",
    "        \n",
    "            #############################[[[Model Save]]]#########################################\n",
    "            if (len(valid_zero_class_p) > 2):\n",
    "                if (valid_zero_class_p[-2] < valid_zero_class_p[-1]):\n",
    "                    if (valid_one_class_p[-2] < valid_one_class_p[-1]):\n",
    "                        FILE = \"model_rnn.pth\"\n",
    "                        torch.save(model, FILE)\n",
    "             \n",
    "        else:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABAi0lEQVR4nO3dd3gVVfrA8e+bRkgCCSEJLUAooZdIVQRFQMWK2LBhQ1zXteDPspbdVdd11911xd21rR1U7A27iBQVkN57KCG0FCC95/z+OBO4hJvkJjeF3Lyf58mTe2fmzpy5d+adM++cOSPGGJRSSvkWv4YugFJKqdqnwV0ppXyQBnellPJBGtyVUsoHaXBXSikfpMFdKaV8kAZ3L4iIEZHuzuuXROSPnkxbg+VcKyLf17Sc9U1ERotI8skyH3XyE5E4Zx8JaOiyVEREdonIuIYuh6eadHAXke9E5M9uhk8QkQPV2dCMMbcZY56ohTKdsJEbY94xxpzj7bwrWN58EckXkWyXvy/qYlnq5NcYgqzyTJMO7sCbwGQRkXLDJwPvGGOK679IDeIOY0yYy99FDV2gpkhE/Bu6DMp3NPXg/hkQCYwqGyAirYALgZkiMkxEFovIERHZLyLPiUiQuxmJyJsi8heX9/c7n9knIjeXm/YCEVklIpkiskdEHnMZvdD5f8SpRZ8mIjeKyM8unx8hIstEJMP5P8Jl3HwReUJEfhGRLBH5XkSiavLliEgrEflSRFJF5LDzOtZlfKSIvOGs42ER+azc5+8VkRTne7ipkuVUOh+X6R4UkURnvTaKyESXcd1FZIHznaSJyPvOcBGR6U45MkRkrYj0q2D+N4nIJmf+O0TkN+XGTxCR1c7vligi4ysrf/nfzRnmmsp7U0ReFJGvRSQHOKuKbQMRGSkii5xtco+zjKEictC1ti0il4nI6grWs1rbn5vP+7n8Fuki8oGIRLqM/1DsmW+GiCwUkb4u45qLyL9EZLcz/mcRae4y+2tFJMn5DR9xV35nPs1E5Gln2oNi06LNnXGjRSRZRB525rNLRK51+Wy4iMx0tuvdIvIHEfFzGT/VZTvYKCKDXBad4GxDGSLyvogEV1TGBmeMadJ/wCvAqy7vfwOsdl4PBk4FAoA4YBMwzWVaA3R3Xr8J/MV5PR44CPQDQoFZ5aYdDfTHHlwHONNe4oyLc6YNcFnOjcDPzutI4DD27CIAuNp539oZPx9IBHoAzZ33T1Wy/vOBWyoY1xq4DAgBWgAfAp+5jP8KeB9oBQQCZ7qsXzHwZ2f4+UAu0KqC5VQ2n2SX6a4A2jvf2yQgB2jnjHsXeMQZFwyMdIafC6wAIgABepd9xk05LgC6OdOd6ZR5kDNuGJABnO0sowPQq4ryH/3dKtlmMoDTXcpd2bbRCchyfvNA5/dJcMZtBM5zWc6nwL0VrGdly4ij3Pbn5vPTgCVALNAM+B/wrsv4m53tpRnwLM7+5Ix7HrvNdQD8gRHOdGXLfQW73Q4ECoDeFZThWWA2dn9oAXwB/K3c9veMM+8zsdtKT2f8TOBz53NxwFZgiss2thcY6mwH3YHOzrhdwFLsNhiJjQe3NXQMq/B3augCNPQfMNLZwZo7738B7qlko/7U5X1Fwf11XAIqNtAenbaCDXW68/qEnYvjg/tkYGm5zy8GbnRezwf+4DLuduDbStZ/PjaIHXH5e6KCaROAw87rdkApbgK2s3PllVuHFOBUN9NWNZ/kSsq+GpjgvJ4JvAzElptmjLPzngr4VXPb+Ay423n9v7LfqBrlP/q7VbLNzKyiDK7bxkOu21+56X6PTSWCDTy5VHAQq+7252b6TcDYct9BkbvPYA+qBgjHHkzygIFupitbbqzLsKXAVW6mFWyw7uYy7DRgp8t2UwyEuoz/APgj9oBSAPRxGfcbYL7z+ruy39zNcncB17m8/wfwUnW2qfr8a+ppGYwxPwOpwAQR6Yo9Ys8CEJEeYlMRB0QkE/gr4EmKoz2wx+X9bteRIjJcROY5p4UZwG0ezrds3rvLDduNrQmVOeDyOhcIc5b7khy7aPqwyzR3GWMiXP7+6EwfIiL/c05dM7Gn7BFic8MdgUPGmMMVlDPdHH/N4mg5yqlqPkeJyPVOWuSIiBzBnhmVfW8PYHf6pSKyQZxUmDHmR+A5bI3xoIi8LCItK5j/eSKyREQOOfM/32X+HbFnRDUufwVct5Oqto2KygDwNnCRiIQBVwI/GWP2u5vQy+0PoDPwqcvvsAkoAdqIiL+IPOWkbDKxARFn/lHYs5OK1gEq2HbLicaeTa5wKcO3zvAyh40xOS7vd2P3nSggiOP3Idf9p7Lv2NPynRSafHB3zASux9aKvzfGHHSGvwhsBuKNMS2Bh7EBpCr7sRtJmU7lxs/CnlJ2NMaEAy+5zLeqbjr3YXcuV52wp5KVMrZFT9lF079WNT1wL9ATGO6s/xnOcMEGpUgRifBgPpXxaD4i0hl7yn4HNgUVAax3yoIx5oAxZqoxpj22JvaCOLltY8x/jDGDgb7Ys6j73cy/GfAx8DTQxpn/1xz7XfZgUzbVKX8ONgiVLaOtm2nK/96VbRsVlQFjzF7sGdxE7Hb8lrvpPFiGJ93E7sGmgFwrBMFOGa4BJgDjsLX1OOczAqQB+RWtQzWkYc8A+rosP9wY4xpoW4lIqMv7Tth9Jw17ltG53Liy/afC77ix0eBuzcRujFOBGS7DWwCZQLaI9AJ+6+H8PgBuFJE+IhICPFpufAtsbS9fRIZhd4gyqdjT/K4VzPtroIeIXCMiASIyCegDfOlh2aqjBXYnOuJcMDu6Hk6t8BtsEG0lIoEickYF86lQNeYTig08qWAvfmJr7jjvr5BjF3sPO9OWiL3YOFxEArHBNh9byywvCJufTQWKReQ8wLX56WvATSIyVuwFxQ4i0quK8q8B+opIgnPh7TEPvpLKto13gHEicqXz27cWkQSX8TOxZzD9sTn3miyjqu0P7MHgSeeAi4hEi8gEl3kXAOnYA9vRSoQxphSbsnxGRNo7tfzTnAOrx5z5vAJMF5EYpwwdROTccpM+LiJBIjIK20jiQ2NMCXb/fFJEWjjr8H/YMx+AV4H7RGSwWN3L1rOx0eAOGGN2AYuwAWS2y6j7sBt+FnZjet/D+X2DzWP+CGx3/ru6HfiziGQBf8JubGWfzQWeBH5xTjlPLTfvdOyGei92B3oAuNAYk+ZJ2SrwnBzfzn2FM/xZ7MWtNOwFtG/LfW4ytha0GZtTn1bD5Vc5H2PMRuBf2NrpQWwA+8VlkqHAryKSjf0N7zbG7ARaYn+7w9jT73Rs7bz8/LOAu7C/xWHs7z7bZfxS4CZgOvYazQKO1f7clt8YsxV7UfkHYBtwXMuZClS2bSRhU0X3Aoew1xwGunz2U6dMn5ZLSVRnGZVuf45/Y7+b7515LAGGO+NmYr/nvdiLvEvKffY+YB2wzFmHv1OzOPR77L61xEn//IA9yyxzAPs77sMeFG8zxmx2xt2JPdDvwP4ms7AHHYwxHzrrPwu733+GvYbR6IhzYUAp5QNEJBH4jTHmh4YuS0MRkdHA28aY2Com9Wlac1fKR4jIZdh0VPkzRdUE6S3GSvkAEZmPvfYy2clJqyZO0zJKKeWDNC2jlFI+6KRIy0RFRZm4uLiGLoZSSjUqK1asSDPGRLsbd1IE97i4OJYvX97QxVBKqUZFRMrfrX6UpmWUUsoHaXBXSikfpMFdKaV8kAZ3pZTyQRrclVLKB1UZ3EXkdbGPKFvvMixSROaIyDbnfyuXcQ+JyHYR2eKmlzallFL1wJOa+5vYx8a5ehCYa4yJB+Y67xGRPsBV2H6zx2O7QdWH/iqlVD2rsp27MWahiMSVGzwB+ygrsP2fz8d2wTkBeM8YUwDsFJHt2GdPLq6l8lastAQKs6EwBwqyj70uzCn3OgdCo6DTaRDdE8STZ2/UgpIiOJIEwREQ2rp+lqmUarJqehNTm7JHeBlj9pd1mI99VJVr/83JHP/4t6NE5FbgVoBOnco/qMhD+1bB25fbgF2cV/3PN4+0Qb7zadBpBLQbAP6BNSuLq70rYc9SOJQIh3ZAeqIN7KYE/JvBKdfC6XdDqzjvl1UXCnNh+xy7DqdPgzC3N8CdaNXbkLwcgkIhKAyahR17HRwOYTEQ1hZCo8H/pLh/ruGUloJfHV/yqo9l+LKyfrfqqwJYy2p7D3P3LbjtmcwY8zL2gcYMGTKkZr2XhURBnwnHAkhQqP1r1gICQ1yCS4tj44LC4MhuSFoMuxdD0iLY8pWdX0QnuPYjW6OvieIC+OExWPKCfR/UAlp3hfYJ0O8yiOwCyctsEFwxA/pfASPvgZheNVtedeRn2KBdUWAtC+gbPoOt30JRrh2+6ye44UsIdvvY0WN+/R9884AN4iVFxz7vltizp7C29jvvOR56XQghJ/EzEYyBnDS7fgFBnk2/fzXsXAhZByHb5S/roD2b7DgMuo+D+HOgbf/aCyJZB+C7h2H9J+AfdOL+0byV/c77XQ7NI2pnmd7KTgU/f1u26nwPhblweKetQB3aYStU2SkQHguRXSGyG7TuBhGdT/zdigucM/0syNx7/DzSd9jXQaHQ+yLoOxE6j7BldKe40P7eKRuhRTu7bHfLdFVSDDmpgIGW7T1fZw951Cukk5b50hjTz3m/BRjt1NrbYZ8c3lNEHgIwxvzNme474DFjTKVpmSFDhpgG7X4g6wDs+tnuECWFcM0HdserjpTN8PEtcHAdDLsVRt1na6ruNtTMfbDoOVjxhg2CvS6E0+6A2KHe12hTt8KBtcfOGMo21tx0Z4KywNrm2F9RLmybA0U59oBZtjEX5cJ710Lc6fagF1DB09DWfWTXvdcFcMUMuw6lJcenwvIOO8HtgN35yoJcykZ7sPULgC5n2uX2uuBYoC/IhoPrYf9aOLAGUjbZHbbvROg2BgKDK/4usg7C9h8gdZP78eIHgaHHVwqCQu16Zu5zvr+y73CnDcjB4dDrIuh7iS1v+Z03Jx3WfWAP4AedNghBYc5Zi8t37h9oD5z719hpwtraQN99jK0UuEsrRveyv01QCG6VlsDy12Hun23gGnwDBDY/cT4ZyZC2FQKC7fxOuQ7izqifWn5pqQ3GB9Y6v6nzPyfFjvcLdL6jGGjR1vmugtykV7Psd5217/j5hzjbdkYyFGQcGy5+0LKDPeiWzae06MTy+QXYoNy6m93Osg/A1u/svhAaA30uhj6XQLuBsHeFU0lcZM9Yy2cPxA/CO9p5tYqDovzjD/I5aYCxB9nLX6vR1ykiK4wxQ9yOq2Fw/yf26fZPiciDQKQx5gER6Yt9PNUw7JPG52IfLu3umZVHNXhwL3NoJ7x9KWTuhytnQA8PGvsYA8tfg+8esYFhwgu2VuSJnHT49SVY+j9bsw4MhY5DbYqo8wiIHWJ3zqqkbIaNn8GGTyF187HhLTvYGkTrbvZ/YIitKWSVBVjnf2mJLXPfidB55PEHmDXvwae/sRv05a+fWHNJ/BHeudIeDK/7pPJg605ZDXfDZ3YdDu+yO1jH4XYHSE/k6Mlf80iI6WODZv4RaNYSep53LNCLP+xdbg9U2763gQNsKsxdjau0BEoKKi6bX4DdKctqgK0622C8+SsoyLTXT3pdaAO9MbDqLdjyjQ0a7QfZoNl3YuVnJGUHoO1zYPuPxwckV+IHptQG/v6XQcJ1dvsoqzzsXwNfTIN9K+1B58Lp9nev8DtfYw9A6z6w2154J0i42tacy28f2QehqIK0p3+QDaYt2hx/8ApuaYOX69lK9kHI2n/srM4vwB6w2g44dubiuuwspzJQUnx8iq/sf/MI57dx2caDw4+tY+6hcqnR3fbgERR6/Jl8UKitbbfuar+H8hWswhy7PW34zP53PSsVP1v2TiNserftALuPla9cHd5l97+j31HZwSsGYvraz9aAV8FdRN7FXjyNwj678lHscwU/wD41PAm4whhzyJn+EeBmoBiY5jxPtFInTXAHe3r4zuVwYB1MeA4Srql42px0mH0HbPkauo2FS160G3l15WfanXv3YlsTOLgBMHZDbDfAnmKGtT2+NtOsJeyY7wT0TYDYA0LfidD5dJsC8uTA4IlF/4Xv/wBDb4Hznz4WUPaugDcvsjvVTV8d27FqyjXQ75hv17vtAPsdtB1gT11FbNpnxwLY+Cls+vJYoBc/+1r87cEh3kl5tOlX8am+64X4stphUZ7d2cM7uj+TKi6AxHn2u9/ytQ30YGuNA6+ChGuhTZ/qr39JsT07MaZc8AmzgTBpEax6xx4Ei3Ihqqc9gGQdgF9fhJDWcO7foP/lnqc2ivJh85ew+h27TmXb3XEBO8aWwe3nc48dAMqCuOsBs1nLY9dayrbf6F72N43uXf3KQEMrC/SpW6HDYFupqSplWYe8rrnXtZMquIPNwb1/nQ0w4x63Fz9F7E6Xts3uZLsX24BckGWnGX5b7Z3W5h22FzN3/2IvzpbtNCfU6pyA3ucSe7rYom3tLN+d7/8Ii/4Dox+C0Q/a7+G1c2wqY8r3dbvsyhQX2rz2xs8AY1MbXc+qv1xyWaDH2AO8J/l4b+Vn2gPLqrcheakdNvgmGPeorXnXVE663c6rm/d2ZYw9EyjItAeboNCal0dVSYN7TRQXwme3wfqP7YXPojxIWgK5aXZ8aLQNrKPus7WQ+lCU59SQUmwOvV0CtGxXP8s2Bj7/na3hnfUIrJwJxflw83cVn/6rupe2zaZratoIQDVqlQX3Jt4erRIBQXDpq/Yiyq8v2txr/DnHmk227lb/TaQCm9tyNEQTShG46D/2oDLvSZv7vfFLDewNLSq+oUugTlJac/dEUV7t5a8bu8JcmPu4TQXV8CKQUqp2aM3dWxrYjwkKgfP+3tClUEpVQW9fU0opH6TBXSmlfJAGd6WU8kEa3JVPWLIjnaU7DzXIstfsOcKSHelVT6hUPdLgrhq9/KISfvv2Cm6ZsYz07Eq6E6gDew7lct2rv3LTG8vYd6QGPZMqVUc0uKtG75OVezmcW0RWQTFPf7+l3pZbXFLKPe+vBqDUGJ78uoIOypRqABrcVaNWWmp4/Zed9OvQkimnd+G9ZXtYm3ykXpb9wvxElu8+zF8m9uP20d35au1+FiWmeTXP0lJDSTX/ToZ7VdTJR9u5q2rJLihm/LMLue3Mblx3aueGLg4LtqWyPSWb6ZMGMq53Gz5bvY8/fb6BT347Aj+/uruDeGXSYf49dxuXJLRnQkIH8otK+HDFHh6bvYGv7hpFoH/1602Hcgo5Z/oC0rILq/W507u35p1bTq328pRv0+DeSG0+kElc61CCA+v3EbVfrNlH8uE8nvpmM+f0bUNMi7rp1W/PoVxiWzVHquji4bWfdtKmZTMu6N+eoAA/HjqvF/d+uIaPVyZzxZCO1V6uMYbE1Gw6RobQLMD9d5tdUMy091bTtmUwf76kHwDBgf786cI+3PrWCt5avJubR3ap9rLfWbKbtOxCfndWtwqXXd7a5CP8sCmFlKx8r3+LxNRsYls193jZ6uSmwb2RKS01/OO7Lby0IJEOEc15YHxPLh7YvsogWFveW5pEh4jmpGYV8NQ3m3nmyoRaX8aSHelc9fISpo2LZ9q4HhVOt/lAJj9vT+OB8T0JCrA15YmndGDW0iT+/u1mzu3XlpbBnj82cV1yBk98tZGlOw/RKTKEh87rxfh+bU/4bh+bvYHkw7m8/5vTjpv/2X3acEaPaKbP2cpFA9sT3aKCh5u4UVBcwswluzmzRzT3n+v5k7nWJWfww6YUftmexsRTYj3+XHlHcgs5798/MbZXDC9cO6jetidVdzTn3ojkFhZz+zsreWlBIpcktCciJJC731vNxBcWsWL34RrNc3d6Dp+t2utR3nbjvkzWJGcwZWQXbhnVhU9W7mXF7tpvfvjOr0kA/PfH7ZWu12s/7aR5oD/XDDv2DF4/P+Hxi/uSnlPIs3O2ebS8/Rl5/N8Hq7nouZ9JTMnm/87uQfNAf377zkqu/N9i1uw5cnTaL9fu46MVydxxVneGxh3/EA4R4dGL+pBfXMI/vt1MdXyxZj+pWQXcMqp6Nf6+7VvSKiSQn7Z6l+tfsDWVwuJSvll/gA9XJHs1L193MDOfL9bsq3rCBqbBvZE4mJnPpP8t4buNB/jjhX2YPimB2XeM5J+XD2DfkTwue3ERd8xayZ5DlT279HiLtqdx8XO/MO391fyyvep22u8tSyIowI9LB3XgjjHdaRcezJ8+30BJae1d0DuUU8h36w9w2aBY2oUHc8/7q8kuKD5hupSsfD5fvY/LB8cSEXJ8H+r9OoRzzbBOzFi8iy0HsipcVk5BMc/M2cpZT8/nyzX7ue3Mbsy7fzR3jY3nq7tG8teJ/dmZlsOE53/hnvdXs2L3YR7+ZB0JHSO4c6z73hi7RYdx88gufLgimZVJnh1wjTG8+tMOerZpwcjuUR59poyfnzAyPpqftqd5dWF17qYUWocGcWrXSB6bvYFdaTk1npcvM8Zw56xV3PnuKuZuOtjQxamUBvdGYP3eDCY89wuJqdm8ev0Qpozsgojg7ydcMaQj8+4bzd1j4/lh00HGPrOAp77ZTFa+m+dDunh3aRLXv76UmBbNaNsymGfmbKk0OOQVlvDpqr2c368tESFBhAQF8PD5vdmwL5P3liXV2rp+sjKZwpJSpp7RhWcnJZB8OJfHZm84Ybq3lyRRVFrKTafHuZ3Pfef0pEVwAI/N3nDcehUUl/DztjT+8uVGznp6Pv+Zu41xvdsw994zefC8XkfTLAH+flwzvBPz7hvN7aO78dW6/Vz24iJKSg3/viqh0gumd46Jp03LZjzq4YFvcWI6mw9kHf1dq2tUfBSpWQVsOVjxgawyxSWlzN+Swlm9YnjmygQC/IRp76+mqKS0RvOa9WsSV760mEtf+OWEv0n/W8zHK5IprcUKgTeyC4p56JO1fL56r0fTz16zj6W7DhES5M/jX2wkv6jSJ4g2KA3uXqiPJmhzNh7kyv8txk/go9tGMLb3iY/xC20WwD1n92DefaO5cEA7XlqQyOh/zuedX3dTXG4HLSk1/OXLjTz0yTpO7x7Fx7eP4M6x3VmZdIQFW1MrLMfX6/aTlV/MVS4pkAsHtOPUrpH887stHM6pXgsPd4wxvLdsDwkdI+jVtiVD4iK546zufLQima/W7j86XX5RCW8v2c3YXm3oGu3+8W+tQoO495yeLN6RzoxFu5i5eBdT3lxGwuNzuO61X5m5eDe92rXk49+exnPXDKJjpPuHTrcIDuSB8b348d4zuXZ4J6ZPSqBz68qfLhTWzB741u3N4IPle6pc71d/3klUWBAXJ7Svclp3RsXb2n5NUzMrdh8mM7+Ysb1iaB/RnL9e2p/Ve47w37mepbXK/LQtlQv+8zMPf7qOzPwiQpsFnPB3KKeQez9cw8XP/+zRXb3GGIpLSt3+ebv/7T2Sx+UvLuLdpXu4/6O1bD6QWen02QXF/PXrTfTvEM5L1w0m6VAur/60w6NlNURzVb2gWkPLdx3irndX8fSVAxnRrXqn0p6wp+o7+es3mxjQIZxXrh9CTMvKW0O0C2/OM1cmcOOIOP7y1SYe+XQ9Mxbt4pEL+nBmj2iyC4q5+91VzN2cwo0j4vjDBb0J8PfjisEdeWFeItPnbOXMHtFua4/vLUuia1Qow7scyzOLCI9d3JcL/vMz/5qzhb9c0t+rdV6x+zDbU7L5+2XH5nPn2HgWbkvjoU/WckqnCNpHNOfTVXs5lFPIlCpapFwzrBPv/prEY19sBKBTZAhXDInlzB7RnNatNSFBnm/+sa1CeHKi5+t38cD2vLPEXtgd0a11hQeE7SnZ/Lg5hWnj4mvc8qldeHPiY8JYuC2VqWd0rfbnf9ySQqC/MNI5SFw4oD3zNqfy3LztnNEjmiHlri2Ut+1gFn/9ehPztqTSKTKEF68d5PZCNNgGAbPX7OPv327mqpeXcG7fNjx0Xm/ioo59P4dyCvlpWyoLt6axcFsqqVnu7zru3DqEWVNPpUNE9bvkXpV0mKkzV1BQVMK/r0rgiS83Mu291Xz2u9Mr/B3+++M2DmYW8OJ1gxnUqRXn9WvLc/O2M3FQbKVl2Howi5veWMbdY+O5cmj1W3DVlD6sowa2p2Rx2YuLycgr4qye0bxx07BanX9hcSl//Gw97y/fw/n92/KvKxJoHlS9Hd8Yw3cbDvK3bzaxOz2XM3tEczAzn20p2Tx2UR8mnxZ33PTvL0vi9x+v47UbhpxwdrDtYBZnT1/IQ+f14jdnnvjkpcdmb2DG4l18ccdI+nWo+UOy7/twDd+s28/SR8YR2uxY4N2VlsP5//mJAbHhvHPLqZz77EKaBfjx5Z0jq0xj7EzLYVFiGiO6RRHXOqReW4HsTMvh0hd+Ibx5IB//dgStw05sPfPIp+v4cEUyix4cQ5Sb8Z768xcbeefX3ax59JxqHyTOfmYBMS2bHddWPiu/iAv+8zOlxvD13aPctjracyiXlxfuYNbSJEKC/LlrTDzXj+jsUVPKvMISXvt5By/MT6SopJTJp8YRFhzAgq2prE0+gjEQERLIqPho4mPCKP+rlRjDaz/vpE3LYD6+bQThIZ63ivpy7T7u/WANMS2b8foNQ4lv04J5m1O46c1l3Hx6F/500YkPN09MzWb8swuZkNCBp68YCEDy4VzGPbOAsb3a8Py1g9wua39GHpe+sIj9Gfm0CA5g3n2jvfqdy6vsYR2alqmmlMx8bnh9GYH+flw2KJYFW1NrtU+RI7mFXP/6r7y/fA93junOc1cPqnZgB1urHt+vLd/fcwZ/uKA3K5MOs/dwHq/fOPSEwA5w6aBYOkWGMP2HrSecQr63bA+B/sJlg903tbvn7B5EhgTxaLn8dnVk5hfx5dp9XJzQ4bjADhAXFcpjF/dlyY5D3DpzOdtTsrlllGf56S5RoVw7vDNdokLrvXlfl6hQXr1hKPsz8rl5xnJyC4+/MHw4p5CPVyYzMaGD1zv8qB5RFBSXsmxX9VovJaXnsi0lmzG9jj+gtwgOZPqkBPZn5PPY5/aaR35RCQu3pvLElxsZ+6/5jPrHPGYtTeK64Z1YcP9ZTD2jq8dt5JsH+XPHmHjm3zeaS0+J5Y1FO3nux2023z+2B5/97nRW/OFs/nv1Kdw1Np47y/1NG9eDlycPISk9l6kzl3uU+zbG8N+527hj1ir6dwjns9tPJ75NCwDO6hXDDad15vVfdrKwXHrSGMPjX2wkOMCf348/1kw1tlUIvxvdna/W7eeX7SemxDLzi7jpjWVk5Rfzn6tPIa+whH9+W3/dY2hwr4as/CJufGMZh3MLeePGoUwbF48Bj/KqntiRms3EFxaxcvcRpk8ayL3n9PT6LstmAf7cMqorP/9+DD/eN5oze0S7nS7Q34+7xsazfm8mczYeawVQUFzCJyuTObtPmwoDUHjzQH4/vhcrdh+u8Xfx+ep95BeVcvUw96etVwyO5bx+bZm7OYWYFvampcZgcOdW/OfqU1iXfIQ7Z6067hrIrKVJ5BeVMqWazR/dGd4lkiB/P37aVr28+4+b7W89tlfMCeMGd27FnWO688mqvVz50mIS/vw917++lLeW7KZ9RHP+eGEf5t07mscn9CMyNOiEz3sipmUwf798AIseHMOqP57Dx78dwd3j4knoGIF/Fdv+ad1a8/SVA1m66xD3frCm0ou0GblF/N8Ha/jXnK1MPKUD70wdfsKZ1EPn9yY+Jox7P1zDIZdrSHM2HmTh1lSmnd3jhHsXpp7RlU6RITw6e8NxF6ALikv4zcwVbE/J5sXrBnHxwPbcPLIL7y/fw2qXprV1SYO7hwqLS/nt2yvZcjCLF64dRP/YcDpGhjCyexQfLNvjdXPARdvTuOT5X8jIK2LW1OFe3ZDiTnjzwCpvqrkkoT1dokKZ/sO2ozvKdxsOcji3iKuGdqr0s5cPjmVYXCQPfbKOGYt2Vbt87y1Nok+7lvSvIK0jIvzt0v707xDOvef0OHrTUmNwbt+2PD6hH3M3p/DHz9djjKGguIQ3F+1iVHwUPZzaozdCggIYEtfqhFpnVX7ckkrXqNDjct6u7jirO6Pio0jJymfSkI68ceNQ1vzpHN6aMpwpI7vQqbX7C9HV1S68ebVSK2UuHtieR87vzVfr9vPEVxtPOHMsKinlzV92cubT8/hs9V7uPbsHz1w50O0ZRnCgP/++6hQycov4/cdrMcaQX1TCn7/cSI82YVx/2ondbZTdmbw9Jfvodl9aarj/w7Us3pHOPy4fwKh4W6G6c0x3Ylo049HP19dLayG9oOoBYwwPfryWn7en8c/LBzC657FaztXDOnH7OytZuC2Vs3qeWPvxxIKtqUx5cxldokJ5/cahFbbcqGsB/n7cPTaeae+v5rsNBzivfzveW5pEbKvmVba/9vMT3rhpKHe/t5pHZ28gMTWbP13YhwAP+lhZl5zBhn2ZPDGhb6Wpk4iQIL64c2S11+tkMPnUzuw/kscL8xNpF9786F2+Zfnb2jAqPpq/f7uZlMz8Ki++g23nvyQx3W3QKhPg78dbU4bXWhnrwi2jurA/I5/Xf9lJ+/DmTD2jK8YYftycwpNfb2JHag6nd2/NI+f3oU/7lpXOq0/7ljwwvid/+WoT7y3bQ0pmAcmH85g1dXiFzV/H9o5hdM9onv1hGxcntOfVn3Yye80+Hhjfk0sHHauktQgO5KHze3HP+2v4cMUeJlVRYfKWBncP/PO7LXyyai//d3aPE/orGde7Da1Dg3j316QaB/ev1+4nLDiAj28fUa3b5evCRQPb898ftzH9h630ateSRYnp3Ht2D4/SQ6HNAvjf5MH8/dvNvLxwBzvTcnj+2kFVrtO7y5IIDvRjwikdams1Tkr3n9uTA5n5PDNnK5GhQcTHhHFGfO21tBoVH8Xfv4Wft6cdF1Qq8vP2NApLShnTu2bb7clCRPjDBb05mJnPk19vosQYftqWyi/b0+kaHcprNwxhTK8Yj6+53Hx6F+ZvSeXPX2yk1BguGNCu0hZx9s7kvpw7fSFXvbyEHak5XH9aZ37rpvHBJQkdmPVrEv/4dgvj+7ar0dmKpxrPuW0DWZSYxgvzE7l6WCfuHNP9hPFBAX5cPjiWuZtTSMnMr9EyElOz6RHTosEDO4C/nzBtXA+2Hszm9ndW4idUqwMufz/h4fN78/fL+rM4MZ1LX1hEUnrFd83mFBQze/U+Lujf/qRY/7okIjx16QBGxUcdbcpZmxd5+7RrSWRokMd59x83pdCiWcAJ3Sg0Rn5+wr+uHMiwLpE89c1mNuzL5PGL+/LdtDMY27tNtb5nPz/h6SsG0izQDz8RHjm/d5Wf6RIVypRRXdiRmsO5fdvw6EXuz0LLmg8fzi1k+g9bq7WO1aXBvQqJKdkA3HN2fIUbyKShHSkpNTXuk2NHWg7dYiq/MaY+XdC/HT3ahLFpfyZjesXQNrz6vQ1OGtqJmVOGkZpVwITnf2bB1lS3ecav1u4nu6C4wgupviYowI8XrxvMv69K4PIKWh/VlJ+fMLJ7FD9tS6syp1taavhxSwpn9IiuUffEJ6PgQH9euX4If53YnwX3ncUNI+JqvG5tw4N5d+qpvDVlGO09bEd/99h4pk8ayL+vOqXSi8F924dz7fDOvLVkd5U3TnnDN37VOpSZb5uvVVar7BodxvAukby/bE+1L5QczinkUE4hXaPc32nZEPz8hP87uycA13rRZ/uIblF89rvTiQgJ4obXlzLkyR+Y9t4qPl2VfPRxeO8uS6J7TBiDO7eqlbI3BmHNApiQ0MGj6xHVNSo+irTsAjZX0qcOwIZ9maRmFTDGTSuZxiy8eSDXDO9UK+mO3u1aVnkDl6vgQH8mnhLr0X0G957Tg5bBATz6ec2bD1dFg3sVMvOKaBbgV+UPdvWwTiQdymVxNR+UvCPNnhmcTDV3gPH92vLTA2fV+DpCmS5RoXxx50ienZTAmT2i+WlbGve8v4YhT/7ABf/5iVVJR7hqaEftYraWlLXM+Glb5a1m5m4+iAiM7um+aayqWxEhQdx/bi9+3XmIL1y61qhNGtyrkJFXRHjzqmsB4/u1Jbx5IO8urV4nWokptve9k6nmXqa2Wu2ENQvgklM6MH1SAsseGcfsO07nnnE9CA70p2Nkc48u/inPtA0PpkebsCrz7j9uTuGUjhFu75pV9WPS0I7069CyznqX1NYyVcjML6KlB8HdnpLZK+GHcgo9vqkjMS2bIH8/YltVv3+MxsjPTxgQG8GA2AjuqqDbXOWdUfHRvLVkN/lFJW7POFMy81mbnMF951T8IBRV9/z9hLduHk5EHbWY8armLiL3iMgGEVkvIu+KSLCIRIrIHBHZ5vxv1MnUzLxiWgZ7dgy8elgnCktK+WSl5xdWd6Tm0Ll1SJ3kX1XTNCo+isLiUpbudN8VwfwtNmVTvssBVf9ahQbVWUqyxhFFRDoAdwFDjDH9AH/gKuBBYK4xJh6Y67xvtDytuQP0bNuCUzpFMGtpkscXSRJTs+lWQbe1StXE8C6tna4I3Ofd524+SLvwYHq38/7OWHXy8ra6GAA0F5EAIATYB0wAZjjjZwCXeLmMBpWZV1St9tdXD+3EjtQclu2q+ik8RSWlJKXn0jX65LqYqhq35kH+DO3SirmbUpi/5fi/eVtS+GlbWrVu6lGNU41z7saYvSLyNJAE5AHfG2O+F5E2xpj9zjT7RcRtcwsRuRW4FaBTp7q9Ddcbnl5QLXPhwHY89sUGvlizj2FdKm9GlXQol+JSozV3VevO6hnDX77axI1vLHM7/py+beu5RKq+1Ti4O7n0CUAX4AjwoYhc5+nnjTEvAy+D7c+9puWoS8YYMvOLadnc868pJCiAgbERrEk+UuW0O1KdljJac1e17MYRcQzrEkmxm/suggP8NSXTBHjTWmYcsNMYkwogIp8AI4CDItLOqbW3A1JqoZwNIrewhJJSU+3b4gd0DOf1n3dSUFxSaf/Wiam2jXtFj4pTqqYC/P0YEBvR0MVQDcibnHsScKqIhIhN3o0FNgGzgRucaW4APveuiA0n03nItKcXVMskxEZQVGLYtL/yuwR3pGYTFdasWmkfpZTyhDc5919F5CNgJVAMrMKmWcKAD0RkCvYAcEVtFLQhZOTZ4F7d4DugYwQAa5OPkOC8dicxNYdumpJRStUBr1rLGGMeNcb0Msb0M8ZMNsYUGGPSjTFjjTHxzv/qPffrJJKZV3W/Mu60Dw8mKiyoyieu7EjN1pSMUqpO6J0zlcjMK0vLVO8ER0QYGBvB2uSMCqc5lFPI4dwirbkrpeqEBvdKHM2516Cf8QGxESSmZpPlzKO8Hc7FVG0GqZSqCxrcK1HTnDvAwI7hGAPr9rqvvSdqcFdK1SEN7pUoy7m38LBvGVdlzdDW7HEf3Hek5hAU4EeHJtJhmFKqfmlwr0RmfhGhQf416tQrMjSITpEhrK3gZqbE1Gy6tA6t9IktSilVUxrcK5GZ53mnYe4MiA1nTQUtZnak5uidqUqpOqPBvRKZ+dXrNKy8hI4R7MvIJyXr+AdnFxaXsvtQrubblVJ1RoN7JarbaVh5ZXn3teXy7kmHcikpNVpzV0rVGQ3ulcjMq16nYeX169ASP+GEvLu2lFFK1TUN7pXwNi0TEhRAjzYtWFPuZibtDVIpVdc0uFfC2wuqwNHuf12fzJSYmk1Mi2a08OLAoZRSldHgXoHSUkNWQbHXwX1Ax3CO5Bax51De0WG2TxmttSul6o4G9wpkFRRjDB4/HLsiA52LqqudvLsxxukNUvPtSqm6o8G9Asc6DfOu5t6zbQuCAvxY67R3P5RTSEZekfYGqZSqUxrcK+BNp2GuAv396Nu+5dHH7iU6F1O1N0ilVF3S4F4BbzoNK29gbATr92ZSXFKqvUEqpeqFBvcKHH1Qhxft3MsM7BhOXlEJ21KySUzNplmAH+0jtMMwpVTd0eBegdpKy8Cxi6prk4+wIzWHLlHaYZhSqm5pcK9AbV1QBYhrHUqL4ABW78kgMTVbUzJKqTqnwb0CmXlFiECLZt6nZfz87GP3Vuw+xJ7DedrGXSlV5zS4VyAzv5gWzQLwq6X0yYDYcLYezKak1GjNXSlV5zS4V6A2uh5wNbBjxNHXWnNXStU1De4V8LbTsPLKLqoCegOTUqrOeZ9Q9lHedvdbXtvwYGJaNEMEwmohj6+UUpXRKFOBjLwi4qJCanWeExLak19UWqvzVEopdzS4V6C20zIAj1zQp1bnp5RSFdGcewVq+4KqUkrVJw3ubhSXlJJTWFLrNXellKovGtzdyMy3/cqE1+IFVaWUqk8a3N2oza4HlFKqIXgV3EUkQkQ+EpHNIrJJRE4TkUgRmSMi25z/rWqrsPWlNjsNU0qphuBtzf3fwLfGmF7AQGAT8CAw1xgTD8x13jcqx7r71eCulGqcahzcRaQlcAbwGoAxptAYcwSYAMxwJpsBXOJdEetfxtG0jObclVKNkzc1965AKvCGiKwSkVdFJBRoY4zZD+D8j3H3YRG5VUSWi8jy1NRUL4pR+8rSMrXxFCallGoI3gT3AGAQ8KIx5hQgh2qkYIwxLxtjhhhjhkRHR3tRjNp39IKq5tyVUo2UN8E9GUg2xvzqvP8IG+wPikg7AOd/indFrH+Z+UX4+wkhQf4NXRSllKqRGgd3Y8wBYI+I9HQGjQU2ArOBG5xhNwCfe1XCBpCZV0zL4ABE9FF4SqnGydsrhncC74hIELADuAl7wPhARKYAScAVXi6j3mXkFWm+XSnVqHkV3I0xq4EhbkaN9Wa+DS0zX/uVUUo1bnqHqhuZebXfI6RSStUnDe5uZObX7oM6lFKqvmlwd0Nz7kqpxk6DuxuallFKNXYa3MvJLyqhoLhUL6gqpRo1De7lZDl9ubcM1py7Uqrx0uBeTob25a6U8gEa3Ms52pe7BnelVCOmwb0c7TRMKeULNLiXo89PVUr5Ag3u5WjNXSnlCzS4l6MXVJVSvkCDezmZ+UUEBfgRHKh9uSulGi8N7uXYvty11q6Uatw0uJdju/vVi6lKqcZNg3s5mdppmFLKB2hwL0c7DVNK+QIN7uXYvtw1uCulGjcN7uXYmrvm3JVSjZsGdxfGGDLy9PmpSqnGT4O7i7yiEopLjV5QVUo1ehrcXWTmlfXlrsFdKdW4aXB3cay7X825K6UaNw3uLrTTMKWUr9Dg7qKs0zDNuSulGjsN7i70KUxKKV+hwd3FsQuqmnNXSjVuGtxdZGpf7kopH6HB3UVGXhEhQf4E+uvXopRq3DSKucjM107DlFK+QYO7i8y8Ym3jrpTyCV4HdxHxF5FVIvKl8z5SROaIyDbnfyvvi1k/tOaulPIVtVFzvxvY5PL+QWCuMSYemOu8bxS00zCllK/wKriLSCxwAfCqy+AJwAzn9QzgEm+WUZ8y8/UpTEop3+Btzf1Z4AGg1GVYG2PMfgDnf4y7D4rIrSKyXESWp6amelmM2mEfjq05d6VU41fj4C4iFwIpxpgVNfm8MeZlY8wQY8yQ6Ojomhaj1pSWGrLyNS2jlPIN3lRTTwcuFpHzgWCgpYi8DRwUkXbGmP0i0g5IqY2C1rWcwmJKjXYappTyDTWuuRtjHjLGxBpj4oCrgB+NMdcBs4EbnMluAD73upT1QDsNU0r5krpo5/4UcLaIbAPOdt6f9I72K6Pt3JVSPqBWIpkxZj4w33mdDoytjfnWp6M9QmpaRinlA/QOVYd2GqaU8iUa3B2ac1dK+RIN7o7MfH04tlLKd2hwd5SlZcL0JiallA/Q4O7IyCuiRbMA/P2koYuilFJe0+DuSM8ppHVYUEMXQymlaoUGd0dqVj7RLZo1dDGUUqpWaHB3pGYVaHBXSvkMDe6O1KwCosM0uCulfIMGdyC/qITM/GKtuSulfIYGdyAtuwBAg7tSymdocMemZECDu1LKd2hwxyW4hwU3cEmUUqp2aHAHUjUto5TyMRrcgbSsQgC9iUkp5TM0uAOp2fm0Cgkk0F+/DqWUb9Boht7ApJTyPRrc0eCulPI9GtyxF1T17lSllC9p8sHdGKM1d6WUz2nywT27oJj8olIN7kopn9Lkg7venaqU8kUa3PXuVKWUD9LgrnenKqV8kAZ3TcsopXyQBvesAvz9hIjmgQ1dFKWUqjUa3LMKiAoLws9PGrooSilVa5p8cE/L1jbuSinf0+SDu96dqpTyRRrc9e5UpZQPqnFwF5GOIjJPRDaJyAYRudsZHikic0Rkm/O/Ve0Vt3aVlhrSsgs1uCulfI43Nfdi4F5jTG/gVOB3ItIHeBCYa4yJB+Y6709Kh3MLKSk1mpZRSvmcGgd3Y8x+Y8xK53UWsAnoAEwAZjiTzQAu8bKMdebYDUx6d6pSyrfUSs5dROKAU4BfgTbGmP1gDwBATAWfuVVElovI8tTU1NooRrXpDUxKKV/ldXAXkTDgY2CaMSbT088ZY142xgwxxgyJjo72thg1osFdKeWrvAruIhKIDezvGGM+cQYfFJF2zvh2QIp3Raw7GtyVUr7Km9YyArwGbDLGPOMyajZwg/P6BuDzmhevbqVmFdA80J/QIP+GLopSStWqAC8+ezowGVgnIqudYQ8DTwEfiMgUIAm4wqsS1qHU7AKiWgRhj1NKKeU7ahzcjTE/AxVFxbE1nW99Ss3Su1OVUr6pSd+hqnenKqV8VdMO7tppmFLKRzXZ4F5YXMqR3CJ9vJ5Syic12eCenqPNIJVSvqvJBndt466U8mUa3DW4K6V8kDft3Bs1De5KnVyKiopITk4mPz+/oYty0gkODiY2NpbAQM+f9dzkg3tUWFADl0QpBZCcnEyLFi2Ii4vTGwtdGGNIT08nOTmZLl26ePy5ppuWyS4gvHkgzQK06wGlTgb5+fm0bt1aA3s5IkLr1q2rfUbTdIO73sCk1ElHA7t7NflemnRw15SMUspXNd3gnl2gT2BSSh3nwIEDXHXVVXTr1o0+ffpw/vnns3XrVnbt2kW/fv3qZJkFBQVMmjSJ7t27M3z4cHbt2lUr8226wV07DVNKuTDGMHHiREaPHk1iYiIbN27kr3/9KwcPHqzT5b722mu0atWK7du3c8899/D73/++VubbJFvL5BQUk1tYojl3pU5Sj3+xgY37PH6wm0f6tG/Joxf1rXD8vHnzCAwM5Lbbbjs6LCEhAeC42vSuXbuYPHkyOTk5ADz33HOMGDGC/fv3M2nSJDIzMykuLubFF19kxIgRTJkyheXLlyMi3Hzzzdxzzz3HLffzzz/nscceA+Dyyy/njjvuwBjj9fWHJhnctY27Uqq89evXM3jw4Cqni4mJYc6cOQQHB7Nt2zauvvpqli9fzqxZszj33HN55JFHKCkpITc3l9WrV7N3717Wr18PwJEjR06Y3969e+nYsSMAAQEBhIeHk56eTlRUlFfr0ySDe1q2BnelTmaV1bAbWlFREXfccQerV6/G39+frVu3AjB06FBuvvlmioqKuOSSS0hISKBr167s2LGDO++8kwsuuIBzzjnnhPkZY04YVhuthppkzv1ozV1z7kopR9++fVmxYkWV002fPp02bdqwZs0ali9fTmFhIQBnnHEGCxcupEOHDkyePJmZM2fSqlUr1qxZw+jRo3n++ee55ZZbTphfbGwse/bsAaC4uJiMjAwiIyO9Xp+mGdy15q6UKmfMmDEUFBTwyiuvHB22bNkyFixYcNx0GRkZtGvXDj8/P9566y1KSkoA2L17NzExMUydOpUpU6awcuVK0tLSKC0t5bLLLuOJJ55g5cqVJyz34osvZsaMGQB89NFHjBkzplZq7k0yLZOaVYCfQGSotnNXSlkiwqeffsq0adN46qmnCA4OJi4ujmefffa46W6//XYuu+wyPvzwQ8466yxCQ0MBmD9/Pv/85z8JDAwkLCyMmTNnsnfvXm666SZKS0sB+Nvf/nbCcqdMmcLkyZPp3r07kZGRvPfee7WzPu7yPfVtyJAhZvny5fW2vAc/XsvczSkse2RcvS1TKVW5TZs20bt374YuxknL3fcjIiuMMUPcTd800zLaxl0p5eOaZnDPLiBK8+1KKR/WNIO71tyVUj6uyQX30lJDWrb2CKmU8m1NLrhn5BVRVGI0uCulfFqTC+7axl0p1RQ0veCud6cqpSrQEF3+Lly4kEGDBhEQEMBHH31Ua/NtusFda+5KKRcN1eVvp06dePPNN7nmmmtqdb5N7g5VDe5KNQLfPAgH1tXuPNv2h/OeqnB0Q3X5GxcXB4CfX+3WtZtccE/LLiAowI+WwU1u1ZVSlWioLn/rSpOLcGVt3PVBvEqdxCqpYTe02u7yt67UWXAXkfHAvwF/4FVjTL38WoXFpSzffYhF29PJyi86YfyvOw9pSkYpdYK+fft6dEHTtcvf0tJSgoPts5jLuvz96quvmDx5Mvfffz/XX389a9as4bvvvuP555/ngw8+4PXXX6/rVQHqKLiLiD/wPHA2kAwsE5HZxpiNdbG83ek5LNyayoKtqSxKTCe3sIQAPyGsgtTLpfEd6qIYSqlGbMyYMTz88MO88sorTJ06FbBd/ubm5tK5c+ej02VkZBAbG4ufnx8zZsw4rsvfDh06MHXqVHJycli5ciXnn38+QUFBXHbZZXTr1o0bb7yx3tanrmruw4DtxpgdACLyHjABqNXgvjb5CHe9u4pd6bkAdIxszqWDOnBmjxhO69aasGZNLuuklKqhhuryd9myZUycOJHDhw/zxRdf8Oijj7Jhwwbv16cuuvwVkcuB8caYW5z3k4Hhxpg7XKa5FbgVoFOnToN3795d7eWkZxdw34drOLNHNGf2jCGudYjm0pVqpLTL38pVt8vfuqrauouwxx1FjDEvAy+D7c+9JgtpHdaMN24aVpOPKqWUT6urm5iSgY4u72OBfXW0LKWUUuXUVXBfBsSLSBcRCQKuAmbX0bKUUj7iZHgy3MmoJt9LnQR3Y0wxcAfwHbAJ+MAY4/0VAqWUzwoODiY9PV0DfDnGGNLT0482ufRUnTUnMcZ8DXxdV/NXSvmW2NhYkpOTSU1NbeiinHSCg4OJjY2t1me0raBS6qQQGBhIly5dGroYPqPJ9QqplFJNgQZ3pZTyQRrclVLKB9XJHarVLoRIKlD9W1SPiQLSaqk4jYmud9Oi6920eLLenY0x0e5GnBTB3VsisryiW3B9ma5306Lr3bR4u96allFKKR+kwV0ppXyQrwT3lxu6AA1E17tp0fVuWrxab5/IuSullDqer9TclVJKudDgrpRSPqhRB3cRGS8iW0Rku4g82NDlqSsi8rqIpIjIepdhkSIyR0S2Of9bNWQZ64KIdBSReSKySUQ2iMjdznCfXncRCRaRpSKyxlnvx53hPr3eZUTEX0RWiciXzvumst67RGSdiKwWkeXOsBqve6MN7i4P4T4P6ANcLSJ9GrZUdeZNYHy5YQ8Cc40x8cBc572vKQbuNcb0Bk4Ffuf8xr6+7gXAGGPMQCABGC8ip+L7613mbmxX4WWaynoDnGWMSXBp317jdW+0wR2Xh3AbYwqBsodw+xxjzELgULnBE4AZzusZwCX1Wab6YIzZb4xZ6bzOwu7wHfDxdTdWtvM20Pkz+Ph6A4hILHAB8KrLYJ9f70rUeN0bc3DvAOxxeZ/sDGsq2hhj9oMNgkBMA5enTolIHHAK8CtNYN2d1MRqIAWYY4xpEusNPAs8AJS6DGsK6w32AP69iKwQkVudYTVe98bcn3uVD+FWvkFEwoCPgWnGmEwRdz+9bzHGlAAJIhIBfCoi/Rq4SHVORC4EUowxK0RkdAMXpyGcbozZJyIxwBwR2ezNzBpzzb2pP4T7oIi0A3D+pzRweeqEiARiA/s7xphPnMFNYt0BjDFHgPnYay6+vt6nAxeLyC5smnWMiLyN7683AMaYfc7/FOBTbOq5xuvemIN7U38I92zgBuf1DcDnDViWOiG2iv4asMkY84zLKJ9edxGJdmrsiEhzYBywGR9fb2PMQ8aYWGNMHHZ//tEYcx0+vt4AIhIqIi3KXgPnAOvxYt0b9R2qInI+NkfnD7xujHmyYUtUN0TkXWA0tgvQg8CjwGfAB0AnIAm4whhT/qJroyYiI4GfgHUcy8E+jM27++y6i8gA7MUzf2wF7ANjzJ9FpDU+vN6unLTMfcaYC5vCeotIV2xtHWy6fJYx5klv1r1RB3ellFLuNea0jFJKqQpocFdKKR+kwV0ppXyQBnellPJBGtyVUsoHaXBXSikfpMFdKaV80P8DsH86fRZqrScAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(valid_zero_class_p, label = 'Class 0')\n",
    "plt.plot(valid_one_class_p, label = 'Class 1')\n",
    "plt.title(\"Validation-Each class accuracy at each epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestAnalysis(model_saved, test_loader):\n",
    "    test_actual = []\n",
    "    test_predict = []\n",
    "\n",
    "    for xtst, ytst in test_loader:\n",
    "        yp = model_saved(xtst)\n",
    "        pred_ix = yp.argmax(dim = 1)\n",
    "        test_predict.append(pred_ix.numpy())\n",
    "        test_actual.append(ytst.numpy())\n",
    "        \n",
    "    return (np.array(test_predict).reshape(-1,1), np.array(test_actual).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNSpam(\n",
       "  (embed): Embedding(7549, 50)\n",
       "  (rnn): RNN(50, 100)\n",
       "  (fc1): Linear(in_features=1000, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "MODEL = torch.load(\"model_rnn.pth\")\n",
    "MODEL.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "#test \n",
    "test_pred, test_actual = TestAnalysis(MODEL, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967948717948718"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_actual, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 80.58, '1': 99.26}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each class accuracy\n",
    "\n",
    "EachAccuracyClass(test_actual, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
